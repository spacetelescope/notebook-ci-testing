{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ad3e89",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Predicting galaxy redshift via regression on 3D-HST photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f528bd3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed14285",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "\n",
    "**In this tutorial, you will see an example of building and training a decision tree-based regression model to perform regression on astronomical data.**  By the end of this tutorial you will have working examples of how to apply decision trees and random forests in scikit-learn (sklearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25d1dc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Decision trees are a form supervised machine learning which can be used for classification or regression. In this notebook, we will walk through the basic steps of applying three types of decision tree algorithms to multi-wavelength photometric data.\n",
    "\n",
    "1. Download and import the data\n",
    "2. Perform data cleaning steps\n",
    "3. Divide the data into training, validation and testing sets\n",
    "4. Use a simple decision tree to perform a regression task via sklearn\n",
    "5. Use a random forest to perform a regression task via sklearn\n",
    "6. Consider the effects of over-fitting\n",
    "8. Compare the \"best\" model to the state-of-the-art \n",
    "\n",
    "Decision trees are used in a wide range of vector analysis tasks. Here we will use them to regress galaxy redshift from its multi-wavelength photometry. We will use data from the [3D-HST](https://archive.stsci.edu/prepds/3d-hst/) survey. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71666ddc",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This notebook uses the following packages:\n",
    "- `numpy` to handle array functions\n",
    "- `tarfile` to unpack files\n",
    "- `astropy` for downloading and accessing FITS files\n",
    "- `matplotlib.pyplot` for plotting data\n",
    "- `sklearn` for machine learning tools and performance metrics\n",
    "\n",
    "If you do not have these packages installed, you can install them using [`pip`](https://pip.pypa.io/en/stable/) or [`conda`](https://docs.conda.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays\n",
    "import numpy as np\n",
    "\n",
    "# unpacking files\n",
    "import tarfile\n",
    "\n",
    "# fits\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.table import Table\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, validation_curve\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# from IPython import get_ipython\n",
    "# get_ipython().run_line_magic('matplotlib', 'notebook')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd93189",
   "metadata": {},
   "source": [
    "### 1. Download and import the data \n",
    "\n",
    "First, download the 3D-HST catalog from the MAST archive. This dataset is described in [Skelton et. al 2014](https://dx.doi.org/10.1088/0067-0049/214/2/24)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'https://archive.stsci.edu/missions/hlsp/3d-hst/RELEASE_V4.0/Photometry/3dhst_master.phot.v4.1.tar'\n",
    "tarfile.open(download_file(file_url, cache=True), \"r:\").extract('3dhst_master.phot.v4.1/3dhst_master.phot.v4.1.cat', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7322000",
   "metadata": {},
   "source": [
    "Read the combined photmetric catalog into a dataframe via astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afe5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = Table.read('3dhst_master.phot.v4.1/3dhst_master.phot.v4.1.cat', format='ascii').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35faa488",
   "metadata": {},
   "source": [
    "Now we will examine the contents of the catalog! The dataset contains standard information such as target id, field name, coordinates, fluxes, errors, and various photometric flags (see [Skelton et. al 2014](https://dx.doi.org/10.1088/0067-0049/214/2/24), or download the [README here](https://archive.stsci.edu/missions/hlsp/3d-hst/RELEASE_V4.0/Photometry/master_readme.v4.1.txt)). In addition, there are derived properties such as photometric redshift (`z_peak`), spectroscopic redshift (`z_spec`), mass (`lmass`) and dust extinction in the V band (`Av`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d264b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0373ed",
   "metadata": {},
   "source": [
    "### 2. Perform data cleaning steps\n",
    "\n",
    "Before building and applying a regression model, we first need to inspect and clean the dataset. \n",
    "\n",
    "To explore the physical parameters of the sample, we plot the spectroscopic redshift vs. the mass derived from the [FAST](https://ui.adsabs.harvard.edu/abs/2018ascl.soft03008K/abstract) phototmetric fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "ax.scatter(tab.z_spec, tab.lmass, alpha=0.2, color='grey')\n",
    "ax.set_xlim(0, 2)\n",
    "ax.set_ylim(7, 12)\n",
    "ax.set_xlabel(r'$z_{\\rm spec}$')\n",
    "ax.set_ylabel(r'$\\log{(M_{*})}\\,\\,[M_{\\odot}]$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c274dd5",
   "metadata": {},
   "source": [
    "By inspection of this plot, we will only keep sources with log(M)>9 to remove sources which do not have complete coverage across redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db27c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tab[tab.lmass > 9].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e255e",
   "metadata": {},
   "source": [
    "We're interested in predicting redshift, so our \"target\" variable will be z_spec. The \"features\" will be all columns except for the spectroscopic and photometric redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d018c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'z_spec'\n",
    "features = [col for col in tab.columns if (col != target)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308f840",
   "metadata": {},
   "source": [
    "Next, we will make histograms of each input to gain an intuition for the distribution of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6377ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0, [20,18])\n",
    "\n",
    "for k, feat in enumerate(features):\n",
    "    ax = fig.add_subplot(7, 6, k+1)\n",
    "    ax.hist(tab[feat], bins=50, log=True, color='grey')\n",
    "    ax.set_title(feat)\n",
    "\n",
    "ax = fig.add_subplot(7, 6, len(features)+1)\n",
    "ax.hist(tab[target], bins=50, color='red')\n",
    "ax.set_title(r'$z_{\\rm spec}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeeeec3",
   "metadata": {},
   "source": [
    "The 'Av', 'lmass' and 'z_peak' values were all computed via FAST photometric fit, and so we will exclude them as well. In addition, we will exclude the categorical flag variables ('flags', 'f140w_flag', 'star_flag', 'use_phot', 'near_star')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda22980",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in features if (col != 'Av') and (col != 'lmass') and (col != 'z_peak') \n",
    "            and (col != 'flags') and (col != 'f140w_flag') and (col != 'star_flag') \n",
    "            and (col != 'use_phot') and (col != 'near_star')]\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bfa6d",
   "metadata": {},
   "source": [
    "Next, we will remove sources which have no constraints for our target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tab[(tab[target] > 0)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c5e0b",
   "metadata": {},
   "source": [
    "Next, we will encode the 'field\" variable,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "tab['field'] = label_encoder.fit_transform(tab['field'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff2886",
   "metadata": {},
   "source": [
    "Finally we will impute missing values of photometric errors (set to -99. in the table) by assigning them the median of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [col for col in features if (col[:1] == 'e') and (col[-1:] == 'W')]\n",
    "\n",
    "for error in errors:\n",
    "    tab[error] = np.where(tab[error] < -90, tab[error].median(), tab[error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45202bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0, [20, 18])\n",
    "\n",
    "for k, feat in enumerate(features):\n",
    "    ax = fig.add_subplot(7, 6, k+1)\n",
    "    ax.hist(tab[feat], bins=50, log=True, color='navy')\n",
    "    ax.set_title(feat)\n",
    "\n",
    "ax = fig.add_subplot(7, 6, len(features)+1)\n",
    "ax.hist(tab[target], bins=50, color='red')\n",
    "ax.set_title(r'$z_{\\rm spec}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae252bff",
   "metadata": {},
   "source": [
    "### 3. Divide the data into train, test and validation sets\n",
    "\n",
    "First, define the independent (X) and dependent (y) variables from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da753d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tab[features].values\n",
    "y = tab[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532aae44",
   "metadata": {},
   "source": [
    "Divide the data into train, validation and test sets. We will use the following definitions:\n",
    "\n",
    "- **Training**: The data used to update *model parameters* (e.g., coefficients or matrix element values).\n",
    "- **Valdiation**: The data used to update *model selection* (for instance, we might change *hyperparameters* of a model based on the validation metrics).\n",
    "- **Testing**: The data used to make final predictions, and possibly evaluate the final model score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(y))\n",
    "\n",
    "# first reserve 70% of the data for training, 30% for validation\n",
    "X_train, X_validate, y_train, y_validate, indices_train, indices_validate = train_test_split(X, y, indices, test_size=0.3, random_state=42)\n",
    "\n",
    "# second, split the validation set in half to obtain validation and test sets. \n",
    "X_validate, X_test, y_validate, y_test, indices_validate, indices_test = train_test_split(X_validate, y_validate, indices_validate, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da814978",
   "metadata": {},
   "source": [
    "### 4. Decision tree regression\n",
    "\n",
    "Using sklearn, we can very easily construct a decision tree model for regressing redshift from the photometric catalog features. A decision tree is composed of a series of `if-else` decision steps. The number of steps and the types of decision at each step is determined by training the algorithm with supervision. In this first example, we will use the [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae673e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "dtree = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model parameters using the training dataset\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926c478",
   "metadata": {},
   "source": [
    "To quantify the performance of the model, we will apply it to the validation set and compare the predicted values with the true values by computing the mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b870893",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = dtree.predict(X_test)\n",
    "print(f'MSE = {mean_squared_error(y_test, y_predict):.4f}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.scatter(y_validate, y_predict, alpha=0.2, color='black')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-0.1, 5)\n",
    "ax.set_ylim(-0.1, 5)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Truth (y_test)')\n",
    "ax.set_ylabel('Decision Tree prediction (y_predict)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914155c7",
   "metadata": {},
   "source": [
    "Hmm, maybe we can do better by tuning the parameters of the model. Decision trees have many parameters, such as the maximum number of decisions (`max_depth`), the minimum number of samples required to create a split a node (`min_samples_split`) and the minimum number of samples required to be at a node leaf (`min_samples_leaf`). All available parameters are listed below, and are described in the [sklearn documenation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor().get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96aa7cd",
   "metadata": {},
   "source": [
    "Selecting the optimal values of these parameters is sometimes done via targeted grid search, and can also be done via random search, which we will implement here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00877afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_distributions = {\n",
    "    'max_depth': np.arange(1, 20, 2).astype(int),\n",
    "    'min_samples_split': np.arange(5, 105, 10).astype(int),\n",
    "    'min_samples_leaf': np.arange(5, 105, 10).astype(int)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    dtree, \n",
    "    param_distributions=hyperparameter_distributions,\n",
    "    n_iter=100\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = random_search.predict(X_test)\n",
    "print(f'MSE = {mean_squared_error(y_test, y_predict):.4f}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.scatter(y_validate, y_predict, alpha=0.2, color='black')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-0.1, 5)\n",
    "ax.set_ylim(-0.1, 5)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Truth (y_test)')\n",
    "ax.set_ylabel('Decision Tree prediction (y_predict)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2147bb",
   "metadata": {},
   "source": [
    "The model improved somewhat with hyperparameter tuning (i.e., the MSE decreased), but the results still looks pretty bad. We'll try another model next!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5866e8c5",
   "metadata": {},
   "source": [
    "### 5. Random forest regression\n",
    "\n",
    "A random forest is an algorithm composed of many decision trees. Trained via supervised machine learning, random forests are used for both classification and regression tasks. Here we'll apply a random forest to regress redshift from 3D-HST photometry, and compare the results to the simple decision tree in Section 4. We will use the [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same parameters as the Decision Tree\n",
    "params = {\n",
    "    \"min_samples_split\": 15,\n",
    "    \"min_samples_leaf\": 5,\n",
    "    \"max_depth\": 15,\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c482ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = rf.predict(X_test)\n",
    "print(f'MSE = {mean_squared_error(y_test, y_predict):.4f}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "ax.scatter(y_test, y_predict, alpha=0.2, color='black')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-0.1, 5)\n",
    "ax.set_ylim(-0.1, 5)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Truth (y_test)')\n",
    "ax.set_ylabel('Decision Tree prediction (y_predict)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e09bfd",
   "metadata": {},
   "source": [
    "### 6. Test for over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f576fb",
   "metadata": {},
   "source": [
    "The results are much improved by the random forest! **However, we must be cautious!** It is possible that this model suffers from over-fitting. To visualize overfitting, we can compare the mean squared error (MSE) for models of increasing `max_depth` on the training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e727f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(1, 20, 2).astype(int)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "for depth in max_depths:\n",
    "\n",
    "    params = {\n",
    "        \"min_samples_split\": 15,\n",
    "        \"min_samples_leaf\": 5,\n",
    "        \"max_depth\": depth,\n",
    "    }\n",
    "    rff = RandomForestRegressor(**params)\n",
    "    rff.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict_train = rff.predict(X_train)\n",
    "    y_predict_test = rff.predict(X_test)\n",
    "    \n",
    "    train_mse.append(mean_squared_error(y_train, y_predict_train))\n",
    "    test_mse.append(mean_squared_error(y_test, y_predict_test))\n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "ax.plot(max_depths, train_mse, color='blue', label='Training Set')\n",
    "ax.plot(max_depths, test_mse, color='orange', label='Test Set')\n",
    "ax.set_xlabel('max depth')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b6b11",
   "metadata": {},
   "source": [
    "Beyond a max_depth of ~10, the MSE on the training set declines while the MSE on the test set flattens out, suggesting some amount of over-fitting. \n",
    "\n",
    "To explore further, we will explore how general our model performance (here quantifed with MSE) is using k-fold cross-validation via `sklearn`. In practice, the X and y datasets are split into k \"folds\", and over k iterations, the model is trained using k-1 folds as training data and the remaining fold as a test set to compute performace (i.e., MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_validate(\n",
    "    estimator=rf, \n",
    "    X=X, \n",
    "    y=y, \n",
    "    cv=5, # number of folds\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "print(f'Cross-validated score: {cv[\"test_score\"].mean():.3f} +/- {cv[\"test_score\"].std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb6a5a",
   "metadata": {},
   "source": [
    "The best-fit MSE is consistent with the cross-validated MSE, suggesting that the model is not significantly over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031c4ef",
   "metadata": {},
   "source": [
    "Next, we'll observe which features are most important to the model predictions with the [`feature_importances`](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "fig = plt.figure(0, [8, 16])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.barh(np.arange(X.shape[1]), importances, \n",
    "        align='center', \n",
    "        height=0.5, \n",
    "        tick_label=features)\n",
    "ax.set_xlabel(\"Feature importance\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03582f16",
   "metadata": {},
   "source": [
    "The most \"important\" features in this model are the F125W and F606W fluxes. Parameters such as id, ra, dec, x, and y understandably have very little influence on the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a856ed3e",
   "metadata": {},
   "source": [
    "### 7. Compare to the state of the art\n",
    "\n",
    "A crucial step in the process of constructing a machine learning model is to consider how the results compare to the state of the art. In this case, we can compare the predictions from our random forest model to the results of detailed modeling of the photometric redshift (`z_peak`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_validate = rf.predict(X_validate)\n",
    "y_skelton2014 = tab['z_peak'].values[indices_validate]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 5))\n",
    "ax[0].scatter(y_validate, y_predict_validate, alpha=0.2, color='black')\n",
    "ax[0].set_aspect('equal')\n",
    "ax[0].set_xlim(-0.1, 5)\n",
    "ax[0].set_ylim(-0.1, 5)\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel('Truth (z_spec)')\n",
    "ax[0].set_ylabel('Random forest prediction (y_predict)')\n",
    "\n",
    "ax[1].scatter(y_validate, y_skelton2014, alpha=0.2, color='black')\n",
    "ax[1].set_aspect('equal')\n",
    "ax[1].set_xlim(-0.1, 5)\n",
    "ax[1].set_ylim(-0.1, 5)\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel('Truth (z_spec)')\n",
    "ax[1].set_ylabel('Skelton et al. 2014 model (z_peak)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d5ca8",
   "metadata": {},
   "source": [
    "Comparing the MSE for the results above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69658e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Random forest MSE = {mean_squared_error(y_validate, y_predict_validate):.4f}\")\n",
    "print(f\"Skelton et al. (2014) MSE = {mean_squared_error(y_validate, y_skelton2014):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65871243",
   "metadata": {},
   "source": [
    "Clearly, the Skelton et al. (2014) model out performs the random forest!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86fad4",
   "metadata": {},
   "source": [
    "## FAQs\n",
    "\n",
    "- **How do I interpret these results?** Overall, although the random forest model is not significantly over-fitting, it performs much worse than the ([Skelton et al. 2014](https://dx.doi.org/10.1088/0067-0049/214/2/24)) model. We can concluded that this particular random forest model is **not** a good choice for predicting galaxy redshift. However, an important difference between these two models is that this random forest only uses photometric bands (F606W, F816W, F125W, F140W, and F160W) while Skelton et al. (2014) uses upwards of 15 photometric bands! \n",
    "\n",
    "\n",
    "- **How can I improve the results of the model?** There are several strategies to try. You can explore changes to the current models, including parameter grid searches, or [pruning](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html). Finally you can apply additional \"feature engineering\", for example selecting different subsets of features or exploring how to improve the data cleaning. \n",
    "\n",
    "\n",
    "- **Why hasn't anyone used this dataset for this purpose before?** The 3D-HST dataset was not constructed for machine learning purposes, but it is a feature-rich, relatively compact dataset for trying out new methods, even if they are not all successful. We encourage you to explore the rest of the [high-level science product](https://archive.stsci.edu/prepds/3d-hst/) for more ideas!\n",
    "\n",
    "\n",
    "- **I want to test my model on my training data!** No. You will convince yourself that your results are much better than they actually are.  Always keep your training, validation, and testing sets completely separate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e2aea",
   "metadata": {},
   "source": [
    "## Extensions / Exercises\n",
    "\n",
    "- **Upgrade the analysis by including new features!** For example, if you include galaxy colors (e.g., F125W-F140W, F140W-F160W, F606W-F125W) do the model results improve? Can you think of other features to include?\n",
    "\n",
    "\n",
    "- **Tune the model parameters with a grid search** Do the Random Forest model results improve if you implement a random grid search over hyperparameters as we did for the Decision Tree model? \n",
    "\n",
    "\n",
    "- **Try other models** Explore `sklearn` and try out other regression models, such as gradient-boosted trees. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed29a9e",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "\n",
    "**Author:**  \n",
    "Claire Murray, Assistant Astronomer, cmurray1@stsci.edu  \n",
    "\n",
    "\n",
    "**Info:**  \n",
    "This notebook is based on the machine learning tutorials by John F. Wu, Assistant Astronomer, (STScI).\n",
    "\n",
    "\n",
    "**Updated On:** 2022-5-25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af436a1f",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "If you use this data set, `astropy`, or `sklearn` for published research, please cite the\n",
    "authors. Follow these links for more information:\n",
    "\n",
    "* [Citing the data set](https://ui.adsabs.harvard.edu/abs/2014ApJS..214...24S/abstract)\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html)\n",
    "* [Citing `sklearn`](https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576645b",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
