name: Execute Jupyter Notebooks with Auto-Scaling

on:
  push:
    paths:
      - 'notebooks/**.ipynb'  # Trigger on changes to notebooks in the notebooks directory
  pull_request:
    paths:
      - 'notebooks/**.ipynb'  # Trigger on PRs with notebooks

jobs:
  run-notebooks:
    runs-on: ubuntu-latest  # Use default runner to start with

    strategy:
      matrix:
        notebook: ${{ fromJson(needs.find-notebooks.outputs.notebooks) }}  # Matrix for parallel execution of notebooks

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Install notebook dependencies
        run: |
          notebook_dir=$(dirname "${{ matrix.notebook }}")
          if [ -f "$notebook_dir/requirements.txt" ]; then
            echo "Installing dependencies for $notebook_dir"
            python -m pip install --upgrade pip
            pip install -r "$notebook_dir/requirements.txt"
          fi

      - name: Execute Jupyter Notebook
        run: |
          notebook_dir=$(dirname "${{ matrix.notebook }}")
          jupyter nbconvert --to notebook --execute "$notebook_dir/${{ matrix.notebook }}" --ExecutePreprocessor.timeout=600 --allow-errors --stdout

      - name: Monitor system resources
        run: |
          # Monitor memory and disk space usage
          MEMORY_USAGE=$(free -g | grep Mem | awk '{print $3}')
          DISK_USAGE=$(df -h / | grep / | awk '{print $5}' | sed 's/%//')
          
          echo "Memory usage: $MEMORY_USAGE GB"
          echo "Disk usage: $DISK_USAGE%"

          # Check if either memory or disk usage exceeds 90%
          if [ "$MEMORY_USAGE" -gt 8 ] || [ "$DISK_USAGE" -gt 90 ]; then
            echo "Resource usage exceeded, scaling to 16GB runner."
            echo "::set-output name=scale_to::16"
          fi

      - name: Scale Runner to 16GB if required
        if: ${{ steps.monitor.outputs.scale_to == '16' }}
        run: |
          echo "Scaling to 16GB runner due to resource usage"
          # This would trigger the next workflow job to scale
          # Logic to trigger the scaling (use different runners for 16GB and 32GB)
          
          # Use a different runner setup (e.g., jwst-pipeline-notebooks-16gb) for the next attempt
          echo "jobs.run-notebooks.runs-on: jwst-pipeline-notebooks-16gb"

      - name: Final Scaling Attempt (32GB)
        if: ${{ steps.monitor.outputs.scale_to == '16' }}
        run: |
          echo "Attempting to scale to 32GB runner"
          # Use a 32GB runner if 16GB failed
          echo "jobs.run-notebooks.runs-on: jwst-pipeline-notebooks-32gb"

      - name: Handle final failure and report
        if: ${{ failure() }}
        run: |
          echo "The notebook failed due to resource exhaustion. Job has failed."
          exit 1

  find-notebooks:
    runs-on: ubuntu-latest

    outputs:
      notebooks: ${{ steps.notebooks.outputs.notebooks }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Find all notebooks
        id: notebooks
        run: |
          notebooks=$(find notebooks/ -type f -name '*.ipynb')
          echo "Found notebooks: $notebooks"
          echo "::set-output name=notebooks::$(echo $notebooks | jq -R . | jq -s .)"  # Convert list to JSON

