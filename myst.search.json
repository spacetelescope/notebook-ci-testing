{"version":"1","records":[{"hierarchy":{"lvl1":"JWST Pipeline Notebooks"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks"},"type":"lvl1","url":"/#jwst-pipeline-notebooks","position":2},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks"},"content":"\n\nImportant\n\nJWST requires a C compiler for dependencies and is currently limited to Python 3.11, 3.12, or 3.13.\n\nNote\n\nLinux and MacOS platforms are tested and supported.  Windows is not currently supported.\n\nThe jwst-pipeline-notebooks repository contains python-based Jupyter notebooks that illustrate how to process JWST data through the STScI science calibration pipeline (jwst;  \n\nhttps://​github​.com​/spacetelescope​/jwst).  An overview of the pipeline can be found at \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline.\n\nNotebooks are organized according to instrument and observing mode.  Each notebook is designed to process data from uncalibrated raw FITS files to end-stage Level 3 data products (calibrated imaging mosaics, 3-D data cubes, 1-D extracted spectra, etc.).  These notebooks by default run in ‘demo’ mode, for which they will download and process example data drawn from the \n\nMAST archive.  They are, however, designed to be simple to run on arbitrary local data sets as well by configuring input directories accordingly.\n\nThese notebooks are modular, allowing users to enable or disable different stages of processing.  Likewise, they provide examples of how to customize pipeline processing for specific science cases.\n\nThe following table summarizes the notebooks currently available and the JWST \n\npipeline versions that they have been tested with:\n\nInstrument\n\nObserving Mode\n\nJWST Build\n\njwst version\n\nNotebook\n\nMIRI\n\nCoronagraphy\n\n12.0\n\n1.19.1\n\nJWPipeNB​-MIRI​-Coron​.ipynb\n\nMIRI\n\nImaging\n\n12.0\n\n1.19.1\n\nJWPipeNB​-MIRI​-imaging​.ipynb\n\nMIRI\n\nImaging TSO\n\n12.0\n\n1.19.1\n\nJWPipeNB​-MIRI​-imaging​-TSO​.ipynb\n\nMIRI\n\nLRS Slit\n\n12.0\n\n1.19.1\n\nJWPipeNB​-MIRI​-LRS​-slit​.ipynb\n\nMIRI\n\nLRS Slitless\n\n12.0\n\n1.19.1\n\nJWPipeNB​-MIRI​-LRS​-slitless​-TSO​.ipynb\n\nMIRI\n\nMRS\n\n12.0\n\n1.19.1\n\nJWPipeNB​-MIRI​-MRS​.ipynb\n\nNIRCam\n\nCoronagraphy\n\n12.0\n\n1.19.1\n\nJWPipeNB​-nircam​-coronagraphy​.ipynb\n\nNIRCam\n\nImaging\n\n12.1\n\n1.20.0\n\nJWPipeNB​-nircam​-imaging​.ipynb\n\nNIRISS\n\nAMI\n\n12.0\n\n1.19.1\n\nJWPipeNB​-niriss​-ami​.ipynb\n\nNIRISS\n\nImaging\n\n12.0\n\n1.19.1\n\nJWPipeNB​-niriss​-imaging​.ipynb\n\nNIRISS\n\nSOSS\n\n12.1\n\n1.20.2\n\nJWPipeNB​-niriss​-soss​.ipynb\n\nNIRISS\n\nWFSS\n\n12.0\n\n1.19.1\n\nJWPipeNB​-niriss​-wfss​.ipynb\n\nNIRSpec\n\nBOTS\n\n12.0\n\n1.19.1\n\nJWPipeNB​-NIRSpec​-BOTS​.ipynb\n\nNIRSpec\n\nFixed Slit\n\n12.0\n\n1.19.1\n\nJWPipeNB​-NIRSpec​-FS​.ipynb\n\nNIRSpec\n\nIFU\n\n12.0\n\n1.19.1\n\nJWPipeNB​-NIRSpec​-IFU​.ipynb\n\nNIRSpec\n\nMOS\n\n12.0\n\n1.19.1\n\nJWPipeNB​-NIRSpec​-MOS​.ipynb","type":"content","url":"/#jwst-pipeline-notebooks","position":3},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Reference Files"},"type":"lvl2","url":"/#reference-files","position":4},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Reference Files"},"content":"As of October 2024, the JWST pipeline will automatically select the best reference file context appropriate to each pipeline version by default.  The notebooks provided here allow users to override this default if desired and choose specific contexts instead.  See \n\nChoosing a Context for guidance.","type":"content","url":"/#reference-files","position":5},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Installation"},"type":"lvl2","url":"/#installation","position":6},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Installation"},"content":"","type":"content","url":"/#installation","position":7},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Individual Notebooks","lvl2":"Installation"},"type":"lvl3","url":"/#individual-notebooks","position":8},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Individual Notebooks","lvl2":"Installation"},"content":"For advanced users, these notebooks can be downloaded individually from the GitHub repository and run in any python environment in which the \n\njwst package meeting the indicated minimum version has been installed.  Note that some notebooks have additional dependencies (e.g., \n\njdaviz) as given in the associated requirements files.","type":"content","url":"/#individual-notebooks","position":9},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Package Installation","lvl2":"Installation"},"type":"lvl3","url":"/#package-installation","position":10},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Package Installation","lvl2":"Installation"},"content":"If desired, you can also clone the entire jwst-pipeline-notebooks repository to your local computer and set up a new virtual or conda environment\nto avoid version conflicts with other packages you may have installed, for example:conda create -n jpnb python=3.13\nconda activate jpnb\ngit clone https://github.com/spacetelescope/jwst-pipeline-notebooks.git\n\nNext, move into the directory of the notebook you want to install and set up the requirements:cd jwst-pipeline-notebooks/notebooks/<whatever-notebook>\npip install -r requirements.txt\njupyter notebook\n\nWe recommend setting up a new environment for each notebook to ensure that there are no conflicting dependencies.","type":"content","url":"/#package-installation","position":11},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Previous Versions"},"type":"lvl2","url":"/#previous-versions","position":12},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Previous Versions"},"content":"Previous versions of these notebooks designed for use with prior builds of the JWST calibration pipeline can be found as tags within this repository.\n\nNotebook Tag\n\nJWST Build\n\njwst version\n\n1.0.0\n\n11.2\n\n1.17.1\n\n1.1.0\n\n11.3\n\n1.18.1\n\n1.2.0\n\n12.0\n\n1.19.1","type":"content","url":"/#previous-versions","position":13},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Citation"},"type":"lvl2","url":"/#citation","position":14},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Citation"},"content":"If you use these notebooks in your work, please cite this repository using \n\nLaw et al. (2025)","type":"content","url":"/#citation","position":15},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Notebook Execution Error Reporting"},"type":"lvl2","url":"/#notebook-execution-error-reporting","position":16},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Notebook Execution Error Reporting"},"content":"This repository includes tools to generate comprehensive reports of notebook execution errors from GitHub Actions workflows. This can help identify patterns in failures, track notebook stability over time, and quickly diagnose issues.","type":"content","url":"/#notebook-execution-error-reporting","position":17},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Using the On-Demand GitHub Action (Easiest)","lvl2":"Notebook Execution Error Reporting"},"type":"lvl3","url":"/#using-the-on-demand-github-action-easiest","position":18},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Using the On-Demand GitHub Action (Easiest)","lvl2":"Notebook Execution Error Reporting"},"content":"The simplest way to generate an error report is through the GitHub Actions interface:\n\nGo to \n\nActions → “Notebook CI - On-Demand Actions”\n\nClick “Run workflow”\n\nSelect “generate-error-report” from the dropdown\n\nConfigure your options (workflow type, number of runs, include logs)\n\nDownload the report from the workflow artifacts","type":"content","url":"/#using-the-on-demand-github-action-easiest","position":19},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Using the Command Line","lvl2":"Notebook Execution Error Reporting"},"type":"lvl3","url":"/#using-the-command-line","position":20},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl3":"Using the Command Line","lvl2":"Notebook Execution Error Reporting"},"content":"To generate an error report locally:# Install dependencies\npip install -r requirements-reporting.txt\n\n# Generate report for all workflows\npython generate_error_report.py --output error_report.md\n\n# Generate report for scheduled workflow only\npython generate_error_report.py --workflow scheduled\n\nFor detailed usage instructions, see \n\nREPORTING.md.","type":"content","url":"/#using-the-command-line","position":21},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Help"},"type":"lvl2","url":"/#help","position":22},{"hierarchy":{"lvl1":"JWST Pipeline Notebooks","lvl2":"Help"},"content":"If you uncover any issues or bugs, you can open an issue on GitHub. For faster responses, however, we encourage you to submit a \n\nJWST Help Desk Ticket","type":"content","url":"/#help","position":23},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron","position":0},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron","position":1},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#miri-conagraphy-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook"},"content":"\n\nAuthors: B. Nickson; MIRI branch\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose: \nThis notebook provides a framework for processing generic Mid-Infrared Instrument (MIRI) Coronagraphic data through all three James Webb Space Telescope (JWST) pipeline stages. Data is assumed to be located in separate observation folders according to the paths set up below. Editing cells other than those in the \n\nConfiguration should not be necessary unless the standard pipeline processing options are modified.\n\nData: \nThis example is set up to use F1550C coronagraphic observations of the super-Jupiter exoplanet HIP 65426 b, obtained by \n\nProgram ID 1386 (PI: S. Hinkley). It incorporates observations of the exoplanet host star HIP 65426 at two separate roll angles (1 exposure each); a PSF reference observation of the nearby star HIP 65219, taken with a 9-pt small grid dither pattern (9 exposures total); a background observation associated with the target star, taken with a 2-pt dither (two exposures); and a background observation associated with the PSF reference target, taken with a 2-pt dither (two exposures).\n\nThe relevant observation numbers are:\n\nScience observations: 8, 9\n\nScience backgrounds: 30\n\nReference observations: 7\n\nReference backgrounds: 31\n\nExample input data to use will be downloaded automatically unless disabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements.\nAny \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the pipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nJan 28, 2025: Migrate from the Coronagraphy_ExambleNB notebook, update to Build 11.2 (jwst 1.17.1).\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes)\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#miri-conagraphy-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#table-of-contents","position":4},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup\n\nDirectory Setup\n\nDetector1 Pipeline\n\nImage2 Pipeline\n\nCoron3 Pipeline\n\nPlot the spectra\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#table-of-contents","position":5},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"1.-Configuration"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-1-configuration","position":6},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"1.-Configuration"},"content":"\n\nSet basic parameters to use with this notebook. These will affect what data is used, where data is located (if already in disk), and pipeline modules run on this data. The list of parameters are as follows:\n\ndemo_mode\n\ndirectories with data\n\nmask\n\nfilter\n\npipeline modules\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this mode, this\nnotebook will download example data from the\nBarbara A. Mikulski Archive for Space Telescopes \n\n(MAST) and process it through the pipeline.\nThis will all happen in a local directory unless modified\nin \n\nSection 3 below.\n\nSet demo_mode = False if you want to process your own data that has already\nbeen downloaded and provide the location of the data.\n\n# Set parameters for demo_mode, mask, filter, data mode directories, and \n# processing steps.\n\n# -------------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# -------------------------Data Mode Directories---------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    basedir = os.path.join(os.path.expanduser('~'), 'FlightData1386/')\n\n    # Point to where science observation data are\n    # Assumes uncalibrated data in sci_r1_dir/uncal/ and sci_r2_dir/uncal/, \n    # and results in stage1, stage2, stage3 directories\n    sci_r1_dir = os.path.join(basedir, 'sci_r1/')\n    sci_r2_dir = os.path.join(basedir, 'sci_r2/')\n\n    # Point to where reference target observation data are\n    # Assumes uncalibrated data in ref_dir/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    ref_targ_dir = os.path.join(basedir, 'ref_targ/')\n\n    # Point to where background observation data are\n    # Assumes uncalibrated data in sci_bg_dir/uncal/ and ref_targ_bg_dir/uncal/,\n    # and results in stage1, stage2 directories\n    bg_sci_dir = os.path.join(basedir, 'bg_sci/')\n    bg_ref_targ_dir = os.path.join(basedir, 'bg_ref_targ/')\n\n# --------------------------Set Processing Steps--------------------------\n# Whether or not to process only data from a given coronagraphic mask/\n# filter (useful if overriding reference files) \n# Note that BOTH parameters must be set in order to work\nuse_mask = '4QPM_1550'  # '4QPM_1065', '4QPM_1140', '4QPM_1550', or 'LYOT_2300'\nuse_filter = 'F1550C'  # 'F1065C', 'F1140C', 'F1550C', or 'F2300C'\n\n# Individual pipeline stages can be turned on/off here. Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndodet1 = True  # calwebb_detector1\ndoimage2 = True  # calwebb_image2\ndocoron3 = True  # calwebb_coron3\n\n# Background processing\ndodet1bg = True  # calwebb_detector1\ndoimage2bg = True  # calwebb_image2\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-1-configuration","position":7},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#set-crds-context-and-server","position":8},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set already, it will be set to create one in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#%env CRDS_CONTEXT jwst_1322.pmap\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path in use\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#set-crds-context-and-server","position":9},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"2.-Package Imports"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-2-package-imports","position":10},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"2.-Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\n#import copy\nimport time\nfrom pathlib import Path\nimport re\n\n# Numpy for doing calculations\nimport numpy as np\n\n# -----------------------Astropy Imports-----------------------------------\n# Astropy utilities for opening FITS and ASCII files, and downloading demo files\nfrom astropy.io import fits\nfrom astropy.wcs import WCS\nfrom astropy.coordinates import SkyCoord\n\n#from astropy import time\nfrom astroquery.mast import Observations\n\n# -----------------------Plotting Imports----------------------------------\n# Matplotlib for making plots\nimport matplotlib.pyplot as plt\n\n\n\n# --------------JWST Calibration Pipeline Imports---------------------------\n# Import the base JWST and calibration reference files packages\nimport jwst\nimport crds\n\n# JWST pipelines (each encompassing many steps)\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Image2Pipeline\nfrom jwst.pipeline import Coron3Pipeline\n\n# JWST pipeline utilities\nfrom jwst import datamodels  # JWST datamodels\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\nfrom jwst.stpipe import Step  # Import the wrapper class for pipeline steps\n\n# Echo pipeline version and CRDS context in use\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(\"Using CRDS Context = {}\".format(crds.get_context_name('jwst')))\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-2-package-imports","position":11},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Define convenience functions","lvl2":"2.-Package Imports"},"type":"lvl3","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#define-convenience-functions","position":12},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Define convenience functions","lvl2":"2.-Package Imports"},"content":"Define a convenience function to select only files of a given coronagraph mask/filter from an input set\n\n# Define a convenience function to select only files of a given coronagraph mask/filter from an input set\ndef select_mask_filter_files(files, use_mask, use_filter):\n    \"\"\"\n    Filter FITS files based on mask and filter criteria from their headers.\n\n    Parameters:\n    -----------\n    files : array-like\n        List of FITS file paths to process\n    use_mask : str\n        Mask value to match in FITS header 'CORONMSK' key\n    use_filter : str\n        Filter value to match in FITS header 'FILTER' key\n\n    Returns:\n    --------\n    numpy.ndarray\n        Filtered array of file paths matching the criteria\n    \"\"\"\n\n    # Make paths absolute paths\n    for i in range(len(files)):\n        files[i] = os.path.abspath(files[i])\n\n    # Convert files to numpy array if it isn't already\n    files = np.asarray(files)\n\n    # If either mask or filter is empty, return all files\n    if not use_mask or not use_filter:\n        return files\n\n    try:\n        # Initialize boolean array for keeping track of matches\n        keep = np.zeros(len(files), dtype=bool)\n\n        # Process each file\n        for i in range(len(files)):\n            try:\n                with fits.open(files[i]) as hdu:\n                    hdu.verify()\n                    hdr = hdu[0].header\n\n                    # Check if requred header keywords exist\n                    if ('CORONMSK' in hdr and 'FILTER' in hdr):\n                        if hdr['CORONMSK'] == use_mask and hdr['FILTER'] == use_filter:\n                            keep[i] = True\n                            files[i] = os.path.abspath(files[i])\n            except (OSError, ValueError) as e:\n                print(f\" Warning: could not process file {files[i]}: {str(e)}\")\n\n        # Return filtered files\n        indx = np.where(keep)\n        return files[indx]\n\n    except Exception as e:\n        print(f\"Error processing files: {str(e)}\")\n        return files  # Return original array in case of failure\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#define-convenience-functions","position":13},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":14},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"content":"\n\nIf running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nFor illustrative purposes, we focus on data taken through the MIRI\n\n\nF1550C filter\nand start with uncalibrated raw data products (uncal.fits). The files use the following naming schema:\njw01386<obs>001_04101_0000<dith>_mirimage_uncal.fits, where obs refers to the observation number and dith refers to the\ndither step number.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    print('Running in demonstration mode and will download example data from MAST!')\n    program = \"01386\"\n    sci_r1_observtn = \"008\"  \n    sci_r2_observtn = \"009\"  \n    ref_targ_observtn = \"007\"      \n    bg_sci_observtn = \"030\"  \n    bg_ref_targ_observtn = \"031\"\n\n    # ----------Define the base and observation directories----------\n    basedir = os.path.join('.', 'miri_coro_demo_data')\n    download_dir = basedir\n    sci_r1_dir = os.path.join(basedir, 'Obs' + sci_r1_observtn)\n    sci_r2_dir = os.path.join(basedir, 'Obs' + sci_r2_observtn)\n    ref_targ_dir = os.path.join(basedir, 'Obs' + ref_targ_observtn)\n    bg_sci_dir = os.path.join(basedir, 'Obs' + bg_sci_observtn)\n    bg_ref_targ_dir = os.path.join(basedir, 'Obs' + bg_ref_targ_observtn)\n\n    uncal_sci_r1_dir = os.path.join(sci_r1_dir, 'uncal')\n    uncal_sci_r2_dir = os.path.join(sci_r2_dir, 'uncal')\n    uncal_ref_targ_dir = os.path.join(ref_targ_dir, 'uncal')\n    uncal_bg_sci_dir = os.path.join(bg_sci_dir, 'uncal')\n    uncal_bg_ref_targ_dir = os.path.join(bg_ref_targ_dir, 'uncal')\n    \n    # Ensure filepaths for input data exist\n    input_dirs = [uncal_sci_r1_dir, uncal_sci_r2_dir, uncal_ref_targ_dir, uncal_bg_sci_dir, uncal_bg_ref_targ_dir]\n\n    for dir in input_dirs:\n        if not os.path.exists(dir):\n            os.makedirs(dir)\n\n\n\nIdentify list of uncalibrated files associated with visits.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/CORON\"],\n                                               provenance_name=[\"CALJWST\"],\n                                               proposal_id=[program])\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE', 'productSubGroupDescription': 'UNCAL', 'calib_level': [1]}}\n\n    # Loop over visits identifying uncalibrated files that are associated with them\n    files_to_download = []\n    for exposure in (obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            files_to_download.extend(filtered_products['dataURI'])\n\n    # Cull to a unique list of files for each observation type \n    # Science roll 1 \n    sci_r1_files_to_download = []\n    sci_r1_files_to_download = np.unique([i for i in files_to_download if str(program + sci_r1_observtn) in i])\n\n    # Science roll 2 \n    sci_r2_files_to_download = []\n    sci_r2_files_to_download = np.unique([i for i in files_to_download if str(program + sci_r2_observtn) in i])\n\n    # PSF Reference taraget data\n    ref_targ_files_to_download = []\n    ref_targ_files_to_download = np.unique([i for i in files_to_download if str(program + ref_targ_observtn) in i])\n\n    # Background files (science assoc.)\n    bg_sci_files_to_download = []\n    bg_sci_files_to_download = np.unique([i for i in files_to_download if str(program + bg_sci_observtn) in i])\n\n    # Background files (reference target assoc.)\n    bg_ref_targ_files_to_download = []  \n    bg_ref_targ_files_to_download = np.unique([i for i in files_to_download if str(program + bg_ref_targ_observtn) in i])\n\n    print(\"Science files selected for downloading: \", len(sci_r1_files_to_download) + len(sci_r1_files_to_download))\n    print(\"PSF Reference target files selected for downloading: \", len(ref_targ_files_to_download))\n    print(\"Background selected for downloading: \", len(bg_sci_files_to_download) + len(bg_ref_targ_files_to_download))\n\n\n\nFor the demo example, there should be 6 Science files, 11 PSF Reference files and 4 Background files selected for downloading.\n\nDownload all the uncal files and place them into the appropriate directories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\nif demo_mode:\n    for filename in sci_r1_files_to_download:\n        sci_r1_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_sci_r1_dir, Path(filename).name))\n    for filename in sci_r2_files_to_download:\n        sci_r2_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_sci_r2_dir, Path(filename).name))\n    for filename in ref_targ_files_to_download:\n        ref_targ_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_ref_targ_dir, Path(filename).name))\n    for filename in bg_sci_files_to_download:\n        bg_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_bg_sci_dir, Path(filename).name))\n    for filename in bg_ref_targ_files_to_download:\n        bg_ref_targ_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_bg_ref_targ_dir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":15},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"4.-Directory Setup"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-4-directory-setup","position":16},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"4.-Directory Setup"},"content":"\n\nSet up detailed paths to input/output stages here. We will set up individual stage1/ and stage2/ sub directories for each observation, but a single stage3/ directory for the combined \n\ncalwebb_coron3 output products.\n\n# Define output subdirectories to keep science data products organized\n# Sci Roll 1\nuncal_sci_r1_dir = os.path.join(sci_r1_dir, 'uncal') # uncal inputs go here\ndet1_sci_r1_dir = os.path.join(sci_r1_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_sci_r1_dir = os.path.join(sci_r1_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\n\n# Sci Roll 2\nuncal_sci_r2_dir = os.path.join(sci_r2_dir, 'uncal') # uncal inputs go here\ndet1_sci_r2_dir = os.path.join(sci_r2_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_sci_r2_dir = os.path.join(sci_r2_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\n\n# Define output subdirectories to keep PSF reference target data products organized\nuncal_ref_targ_dir = os.path.join(ref_targ_dir, 'uncal') # uncal inputs go here\ndet1_ref_targ_dir = os.path.join(ref_targ_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_ref_targ_dir = os.path.join(ref_targ_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\n\n# Define output subdirectories to keep background data products organized\n# Sci Bkg\nuncal_bg_sci_dir = os.path.join(bg_sci_dir, 'uncal') # uncal inputs go here\ndet1_bg_sci_dir = os.path.join(bg_sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_bg_sci_dir = os.path.join(bg_sci_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\n\n# Ref target Bkg\nuncal_bg_ref_targ_dir = os.path.join(bg_ref_targ_dir, 'uncal') # uncal inputs go here\ndet1_bg_ref_targ_dir = os.path.join(bg_ref_targ_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_bg_ref_targ_dir = os.path.join(bg_ref_targ_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\n\ncoron3_dir = os.path.join(basedir, 'stage3')\n\n# We need to check that the desired output directories exist, and if not create them\ndet1_dirs = [det1_sci_r1_dir, det1_sci_r2_dir, det1_ref_targ_dir, det1_bg_sci_dir, det1_bg_ref_targ_dir]\nimage2_dirs = [image2_sci_r1_dir, image2_sci_r2_dir, image2_ref_targ_dir, image2_bg_sci_dir, image2_bg_ref_targ_dir]\n\nfor dir in det1_dirs:\n    if not os.path.exists(dir):\n        os.makedirs(dir)\nfor dir in image2_dirs:\n    if not os.path.exists(dir):\n        os.makedirs(dir)\nif not os.path.exists(coron3_dir):\n    os.makedirs(coron3_dir)\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-4-directory-setup","position":17},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-5-detector1-pipeline","position":18},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"content":"\n\nIn this section, we process our uncalibrated data through the calwebb_detector1 pipeline to create Stage 1 data products. For coronagraphic exposures, these data products include a *_rate.fits file (a 2D countrate product, based on averaging over all integrations in the exposure), but specifically also a *_rateints.fits file, a 3D countrate product, that contains the individual results of each integration, wherein 2D countrate images for each integration are stacked along the 3rd axis of the data cubes (ncols x nrows x nints). These data products have units of DN/s.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_detector1\n\nBy default, all steps in the calwebb_detector1 are run for MIRI except: the \n\nipc and \n\ncharge_migration steps. There are also several steps performed for MIRI data that are not performed for other instruments. These include: \n\nemicorr, \n\nfirstframe, \n\nlastframe, \n\nreset and \n\nrscd.\n\nTo override certain steps and reference files, use the examples provided below. E.g., turn on detection of cosmic ray showers.\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'], det1dict['saturation'] = {}, {}, {}, {}\ndet1dict['firstframe'], det1dict['lastframe'], det1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}, {}, {}\ndet1dict['dark_current'], det1dict['refpix'], det1dict['jump'], det1dict['ramp_fit'], det1dict['gain_scale'] = {}, {}, {}, {}, {}\ndet1dict['clean_flicker_noise'] = {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n# skipping refpix step\n#det1dict['refpix']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n\n# Turn on multi-core processing (off by default).  Choose what fraction of cores to use (quarter, half, or all)\ndet1dict['jump']['maximum_cores'] = 'half' \n\n# Save the frame-averaged dark data created during the dark current subtraction step\n#det1dict['dark_current']['dark_output'] = 'dark.fits'  # Frame-averaged dark \n\n# Turn on detection of cosmic ray showers (off by default)\n#det1dict['jump']['find_showers'] = True\n\n\n\nBelow an example of how to insert custom pipeline steps using the pre-hook/post-hook framework.\n\nFor more information see \n\nTips and Trick for working with the JWST Pipeline\n\n\n# Define a new step called XplyStep that multiplies everything by 1.0\n# I.e., it does nothing, but could be changed to do something more interesting.\nclass XplyStep(Step):\n    spec = '''\n    '''\n    class_alias = 'xply'\n\n    def process(self, input_data):\n        with datamodels.open(input_data) as model:\n            result = model.copy()\n        sci = result.data\n        sci = sci * 1.0\n        result.data = sci\n        self.log.info('Multiplied everything by one in custom step!')\n        return result\n\n\n# And here we'll insert it into our pipeline dictionary to be run at the end right after the gain_scale step\ndet1dict['gain_scale']['post_hooks'] = [XplyStep]\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-5-detector1-pipeline","position":19},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Calibrating Science Files","lvl2":"5.-Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#calibrating-science-files","position":20},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Calibrating Science Files","lvl2":"5.-Detector1 Pipeline"},"content":"Look for input science files and run calwebb_detector1 pipeline using the call method. For the demo example there should be 2 input science files, one for the observation at roll 1 (Obs 8) and one for the observation at roll 2 (Obs 9).\n\nuncal_sci_r1_dir\n\n\n\n# Look for input files of the form *uncal.fits from the science observation\nsstring1 = os.path.join(uncal_sci_r1_dir, 'jw*mirimage*uncal.fits')\nsstring2 = os.path.join(uncal_sci_r2_dir, 'jw*mirimage*uncal.fits')\n\nuncal_sci_r1_files = sorted(glob.glob(sstring1))\nuncal_sci_r2_files = sorted(glob.glob(sstring2))\n\n# Check that these are the correct mask/filter to use\nuncal_sci_r1_files = select_mask_filter_files(uncal_sci_r1_files, use_mask, use_filter)\nuncal_sci_r2_files = select_mask_filter_files(uncal_sci_r2_files, use_mask, use_filter)\n\nprint('Found ' + str((len(uncal_sci_r1_files) + len(uncal_sci_r2_files))) + ' science input files')\n\n\n\n# Run the pipeline on these input files by a simple loop over files using\n# our custom parameter dictionary\nif dodet1:\n    for file in uncal_sci_r1_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_sci_r1_dir)\n\n    for file in uncal_sci_r2_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_sci_r2_dir)\nelse:\n    print('Skipping Detector1 processing for SCI data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#calibrating-science-files","position":21},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Calibrating PSF Reference Target Files","lvl2":"5.-Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#calibrating-psf-reference-target-files","position":22},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Calibrating PSF Reference Target Files","lvl2":"5.-Detector1 Pipeline"},"content":"Look for input PSF Reference Target files. For the demo example there should be 9 files in total, one for each exposure of the PSF reference target taken in the 9-point dither pattern.\n\n# Now let's look for input files of the form *uncal.fits from the background\n# observations\nsstring = os.path.join(uncal_ref_targ_dir, 'jw*mirimage*uncal.fits')\nuncal_ref_targ_files = sorted(glob.glob(sstring))\n\n# Check that these are the band/channel to use\nuncal_ref_targ_files = select_mask_filter_files(uncal_ref_targ_files, use_mask, use_filter)\n\nprint('Found ' + str(len(uncal_ref_targ_files)) + ' PSF reference input files')\n\n\n\nRuns calwebb_detector1 module on the reference target files using the same custom parameter dictionary.\n\n# Run the pipeline on these input files by a simple loop over files using\n# our custom parameter dictionary\nif dodet1:\n    for file in uncal_ref_targ_files:\n        print(file)\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_ref_targ_dir)\nelse:\n    print('Skipping Detector1 processing for PSF reference data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#calibrating-psf-reference-target-files","position":23},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Calibrating Background Files","lvl2":"5.-Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#calibrating-background-files","position":24},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Calibrating Background Files","lvl2":"5.-Detector1 Pipeline"},"content":"Look for input background files and run calwebb_detector1\npipeline using the call method.\n\nFor the demo example there should be 4 background files in total: two exposures of the background target associated with the science target (taken in the 2-point dither) and two exposures of the background target associated with the PSF reference target (taken in the 2-point dither).\n\n# Look for input files of the form *uncal.fits from the background\n# observations\nsstring1 = os.path.join(uncal_bg_sci_dir, 'jw*mirimage*uncal.fits')\nsstring2 = os.path.join(uncal_bg_ref_targ_dir, 'jw*mirimage*uncal.fits')\n\nuncal_bg_sci_files = sorted(glob.glob(sstring1))\nuncal_bg_ref_targ_files = sorted(glob.glob(sstring2))\n\n# Check that these are the filter to use\nuncal_bg_sci_files = select_mask_filter_files(uncal_bg_sci_files, use_mask, use_filter)\nuncal_bg_ref_targ_files = select_mask_filter_files(uncal_bg_ref_targ_files, use_mask, use_filter)\n\nprint('Found ' + str((len(uncal_bg_sci_files) + len(uncal_bg_ref_targ_files))) + ' background input files')\n\n\n\n# Run the pipeline on these input files by a simple loop over files using\n# our custom parameter dictionary\nif dodet1bg:\n    for file in uncal_bg_sci_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_bg_sci_dir)\n    for file in uncal_bg_ref_targ_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_bg_ref_targ_dir)\nelse:\n    print('Skipping Detector1 processing for BG data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#calibrating-background-files","position":25},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"6.-Image2 Pipeline"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-6-image2-pipeline","position":26},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"6.-Image2 Pipeline"},"content":"\n\nIn this section we process our 3D countrate (rateints) products from\nStage 1 (calwebb_detector1) through the Image2 (calwebb_image2) pipeline\nin order to produce Stage 2\ndata products (i.e., 3D calibrated calints and 3D background-subtracted bsubints data). These data products have units of MJy/sr.\n\nIn this pipeline processing stage, the \n\nbackground subtraction\nstep is performed (if the data has a dedicated background defined), the \n\nworld coordinate system (WCS)\nis assigned, the data is \n\nflat fielded,\nand a \n\nphotometric calibration\nis applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n\nThe \n\nresampling step is performed, to create resampled images of each dither position, but this is only a quick-look product. The resampling step occurs during the Coron3 stage by default. While the resampling step is done in the Image2 stage, the data quality from the Coron3 stage will be better since the bad pixels, which adversely affect both the centroids and photometry in individual images, will be mostly removed.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_image2\n\ntime_image2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nimage2dict = {}\nimage2dict['assign_wcs'], image2dict['bkg_subtract'], image2dict['flat_field'], image2dict['photom'], image2dict['resample'] = {}, {}, {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image2dict['resample']['skip'] = False\n#image2dict['bkg_subtract']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf'  # Imager filter offsets (ASDF file)\n#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf'  # Spectral distortion (ASDF file)\n#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf'  # Wavelength channel mapping (ASDF file)\n#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n#image2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array\n\n# Save the combined background used for subtraction\nimage2dict['bkg_subtract']['save_combined_background'] = True \n\n# Relevant step-specific arguments for background subtraction\n#image2dict['bkg_subtract']['sigma'] = 3.0  # Number of standard deviations to use for sigma-clipping\n#image2dict['bkg_subtract']['maxiters'] = None  # Number of clipping iterations to perform when combining multiple background images. If None, will clip until convergence is achieved\n\n# Relevant step-specific arguments for flat field\n#image2dict['flat_field']['user_supplied_flat'] = 'myfile.fits'  # Path to user-supplied Flat-field image \n#image2dict['flat_field']['inverse'] = False  # Whether to inverse the math operations used to apply the Flat-field (i.e. multiply instead of divide)\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf'  # Imager filter offsets (ASDF file)\n#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n#image2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array\n\n\n\nDefine a function to create association files for Stage 2. This will enable use of the background subtraction, if chosen above.\n\nNote that the background will not be applied properly to all files if more than *one* SCI file is included in the association.\n\ndef writel2asn(onescifile, bgfiles, asnfile, prodname):\n    # Define the basic association of science files\n    asn = afl.asn_from_list([onescifile], rule=DMSLevel2bBase, product_name=prodname)  # Wrap in array since input was single exposure\n\n    #Coron/filter configuration for this sci file\n    with fits.open(onescifile) as hdu:\n        hdu.verify()\n        hdr = hdu[0].header\n        this_mask, this_filter = hdr['CORONMSK'], hdr['FILTER']\n\n    # Find which background files are appropriate to this mask/filter and add to association\n    for file in bgfiles:\n        hdu.verify()\n        hdr = hdu[0].header\n        if hdr['FILTER'] == this_filter and hdr['CORONMSK'] == this_mask:\n            asn['products'][0]['members'].append({'expname': file, 'exptype': 'background'})\n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nFind and sort all of the input files for the selected filter and coronagraphic mask, ensuring use of absolute paths.\n\nThe input files should be rateints.fits products and for the demo example there should be a total of 2 files corresponding to the science target; 9 files corresponding to the reference target; 2 files corresponding to the science background target and 2 files corresponding to the reference background target.\n\n# Identify Science Files \n# Roll 1\nsstring = os.path.join(det1_sci_r1_dir, 'jw*mirimage*rateints.fits')  # Use files from the detector1 output folder\nsci_r1_files = sorted(glob.glob(sstring))\n\n# Check that these are the mask/filter to use\nsci_r1_files = select_mask_filter_files(sci_r1_files, use_mask, use_filter)\n\n# Roll 2\nsstring = os.path.join(det1_sci_r2_dir, 'jw*mirimage*rateints.fits')  # Use files from the detector1 output folder\nsci_r2_files = sorted(glob.glob(sstring))\nsci_r2_files = select_mask_filter_files(sci_r2_files, use_mask, use_filter)\n\n# Identify PSF Ref Target Files\nsstring = os.path.join(det1_ref_targ_dir, 'jw*mirimage*rateints.fits')\nref_targ_files = sorted(glob.glob(sstring))\nref_targ_files = select_mask_filter_files(ref_targ_files, use_mask, use_filter)\n\n# Background Files\n# Sci Bkg\nsstring = os.path.join(det1_bg_sci_dir, 'jw*mirimage*rateints.fits')\nbg_sci_files = sorted(glob.glob(sstring))\nbg_sci_files = select_mask_filter_files(bg_sci_files, use_mask, use_filter)\n\n# Ref target Bkg \nsstring = os.path.join(det1_bg_ref_targ_dir, 'jw*mirimage*rateints.fits')\nbg_ref_targ_files = sorted(glob.glob(sstring))\nbg_ref_targ_files = select_mask_filter_files(bg_ref_targ_files, use_mask, use_filter)\n\nprint('Found ' + str(len(sci_r1_files) + len(sci_r2_files)) + ' science files')\nprint('Found ' + str(len(ref_targ_files)) + ' reference files')\nprint('Found ' + str(len(bg_sci_files)) + ' science background files')\nprint('Found ' + str(len(bg_ref_targ_files)) + ' reference background files')\n\n\n\nStep through each of the science files for both rolls. First creates the association file using relevant associated backgrounds and then runs calwebb_image2 processing.\n\nif doimage2:\n    # Science Roll 1\n    # Generate a proper background-subtracting association file\n    for file in sci_r1_files:\n        asnfile = os.path.join(image2_sci_r1_dir, 'l2asn.json')\n        writel2asn(file, bg_sci_files, asnfile, 'Level2')\n        Image2Pipeline.call(asnfile, steps=image2dict, save_bsub=True, save_results=True, output_dir=image2_sci_r1_dir)\n\n    # Science Roll 2\n    # Generate a proper background-subtracting association file\n    for file in sci_r2_files:\n        asnfile = os.path.join(image2_sci_r2_dir, 'l2asn.json')\n        writel2asn(file, bg_sci_files, asnfile, 'Level2')\n        Image2Pipeline.call(asnfile, steps=image2dict, save_bsub=True, save_results=True, output_dir=image2_sci_r2_dir)\nelse:\n    print('Skipping Image2 processing for SCI data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep through each of the reference target files. First creates the association file using relevant associated backgrounds and then runs calwebb_image2 processing.\n\nif doimage2:\n    for file in ref_targ_files:\n        # Extract the dither number to use in asn filename\n        match = re.compile(r'(\\d{5})_mirimage').search(file)\n\n        # Generate a proper background-subtracting association file\n        asnfile = os.path.join(image2_ref_targ_dir, match.group(1) + '_l2asn.json')\n        writel2asn(file, bg_ref_targ_files, asnfile, 'Level2')\n        Image2Pipeline.call(asnfile, steps=image2dict, save_bsub=True, save_results=True, output_dir=image2_ref_targ_dir)  \nelse:\n    print('Skipping Image2 processing for PSF REF target data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Image2: {time1 - time_image2} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-6-image2-pipeline","position":27},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"7.-Coron3 Pipeline"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-7-coron3-pipeline","position":28},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"7.-Coron3 Pipeline"},"content":"\n\nIn this section, we’ll run the Coron3 (calwebb_coron3) pipeline on the calibrated MIRI coronagraphic exposures to produce PSF-subtracted, resampled, combined images of the source object. The input to calwebb_coron3 must be in the form of an association file that lists one or more exposures of a science target and one or more reference PSF targets. The individual target and reference PSF exposures should be in the form of 3D photometrically calibrated (_calints) products from calwebb_image2 processing. Each pipeline step will loop over the 3D stack of per-integration images contained in each exposure. The relevant steps are:\n\noutlier_detection: CR-flag all PSF and science target exposures\n\nstack_refs: Reference PSF stacking\n\nalign_refs: Reference PSF alignment\n\nklip: PSF subtraction with the KLIP algorithm\n\nresample: Image resampling and World Coordinate System registration\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_coron3\n\ntime_coron3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Coron3 pipeline should be configured\n\n# Boilerplate dictionary setup\ncoron3dict = {}\ncoron3dict['outlier_detection'], coron3dict['stack_refs'], coron3dict['align_refs'] = {}, {}, {}\ncoron3dict['klip'], coron3dict['resample'] = {}, {}\n\n# Set the maximum number of KL transform rows to keep when computing the PSF fit to the target.\ncoron3dict['klip']['truncate'] = 25   # The maximum number of KL modes to use.\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#coron3dict['align_refs']['override_psfmask'] = 'myfile.fits'  # The PSFMASK reference file\n\n# Options for adjusting performance for the outlier detection step\n#coron3dict['outlier_detection']['kernel_size'] = '7 7'  # Dial this to adjust the detector kernel size\n#coron3dict['outlier_detection']['threshold_percent'] = 99.8  # Dial this to be more/less aggressive in outlier flagging (values closer to 100% are less aggressive)\n\n# Options for adjusting the resample step\n#coron3dict['resample']['pixfrac'] = 1.0  # Fraction by which input pixels are “shrunk” before being drizzled onto the output image grid\n#coron3dict['resample']['kernel'] = 'square'  # Kernel form used to distribute flux onto the output image\n#coron3dict['resample']['fillval'] = 'INDEF'  # Value to assign to output pixels that have zero weight or do not receive any flux from any input pixels during drizzling\n#coron3dict['resample']['weight_type'] = 'ivm'  # Weighting type for each input image.\n#coron3dict['resample']['output_shape'] = None  \n#coron3dict['resample']['crpix'] = None\n#coron3dict['resample']['crval'] = None\n#coron3dict['resample']['rotation'] = None\n#coron3dict['resample']['pixel_scale_ratio'] = 1.0\n#coron3dict['resample']['pixel_scale'] = None\n#coron3dict['resample']['output_wcs'] = ''\n#coron3dict['resample']['single'] = False\n#coron3dict['resample']['blendheaders'] = True \n\n\n\nDefine a function to create association files for Stage 3. It creates an association from a list of science exposures and a list of PSF reference exposures.\n\ndef writel3asn(scifiles, ref_targ_files, asnfile, prodname):\n    \"\"\"Create an association from a list of science exposures and a list of PSF reference exposures, \n    intended for calwebb_coron3 processing.\n\n    Parameters\n    ----------\n    scifiles : list\n        List of science files\n    ref_targ_files : list\n        List of reference files\n    asnfile : str\n        The path to the association file.\n    \"\"\"\n    # Define the basic association of science files\n    asn = afl.asn_from_list(scifiles, rule=DMS_Level3_Base, product_name=prodname)\n\n    # Add reference target files to the association\n    nref = len(ref_targ_files)\n    for ii in range(0, nref):\n        asn['products'][0]['members'].append({'expname': ref_targ_files[ii], 'exptype': 'psf'})\n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths. For the demo example there should be 2 science files and 9 PSF reference files.\n\n# Science Files need the calints.fits files\nsstring = os.path.join(image2_sci_r1_dir, 'jw*mirimage*calints.fits')\nsstring2 = os.path.join(image2_sci_r2_dir, 'jw*mirimage*calints.fits')\nr1_calfiles = sorted(glob.glob(sstring))\nr2_calfiles = sorted(glob.glob(sstring2))\ncalfiles = r1_calfiles + r2_calfiles\n\n# Check that these are the mask/filter to use\ncalfiles = select_mask_filter_files(calfiles, use_mask, use_filter)\n\n# Reference target Files need the calints.fits files\nsstring = os.path.join(image2_ref_targ_dir, 'jw*mirimage*calints.fits')\nref_targ_files = sorted(glob.glob(sstring))\n\n# Check that these are the mask/filter to use\nref_targ_files = select_mask_filter_files(ref_targ_files, use_mask, use_filter)\n\nprint('Found ' + str(len(calfiles)) + ' science files to process')\nprint('Found ' + str(len(ref_targ_files)) + ' reference PSF files to process')\n\n\n\nMake an association file that includes all of the Science and Reference files and run Coron3\n\nif docoron3:\n    asnfile = os.path.join(coron3_dir, 'l3asn.json')\n    writel3asn(calfiles, ref_targ_files, asnfile, 'Level 3')\n    Coron3Pipeline.call(asnfile, steps=coron3dict, save_results=True, output_dir=coron3_dir)\nelse:\n    print('Skipping coron3 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRun calwebb_image3 using the call method.\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for coron3: {time1 - time_coron3} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-7-coron3-pipeline","position":29},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"8.-Examine the output"},"type":"lvl2","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-8-examine-the-output","position":30},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl2":"8.-Examine the output"},"content":"\n\nHere we’ll plot the data to see what our source looks like.\n\n# Stage 3 output files\n\n# Individual exposures\nsstring = os.path.join(coron3_dir, 'jw*psfsub.fits')\npsfsubfiles = sorted(glob.glob(sstring))\nnpsfsub = len(psfsubfiles)\n\n# Combined exposure\nsstring = os.path.join(coron3_dir, '*i2d.fits')\ni2dfiles = sorted(glob.glob(sstring))\n\n\n\nif npsfsub == 1:\n    imgs = {'roll1': datamodels.open(psfsubfiles[0]).data.copy(),\n            'combo': datamodels.open(i2dfiles[0]).data.copy()}\nelse:\n    imgs = {'roll1': datamodels.open(psfsubfiles[0]).data.copy(),\n            'roll2': datamodels.open(psfsubfiles[1]).data.copy(),\n            'combo': datamodels.open(i2dfiles[0]).data.copy()}\n\n\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 8))\nvmin, vmax = np.nanquantile(np.concatenate(list([i.ravel() for i in imgs.values()])), [0.05, 0.95])\nfor i, roll in enumerate(imgs.keys()):\n    img = imgs[roll]\n    while img.ndim > 2:\n        img = np.nanmean(img, axis=0)\n    ax = axes[i]\n    ax.set_title(roll)\n    ax.imshow(img, vmin=vmin, vmax=vmax)\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#id-8-examine-the-output","position":31},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Overlay sky coordinates","lvl2":"8.-Examine the output"},"type":"lvl3","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#overlay-sky-coordinates","position":32},{"hierarchy":{"lvl1":"MIRI Conagraphy Pipeline Notebook","lvl3":"Overlay sky coordinates","lvl2":"8.-Examine the output"},"content":"Overlay the RA and Dec grid over the combined rolls\n\nwith fits.open(i2dfiles[0]) as f:\n    wcs = WCS(f[1].header)\n\n\n\n# The star coordinates at the time of observation are in the header\nexp_file = uncal_sci_r1_files[0]\ntarg_ra = fits.getval(exp_file, 'TARG_RA', 0)\ntarg_dec = fits.getval(exp_file, 'TARG_DEC', 0)\nstarcoord = SkyCoord(targ_ra, targ_dec, unit='deg', frame='icrs')\n\n\n\nfig, ax = plt.subplots(1, 1, subplot_kw={'projection': wcs})\nvmin, vmax = np.nanquantile(imgs['combo'], [0.01, 0.99])\nax.imshow(imgs['combo'], vmin=vmin, vmax=vmax)\nax.scatter(*wcs.world_to_pixel(starcoord),\n           marker='x', s=100, c='w')\nax.grid(True)\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/coronagraphy/jwpipenb-miri-coron#overlay-sky-coordinates","position":33},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso","position":0},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso","position":1},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#miri-imaging-tso-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook"},"content":"Authors: Ian Wong; MIRI branch\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing generic Mid-Infrared Instrument\n(MIRI) Imaging time series observations (TSO) data through all\nthree James Webb Space Telescope (JWST) pipeline stages.  The data are assumed\nto be located in the observation directory located in the path set up below.\nIt should not be necessary to edit any cells other than in the\n\n\nConfiguration section unless modifying the standard\npipeline processing options.\n\nA significant portion of the data processing workflow for Imaging TSOs is identical to the methods used to process (non-TSO) Imaging observations, and much of this notebook mirrors the corresponding steps shown in the general MIRI Imaging notebook.\n\nData:\nThis example is set up to use observations of a secondary eclipse event of LHS-1478b, which were obtained as part of Cycle 1 General Observers Proposal ID (PID) 3730 Observation 13 (PI: H. Diamond-Lowe). A continuous series of 964 integrations of the target was collected with the F1500W filter. No dithering was carried out, as is standard practice for Imaging TSOs. The SUB256 subarray readout was used. The example uncalibrated data will be downloaded automatically unless disabled (i.e., to run with user-supplied local files instead).\n\nMost Imaging TSO programs do not have dedicated background observations, with background flux subtraction handled using pixels near the target in the science observations. This version of the notebook does not accommodate cases where dedicated background subtraction is needed. Consult the general MIRI Imaging notebook for a detailed implementation of dedicated background exposures.\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements. Any \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nFeb 2 2025: Notebook created.\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes)\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#miri-imaging-tso-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#table-of-contents","position":4},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup (ignore if not using demo data)\n\nDirectory Setup\n\nDetector1 Pipeline\n\nImage2 Pipeline\n\nTso3 Pipeline\n\nVisualize the photometric light curve\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#table-of-contents","position":5},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-1-configuration","position":6},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"1. Configuration"},"content":"","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-1-configuration","position":7},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Install dependencies","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#install-dependencies","position":8},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Install dependencies","lvl2":"1. Configuration"},"content":"To make sure that the pipeline version is compatabile with this notebook and the required dependencies and packages are installed,\nit is recommended that users create a new dedicated conda environment and install the provided\nrequirements.txt file before starting this notebook: conda create -n lrs_demo python=3.11\nconda activate lrs_demo\npip install -r requirements.txt","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#install-dependencies","position":9},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Set run parameters","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#set-run-parameters","position":10},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Set run parameters","lvl2":"1. Configuration"},"content":"Set basic parameters to use with the notebook. These will affect\nwhat observation is used, where the uncalibrated data are located (if already on disk), which\npipeline modules to run on the data, and whether background subtraction is carried out. The list of parameters are:\n\ndemo_mode\n\ndirectory with data\n\npipeline steps\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this mode, this\nnotebook will download the example data from the\nBarbara A. Mikulski Archive for Space Telescopes (\n\nMAST) and process them through the pipeline.\nAll input and output data will be stored in the local directory unless modified\nin \n\nSection 3 below.\n\nSet demo_mode = False to process user-specified data that have already\nbeen downloaded and provide the location of the data.\n\n# Set parameters for demo_mode and processing steps.\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    basedir = os.path.join(os.getcwd(), '')\n\n    # Point to where science observation data are stored.\n    # Assumes uncalibrated data in sci_dir/uncal/, with the results stored in stage1,\n    # stage2, stage3 directories\n    sci_dir = os.path.join(basedir, 'imaging_demo_data/PID03730Obs013/')\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndo_det1 = True  # calwebb_detector1\ndo_image2 = True  # calwebb_image2\ndo_tso3 = True  # calwebb_tso3\ndo_viz = True  # Visualize calwebb_tso3 results\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#set-run-parameters","position":11},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#set-crds-context-and-server","position":12},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need\nto configure our environment. This includes defining a CRDS cache\ndirectory in which to keep the reference files that will be used by the\ncalibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set\nalready, it will be set to create one in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#%env CRDS_CONTEXT jwst_1293.pmap\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path in use\nprint(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\nprint(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#set-crds-context-and-server","position":13},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-2-package-imports","position":14},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"2. Package Imports"},"content":"Automatically import necessary Python packages for use in the data processing and visualization.\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\nfrom pathlib import Path\n\n# Numpy for doing calculations\nimport numpy as np\n\n# -----------------------Astropy Imports-----------------------------------\n# Astropy utilities for opening FITS and ASCII files and downloading demo files\nfrom astropy.io import ascii\n\n# -----------------------Astrquery Imports-----------------------------------\n# Utilities to download data \nfrom astroquery.mast import Observations\n\n# -----------------------Plotting Imports----------------------------------\n# Matplotlib for making plots\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n# ----------------------JWST calibration pipeline--------------------------\nimport jwst\nimport crds\n\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Image2Pipeline\nfrom jwst.pipeline import Tso3Pipeline\n\n# JWST pipeline utilities\nfrom jwst import datamodels\n#from jwst.datamodels import ImageModel\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files\n#from jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\n# Echo pipeline version and CRDS context in use\nprint(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\nprint(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")\n\n\n\n\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-2-package-imports","position":15},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":16},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"If running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    program = '03730'\n    sci_obs = \"013\"\n    basedir = os.path.join('.', 'imaging_demo_data')\n    sci_dir = os.path.join(basedir, 'PID' + program + 'Obs' + sci_obs)\n    uncal_dir = os.path.join(sci_dir, 'uncal')\n\n    # Ensure filepaths for input data exists\n    os.makedirs(uncal_dir, exist_ok=True)\n\n\n\nIdentify list of uncalibrated files associated with the observations.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/IMAGE\"], provenance_name=[\"CALJWST\"], obs_id=['jw' + program + sci_obs + '*'])\n\n\n\n# Turn the list of observations into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE',\n                           'productSubGroupDescription': 'UNCAL',\n                           'calib_level': [1]}}\n\n    # Science files\n    files_to_download = []\n    # Loop over visits identifying uncalibrated files that are associated with them\n    for exposure in (obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            files_to_download.extend(filtered_products['dataURI'])\n\n    print(\"Number of files selected for downloading: \", len(files_to_download))\n\n\n\nDue to data file size constraints, long TSOs have their exposures broken up into multiple segment files. In this case, there should be a total of 5 segments, which together comprise the full duration of the time series observation.\n\nNow, download all the uncal files and place them into the appropriate\ndirectories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\nif demo_mode:\n    for filename in files_to_download:\n        obs_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_dir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":17},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-4-directory-setup","position":18},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"Set up detailed paths to input/output stages here. When running this notebook outside of demo mode, the uncalibrated pipeline input files must be placed into the appropriate directories before proceeding to the JWST pipeline processing.\n\n# Define output subdirectories to keep the data products organized\nuncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\ntso3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_tso3 pipeline outputs will go here\n\n# Create desired output directories, if needed\nos.makedirs(det1_dir, exist_ok=True)\nos.makedirs(image2_dir, exist_ok=True)\nos.makedirs(tso3_dir, exist_ok=True)\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-4-directory-setup","position":19},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-5-detector1-pipeline","position":20},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"content":"Run the datasets through the\n\n\nDetector1\nstage of the pipeline to apply detector level calibrations and create a\ncountrate data product where slopes are fitted to the integration ramps.\nThe *_rate.fits products are 2D countrate images, averaged over all\nintegrations within each segment. Meanwhile, 3D countrate data stacks containing an image for each integration (*_rateints.fits files) are also\ncreated, which will be used in the subsequent stage to preserve the temporal information in the exposure series.\n\nWhen processing MIRI Imaging TSOs, the Detector1 pipeline skips a few pipeline steps by default that would otherwise be run for non-TSO data. These are rscd and firstframe, which both essentially instruct the pipeline to ignore initial frames within each ramp. The motivation behind the different settings here is that most TSOs have short ramps, and ignoring too many frames can leave too little of the ramp to adequately produce a ramp slope fit. See \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_detector1 for a detailed overview of the various pipeline steps that comprise Detector1.\n\nAs of CRDS context jwst_1201.pmap and later, the\njump step\nin the Detector1 pipeline allows for the removal of residuals associated\nwith \n\nshowers\nfor MIRI Imaging observations, but only for data taken with filters shortward (inclusive) of F1500W.\nSetting the find_showers parameter to True in the jump step activates this functionality. The default parameters for this correction are specified in the pars-jumpstep parameter reference files. Users may wish to alter parameters to optimize removal of\nshower residuals. Available parameters are discussed in the\n\n\nDetection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023).\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'] = {}, {}, {}\ndet1dict['saturation'], det1dict['firstframe'], det1dict['lastframe'] = {}, {}, {}\ndet1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}\ndet1dict['dark_current'], det1dict['refpix'], det1dict['jump'] = {}, {}, {}\ndet1dict['ramp_fit'], det1dict['gain_scale'], det1dict['clean_flicker_noise'] = {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped\n#det1dict['refpix']['skip'] = True\n#det1dict['jump']['find_showers'] = True  # Turn on detection of cosmic ray showers\n#det1dict['clean_flicker_noise']['skip'] = True  # Skipped by default\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits'  # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n\n# Turn on multi-core processing (off by default).  Choose what fraction of cores to use (quarter, half, or all)\ndet1dict['jump']['maximum_cores'] = 'half'\n\n# Alter parameters to optimize removal of shower residuals (example)\n#det1dict['jump']['after_jump_flag_dn1'] = X  # A floating point value in units of DN\n#det1dict['jump']['after_jump_flag_time1'] = x.x  # A floating point value in units of seconds\n\n\n\nGrab all of the uncalibrated files, which comprise the full time series observation.\n\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\nprint(uncal_files)\nprint('Found ' + str(len(uncal_files)) + ' input uncal files')\n\n\n\nRun the Detector1 pipeline on the selected uncalibrated data using the call method. For long TSOs with full array readouts, this process may take more than 10 minutes per file, particularly if find_showers = True.\n\n# Run the pipeline on the selected uncal files one by one with the custom parameter dictionary \nif do_det1:\n    for file in uncal_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_dir)\nelse:\n    print('Skipping Detector1 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime for Detector1: {time1 - time0:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-5-detector1-pipeline","position":21},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#exploring-the-data","position":22},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"content":"Identify the *_rateints.fits files and verify which pipeline steps were run and\nwhich calibration reference files were applied.\n\nThe header contains information about which calibration steps were\ncompleted and skipped and which reference files were used to process the\ndata.\n\nif do_det1:\n    # Find rate files\n    rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rateints.fits')))\n\n    # Read in file as datamodel\n    rate_f = datamodels.open(rate_files[0])\n\n    # Check which steps were run\n    rate_f.meta.cal_step.instance\n\n    # Check which reference files were used to calibrate the dataset:\n    rate_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#exploring-the-data","position":23},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-6-image2-pipeline","position":24},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"content":"In the \n\nImage2 stage of the pipeline,\nflat-fielded and flux-calibrated data products (*_calints.fits files) are created from the *_rateints.fits files produced by Detector1.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_image2 for a detailed overview of the various pipeline steps that comprise Image2.\n\nTo override certain steps and reference files, use the examples below.\n\ntime_image2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nimage2dict = {}\nimage2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\nimage2dict['photom'] = {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image2dict['photom']['skip'] = True \n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf'  # Imager filter offsets (ASDF file)\n#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf'  # Spectral distortion (ASDF file)\n#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf'  # Wavelength channel mapping (ASDF file)\n#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n#image2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array\n\n\n\nGrab the *rateints.fits files, ensuring the use of absolute paths.\n\n# Get rate files from the Detector1 output folder\nrate_files = sorted(glob.glob(os.path.join(det1_dir, '*rateints.fits')))\n\n# Use the absolute file paths\nfor ii in range(len(rate_files)):\n    rate_files[ii] = os.path.abspath(rate_files[ii])\nrate_files = np.array(rate_files)\n\n\n\nRun the files through the Image2 pipeline.\n\n# Run the pipeline on the selected rate files one by one with the custom parameter dictionary\nif do_image2:\n    for ii, file in enumerate(rate_files):\n        Image2Pipeline.call(file, steps=image2dict, save_results=True, output_dir=image2_dir)\n\nelse:\n    print('Skipping Image2 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-6-image2-pipeline","position":25},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"7. Tso3 Pipeline"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-7-tso3-pipeline","position":26},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"7. Tso3 Pipeline"},"content":"The Stage 3 pipeline for TSOs, \n\nTso3, is significantly simpler than the analogous processing stage for non-TSO data sets. First, an\n\n\nassociation file\nneeds to be created that contains all of the *_calints.fits files produced from Stage 2.\n\nBy default, the Tso3 pipeline performs the following steps on MIRI Imaging TSO data sets:\n\noutlier_detection flags any remaining cosmic rays, bad pixels, or other artifacts not already flagged during the Detector1 stage of the pipeline. For TSOs, a moving median filtering process is carried out that searches for outlier pixel values along the time axis. This method is designed to guard against the spurious flagging of true astrophysical variability in the target. The default rolling window width is 25 integrations, but that parameter can be adjusted in the user-specified dictionary below.\n\ntso_photometry does aperture photometry using a circular aperture centered on the target. The sky background is computed as the mean within a circular annulus. The output is a table (ASCII ecsv format) containing the time at the midpoint of each integration and the photometry values. The default extraction aperture and background annulus sizes are stored in the tsophot \n\nreference file. \n\nIMPORTANT NOTE: the position of the photometric aperture is determined by the world coordinate solution (WCS) in the header, which can be offset from the true position of the target due to pointing and/or target coordinate inaccuracies. It is recommended that users carry out their own photometric extraction using a computed centroid position for the target aperture.\n\nTo override certain steps and reference files, use the examples below.\n\ntime_tso3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Tso3 pipeline should be configured\n\n# Boilerplate dictionary setup\ntso3dict = {}\ntso3dict['outlier_detection'], tso3dict['tso_photometry'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#tso3dict['outlier_detection']['skip'] = True\n\n# Overrides for specific parameters in the step (examples)\n#tso3dict['outlier_detection']['rolling_window_width'] = 35\n\n\n\nCollect all of the Stage 2 *calints.fits files, ensuring the use of absolute paths.\n\n# Grab all the calints.fits files\ncal_files = sorted(glob.glob(os.path.join(image2_dir, '*calints.fits')))\nfor ii in range(0, len(cal_files)):\n    cal_files[ii] = os.path.abspath(cal_files[ii])\ncalfiles = np.array(cal_files)\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-7-tso3-pipeline","position":27},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Tso3 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#create-association-file","position":28},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Tso3 Pipeline"},"content":"An association file lists the exposures to be calibrated together in Stage 3\nof the JWST pipeline. The code below creates an\nassociation file from the *calints.fits files.\n\n# Create a Level 3 Association\nif do_tso3:\n    # Define the basic association of science files\n    asn = afl.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='Stage3')\n\n    # Write the association to a json file\n    asnfile = os.path.join(tso3_dir, 'stage3_asn.json')\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#create-association-file","position":29},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Run the Tso3 pipeline","lvl2":"7. Tso3 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#run-the-tso3-pipeline","position":30},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl3":"Run the Tso3 pipeline","lvl2":"7. Tso3 Pipeline"},"content":"In addition to the photometry file Stage3_phot.ecsv, the Tso3 pipeline produces outlier-masked calibrated image stacks *crfints.fits for each segment of integrations.\n\nif do_tso3:\n    Tso3Pipeline.call(asnfile, output_dir=tso3_dir, steps=tso3dict, save_results=True)\nelse:\n    print('Skipping Tso3 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image3: {time1 - time_tso3:0.0f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#run-the-tso3-pipeline","position":31},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"8. Visualize the photometric light curve"},"type":"lvl2","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-8-visualize-the-photometric-light-curve","position":32},{"hierarchy":{"lvl1":"MIRI Imaging TSO Pipeline Notebook","lvl2":"8. Visualize the photometric light curve"},"content":"Plot the extracted photometric light curve produced by the pipeline. For the demo mode example, note the handful of outliers that were not addressed by the Tso3 pipeline, as well as the systematic offset in flux level in the last segment of integrations.\n\nif do_viz:\n    # Read in photometry file\n    phot_file = os.path.join(tso3_dir, 'Stage3_phot.ecsv')\n    data = ascii.read(phot_file, comment='#', delimiter=' ')\n\n    # Make normal plots\n    %matplotlib inline\n    # Interactive plots\n    #%matplotlib notebook\n\n    # Plot result\n    rc('axes', linewidth=2)\n    fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=150)\n    ax.plot(data['MJD'], data['aperture_sum'], 'b.', ms=6)\n    plt.xlabel('MJD_UTC (d)')\n    plt.ylabel('Flux (Jy)')\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(os.path.join(tso3_dir, 'imaging_tso_example_lc.png'))\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging-tso/jwpipenb-miri-imaging-tso#id-8-visualize-the-photometric-light-curve","position":33},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging","position":0},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging","position":1},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#miri-imaging-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook"},"content":"Authors: M. Cracraft\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing generic Mid-Infrared Instrument\n(MIRI) Imaging data through all\nthree James Webb Space Telescope (JWST) pipeline stages.  Data is assumed\nto be located in one observation folder according to paths set up below.\nIt should not be necessary to edit any cells other than in the\n\n\nConfiguration section unless modifying the standard\npipeline processing options.\n\nData:\nThis example is set up to use an example dataset is from\n\n\nProgram ID\n1040 (PI: O. Detre, Co-I: A. Noriega-Crespo) which is an external flat commissioning program.\nThe MIRI imaging dataset uses a 5-step dither pattern. Example input data to use will be\ndownloaded automatically unless disabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the calibration pipeline version given above and uses the context associated with this version of the JWST Calibration Pipeline. Information about this an other contexts can be found in the JWST Calibration Reference Data System (CRDS) \n\nserver. If you use different pipeline\nversions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nSeptember 25, 2024: original notebook released\nNovember 22, 2024: Updates to workflow when skipping pipeline modules\nJanuary 16, 2025: Add handling for dedicated backgrounds, update to jwst 1.17.1\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes)\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#miri-imaging-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#table-of-contents","position":4},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup (ignore if not using demo data)\n\nDirectory Setup\n\nDetector 1 Pipeline\n\nImage2 Pipeline\n\nImage3 Pipeline\n\nVisualize the data\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#table-of-contents","position":5},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-1-configuration","position":6},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"1. Configuration"},"content":"\n\nSet basic configuration for running notebook.\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-1-configuration","position":7},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#install-dependencies-and-parameters","position":8},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"\n\nTo make sure that the pipeline version is compatabile with the steps\ndiscussed below and the required dependencies and packages are installed,\nyou can create a fresh conda environment and install the provided\nrequirements.txt file before starting this notebook: conda create -n miri_imaging_pipeline python=3.11\nconda activate miri_imaging_pipeline\npip install -r requirements.txt\n\nSet the basic parameters to use with this notebook. These will affect\nwhat data is used, where data is located (if already in disk), and\npipeline modules run in this data. The list of parameters are:\n\ndemo_mode\n\ndirectories with data\n\npipeline modules\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this\nmode this notebook will download example data from the Barbara A.\nMikulski Archive for Space Telescopes\n(\n\nMAST)\nand process it through the pipeline. This will all happen in a local\ndirectory unless modified in\n\n\nSection 3 below.\n\nSet demo_mode = False if you want to process your own data\nthat has already been downloaded and provide the location of the data.\n\n# Set parameters for demo_mode and processing steps.\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    user_home_dir = os.path.expanduser('~')\n\n    # Point to where science observation data are\n    # Assumes uncalibrated data in sci_dir/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    sci_dir = os.path.join(user_home_dir, 'FlightData/APT1040/data/Obs001/')\n    \n    # Point to where background observation data are\n    # Assumes uncalibrated data in bg_dir/uncal/ and results in stage1 directory\n    #bg_dir = os.path.join(user_home_dir, 'FlightData/APT1714/data/Obs02/')\n    bg_dir = '' # If no background observation, use an empty string\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndodet1 = True  # calwebb_detector1\ndoimage2 = True  # calwebb_image2\ndoimage3 = True  # calwebb_image3\ndoviz = True # Visualize calwebb_image3 results\n\n# Background processing (if present)\ndodet1bg = True  # calwebb_detector1\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#install-dependencies-and-parameters","position":9},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#set-crds-context-and-server","position":10},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need\nto configure our environment. This includes defining a CRDS cache\ndirectory in which to keep the reference files that will be used by the\ncalibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set\nalready, it will be set to create one in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#%env CRDS_CONTEXT jwst_1293.pmap\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path in use\nprint(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\nprint(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#set-crds-context-and-server","position":11},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-2-package-imports","position":12},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\nfrom pathlib import Path\n#import urllib.request\n\n# Numpy for doing calculations\nimport numpy as np\n\n# To display full ouptut of cell, not just the last result\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n# --------------------Astroquery Imports------------------------------\n# ASCII files, and downloading demo files\nfrom astroquery.mast import Observations\n\n# ----------------Matplotlib for visualizing images-------------------\nimport matplotlib.pyplot as plt\n\n# -------------------Astropy routines for visualizing detected sources----------\nfrom astropy.table import Table\nfrom astropy.io import fits\n\n# ----------------------JWST calibration pipeline------------------------\nimport jwst\nimport crds\n\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Image2Pipeline\nfrom jwst.pipeline import Image3Pipeline\n\n# JWST pipeline utilities\nfrom jwst import datamodels\nfrom jwst.datamodels import ImageModel\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\n# Echo pipeline version and CRDS context in use\nprint(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\nprint(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")\n\n\n\n\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-2-package-imports","position":13},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":14},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"\n\nIf running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nFor illustrative purposes, we focus on data taken through the MIRI\n\n\nF770W filter\nand start with uncalibrated data products. The files are named\njw01040001005_03103_0000n_miri_uncal.fits, where n refers to the\ndither step number which ranges from 1 - 5.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    print('Running in demonstration mode and will download example data from MAST!')\n    program = '01040'\n    sci_observtn = \"001\"\n    visit = \"005\"\n    data_dir = os.path.join('.', 'mir_im_demo_data')\n    download_dir = data_dir\n    sci_dir = os.path.join(data_dir, 'Obs' + sci_observtn)\n    uncal_dir = os.path.join(sci_dir, 'uncal')\n    bg_dir = ''\n\n    # Ensure filepaths for input data exist\n    if not os.path.exists(uncal_dir):\n        os.makedirs(uncal_dir)\n\n    # Create directory if it does not exist\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n\n\n\nIdentify list of science (SCI) uncalibrated files associated with visits.\n\nSelects only filter f770w data\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    # Science data\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/IMAGE\"],\n                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n                                                   filters=['F770W'],  # Data for Specific Filter\n                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n                                                   )\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE',\n                           'productSubGroupDescription': 'UNCAL',\n                           'calib_level': [1]}}\n\n    # Science files\n    sci_files_to_download = []\n\n    # Loop over visits identifying uncalibrated files that are associated\n    # with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files_to_download.extend(filtered_products['dataURI'])\n\n    # Download only the files in a single visit\n    sci_files_to_download = [match for match in sci_files_to_download if ('jw' + program + sci_observtn + visit) in match]\n    sci_files_to_download = sorted(sci_files_to_download)\n    print(f\"Science files selected for downloading: {len(sci_files_to_download)}\")\n\n\n\nDownload all the uncal files and place them into the appropriate\ndirectories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\nif demo_mode:\n    for filename in sci_files_to_download:\n        sci_manifest = Observations.download_file(filename,\n                                                  local_path=os.path.join(uncal_dir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":15},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-4-directory-setup","position":16},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"\n\nSet up detailed paths to input/output stages here.\n\n# Define output subdirectories to keep science data products organized\nuncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\nimage3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n\n# Output subdirectories to keep background data products organized\nuncal_bgdir = os.path.join(bg_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_bgdir = os.path.join(bg_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\n\n# We need to check that the desired output directories exist, and if not\n# create them\nif not os.path.exists(det1_dir):\n    os.makedirs(det1_dir)\nif not os.path.exists(image2_dir):\n    os.makedirs(image2_dir)\nif not os.path.exists(image3_dir):\n    os.makedirs(image3_dir)\n    \nif ((bg_dir != '') & (not os.path.exists(det1_bgdir))):\n    os.makedirs(det1_bgdir)\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-4-directory-setup","position":17},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-5-detector1-pipeline","position":18},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"content":"Run the datasets through the\n\n\nDetector1\nstage of the pipeline to apply detector level calibrations and create a\ncountrate data product where slopes are fitted to the integration ramps.\nThese *_rate.fits products are 2D (nrows x ncols), averaged over all\nintegrations. 3D countrate data products (*_rateints.fits) are also\ncreated (nintegrations x nrows x ncols) which have the fitted ramp slopes\nfor each integration.\n\nBy default, all steps in the Detector1 stage of the pipeline are run for\nMIRI except: the group_scale, ipc and the gain_scale steps.\n\nMIRI performs a few pipeline steps in calwebb_detector1 that are not performed for other instruments.\nThe \n\nemicorr step corrects\nfor known noise patterns in MIRI data. For certain subarrays, these noise patterns are clearly imprinted on\nthe data in the rate.fits files.\n\nThe \n\nfirstframe step flags the first frame in each integration as bad, if the number of groups per integration is greater than 3.\n\nThe \n\nlastframe step\nflags the last frame in each integration as bad, if the number of groups per integration is greater than 2.\n\nThe \n\nreset correction step\ncorrects for the reset anomaly effect. This effect is caused by the non-ideal behavior of the field effect\ntransistor (FET) upon resetting in the dark causing the initial frames in an integration to be offset\nfrom their expected values.\n\nThe \n\nrscd step reads a reference\nfile for each data file and determines how many frames at the start of a ramp should be flagged as bad. There are a\nnumber of nonlinearities at the start of MIRI ramps, and the flagging allows the more linear portion of the ramp to\nbe used for jump detection and ramp fitting, without using the initial, non-linear portion of the ramp. The number\nof groups flagged depend on filter and subarray.\n\nAs of CRDS context jwst_1201.pmap and later, the\n\n\njump step\nof the DETECTOR1 stage of the pipeline will remove residuals associated\nwith \n\nshowers\nfor the MIRI imaging mode, but only for data with filter F1500W and shorter. The default parameters for this correction,\nwhere find_showers set to True turns on the shower\nremoval algorithm, are specified in the pars-jumpstep parameter\nreference files. Users may wish to alter parameters to optimize removal of\nshower residuals. Available parameters are discussed in the\n\n\nDetection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023).\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'] = {}, {}, {}\ndet1dict['saturation'], det1dict['firstframe'], det1dict['lastframe'] = {}, {}, {}\ndet1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}\ndet1dict['dark_current'], det1dict['refpix'], det1dict['jump'] = {}, {}, {}\ndet1dict['ramp_fit'], det1dict['gain_scale'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped\n# skipping the refpix step\n#det1dict['refpix']['skip'] = True\n#det1dict['jump']['find_showers'] = False # Turn off detection of cosmic ray showers\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits'  # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n\n# Turn on multi-core processing (off by default).  Choose what fraction of cores to use (quarter, half, or all)\ndet1dict['jump']['maximum_cores'] = 'half'\n\n# Alter parameters to optimize removal of shower residuals (example)\n#det1dict['jump']['after_jump_flag_dn1'] = X  # A floating point value in units of DN\n#det1dict['jump']['after_jump_flag_time1'] = x.x # A floating point value in units of seconds\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-5-detector1-pipeline","position":19},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Calibrating Science Files","lvl2":"5. Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#calibrating-science-files","position":20},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Calibrating Science Files","lvl2":"5. Detector1 Pipeline"},"content":"Look for input science files and run calwebb_detector1 pipeline using the call method.\n\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\nuncal_bgfiles = sorted(glob.glob(os.path.join(uncal_bgdir, '*_uncal.fits')))\n\nprint('Found ' + str(len(uncal_files)) + ' science input files')\nprint('Found ' + str(len(uncal_bgfiles)) + ' background input files')\n\n\n\nLook at the first file to determine exposure parameters and practice using\nJWST datamodels¶\n\nif dodet1:\n    # print file name\n    print(uncal_files[0])\n\n    # Open file as JWST datamodel\n    examine = datamodels.open(uncal_files[0])\n\n    # Print out exposure info\n    print(f\"Instrument: {examine.meta.instrument.name}\")\n    print(f\"Filter: {examine.meta.instrument.filter}\")\n    print(f\"Number of integrations: {examine.meta.exposure.nints}\")\n    print(f\"Number of groups: {examine.meta.exposure.ngroups}\")\n    print(f\"Readout pattern: {examine.meta.exposure.readpatt}\")\n    print(f\"Dither position number: {examine.meta.dither.position_number}\")\n    print(\"\\n\")\n\n\n\n\n\nFrom the above, we confirm that the demo data file is for the MIRI instrument\nusing the F770W filter in the \n\nFilter Wheel. This observation uses\nthe MIRI \n\nreadout pattern FASTR1,\n6 groups per integration, and 1 integration per exposure. This data file\nis the 1st dither position in this exposure sequence. For more information\nabout how JWST exposures are defined by up-the-ramp sampling, see the\n\n\nUnderstanding Exposure Times JDox article.\n\nThis metadata will be the same for all exposures in this observation other\nthan the dither position number.\n\n# Run Detector1 stage of pipeline, specifying:\n# output directory to save *_rate.fits files\n# save_results flag set to True so the rate files are saved\n\nif dodet1:\n    for uncal in uncal_files:\n        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_dir, steps=det1dict, save_results=True,)\nelse:\n    print('Skipping Detector1 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#calibrating-science-files","position":21},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Calibrating Background Files","lvl2":"5. Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#calibrating-background-files","position":22},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Calibrating Background Files","lvl2":"5. Detector1 Pipeline"},"content":"Look for input background files and run calwebb_detector1\npipeline using the call method.\n\n# Run Detector1 stage of pipeline on any background files\n\nif dodet1bg:\n    for uncal in uncal_bgfiles:\n        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_bgdir, steps=det1dict, save_results=True,)\nelse:\n    print('Skipping Detector1 BG processing')\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime for Detector1: {time1 - time0:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#calibrating-background-files","position":23},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#exploring-the-data","position":24},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"content":"Identify *_rate.fits files and verify which pipeline steps were run and\nwhich calibration reference files were applied.\n\nThe header contains information about which calibration steps were\ncompleted and skipped and which reference files were used to process the\ndata.\n\nif dodet1:\n    # find rate files\n    rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rate.fits')))\n\n    # Read in file as datamodel\n    rate_f = datamodels.open(rate_files[0])\n\n    # Check which steps were run\n    rate_f.meta.cal_step.instance\n\n    # Check which reference files were used to calibrate the dataset:\n    rate_f.meta.ref_file.instance\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#exploring-the-data","position":25},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-6-image2-pipeline","position":26},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"content":"In the \n\nImage2 stage of the pipeline,\ncalibrated unrectified data products are created (*_cal.fits or\n*_calints.fits files, depending on whether the input files are\n*_rate.fits or *_rateints.fits).\n\nIn this pipeline processing stage, the\n\n\nbackground subtraction\nstep is performed if the data have a dedicated background defined,\nthe \n\nworld coordinate system (WCS)\nis assigned, the data are \n\nflat fielded,\nand a \n\nphotometric calibration\nis applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n\nThe \n\nresampling\nstep is performed, to create resampled images of each dither position, but this is\nonly a quick-look product. The resampling step occurs during the Image3 stage by\ndefault. While the resampling step is done in the Image2 stage, the data quality\nfrom the Image3 stage will be better since the bad pixels, which adversely affect\nboth the centroids and photometry in individual images, will be mostly\nremoved.\n\ntime_image2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nimage2dict = {}\nimage2dict['bkg_subtract'] = {}\nimage2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\nimage2dict['photom'], image2dict['resample'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image2dict['resample']['skip'] = False\n\n# Change the nsigma used for clipping the input background data\nimage2dict['bkg_subtract']['sigma'] = 2\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf'  # Imager filter offsets (ASDF file)\n#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf'  # Spectral distortion (ASDF file)\n#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf'  # Wavelength channel mapping (ASDF file)\n#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n#image2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array\n\n\n\nDefine a function to create association files for Stage 2. This will enable use of the pixel-based background subtraction, if chosen above. This requires one input SCI file, but can have multiple input background files.\n\nNote that the background will not be applied properly to all files if more than *one* SCI file is included in the association.\n\ndef writel2asn(onescifile, bgfiles, asnfile, prodname):\n    # Define the basic association of science files\n    asn = afl.asn_from_list([onescifile], rule=DMSLevel2bBase, product_name=prodname)  # Wrap in array since input was single exposure\n\n    # Filter configuration for this sci file\n    with fits.open(onescifile) as hdu:\n        hdu.verify()\n        hdr = hdu[0].header\n        this_filter = hdr['FILTER']\n\n    # If backgrounds were provided, find which are appropriate to this\n    # filter and add to association\n    for file in bgfiles:\n        with fits.open(file) as hdu:\n            hdu.verify()\n            if (hdu[0].header['FILTER'] == this_filter):\n                asn['products'][0]['members'].append({'expname': file, 'exptype': 'background'})              \n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\n# Find all Science rate.fits files\nsstring = os.path.join(det1_dir, 'jw*rate.fits')  # Use files from the detector1 output folder\nrate_files = sorted(glob.glob(sstring))\nfor ii in range(0, len(rate_files)):\n    rate_files[ii] = os.path.abspath(rate_files[ii])\nrate_files = np.array(rate_files)\n\n# Background Files\nsstring = os.path.join(det1_bgdir, 'jw*rate.fits')\nbgfiles = sorted(glob.glob(sstring))\nfor ii in range(0, len(bgfiles)):\n    bgfiles[ii] = os.path.abspath(bgfiles[ii])\nbgfiles = np.array(bgfiles)\n\nprint(f\"Found  {str(len(rate_files))} science files\")\nprint(f\"Found  {str(len(bgfiles))} background files\")\n\n\n\n# Run Image2 stage of pipeline, specifying the output directory to save *_cal.fits files\n# and save_results flag set to True so the rate files are saved\nif doimage2:\n    for rate in rate_files:\n        asnfile = os.path.join(sci_dir, 'l2asn.json')\n        writel2asn(rate, bgfiles, asnfile, 'Level2')\n        cal_result = Image2Pipeline.call(asnfile, output_dir=image2_dir, steps=image2dict, save_results=True)\nelse:\n    print(\"Skipping Image2 processing.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-6-image2-pipeline","position":27},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run and reference files used","lvl2":"6. Image2 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#verify-which-pipeline-steps-were-run-and-reference-files-used","position":28},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run and reference files used","lvl2":"6. Image2 Pipeline"},"content":"\n\nif doimage2:\n    # Identify *_cal.fits files\n    cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_cal.fits')))\n\n    cal_f = datamodels.open(cal_files[0])\n\n    # Check which steps were run:\n    cal_f.meta.cal_step.instance\n\n    # Check which reference files were used to calibrate the dataset:\n    cal_f.meta.ref_file.instance\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#verify-which-pipeline-steps-were-run-and-reference-files-used","position":29},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"7. Image3 Pipeline"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-7-image3-pipeline","position":30},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"7. Image3 Pipeline"},"content":"In the \n\nImage3\nstage of the pipeline, the individual *_cal.fits files for each of the dither positions are\ncombined to one single distortion corrected image. First, an\n\n\nAssociation\nneeds to be created to inform the pipeline that these individual exposures are linked together.\n\nBy default, the Image3 stage of the pipeline performs the following steps on MIRI data:\n\ntweakreg -\ncreates source catalogs of pointlike sources for each input image. The source catalog for each input\nimage is compared to each other to derive coordinate transforms to align the images relative to each other.\n\nAs of pipeline version 1.14.0, the default source finding algorithm is IRAFStarFinder.\n\nskymatch -\nmeasures the background level from the sky to use as input into the subsequent outlier detection and resample steps.\n\noutlier detection -\nflags any remaining cosmic rays, bad pixels, or other artifacts not already flagged during the DETECTOR1 stage\nof the pipeline, using all input images to create a median image so that outliers in individual images can be identified.\n\nresample -\nresamples each input image based on its WCS and distortion information and creates a single undistorted image.\n\nsource catalog -\ncreates a catalog of detected sources along with measured photometries and morphologies (i.e., point-like vs extended).\nUseful for quicklooks, but optimization is likely needed for specific science cases. Users may wish to experiment with\nchanging the snr_threshold and deblend options. Modifications to the following parameters will not significantly\nimprove data quality and it is advised to keep them at their default values: aperture_ee1, aperture_ee2,\naperture_ee3, ci1_star_threshold, ci2_star_threshold.\n\nSome values that have been shown to give good results for MIRI data are to set the outlier_detection’s parameter scale\nto ‘1.0 0.8’ and to set the resample parameter weight_type to ‘exptime’, both currently set in the\n\n\nparameter reference file\npars-outlierdetectionstep, but can be overridden as indicated below.\n\ntime_image3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image3 pipeline should be configured\n# Boilerplate dictionary setup\nimage3dict = {}\nimage3dict['assign_mtwcs'], image3dict['tweakreg'], image3dict['skymatch'] = {}, {}, {}\nimage3dict['outlier_detection'], image3dict['resample'], image3dict['source_catalog'] = {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image3dict['outlier_detection']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image3dict['source_catalog']['override_apcorr'] = 'myfile.fits'  # Aperture correction parameters\n#image3dict['source_catalog']['override_abvegaoffset'] = 'myfile.asdf'  # Data to convert from AB to Vega magnitudes (ASDF file)\n\n# Overrides for specific parameters in the step (examples)\n#image3dict['resample']['weight_type'] = ['exptime']\n#image3dict['outlier_detection']['scale'] = ['1.0 0.8']\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\n# Science Files need are the cal.fits files\nsstring = os.path.join(image2_dir, 'jw*cal.fits')\ncal_files = sorted(glob.glob(sstring))\nfor ii in range(0, len(cal_files)):\n    cal_files[ii] = os.path.abspath(cal_files[ii])\ncalfiles = np.array(cal_files)\n\nprint(f'Found {str(len(cal_files))} science files to process')\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-7-image3-pipeline","position":31},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#create-association-file","position":32},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Image3 Pipeline"},"content":"An association file lists the exposures to calibrated together in Stage3\nof the pipeline. Note that an association file is available for download\nfrom MAST, with a filename of *_asn.json. Here we show how to create an\nassociation file to point to the data products created when processing data\nthrough the pipeline. Note that the output products will have a rootname\nthat is specified by the product_name in the association file. For\nthis tutorial, the rootname of the output products will be\nimage3_association.\n\n# Create a Level 3 Association\nif doimage3:\n    associations = afl.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='image3_association')\n\n    associations.data['asn_type'] = 'image3'\n    program = datamodels.open(cal_files[0]).meta.observation.program_number\n    associations.data['program'] = program\n\n    # Format association as .json file\n    asn_filename, serialized = associations.dump(format=\"json\")\n\n    # Write out association file\n    association_im3 = os.path.join(sci_dir, asn_filename)\n    with open(association_im3, \"w\") as fd:\n        fd.write(serialized)\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#create-association-file","position":33},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#run-image3-stage-of-the-pipeline","position":34},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"content":"Given the grouped exposures in the association file, the products if the\nImage3 stage of the pipeline are:\n\na *_crf.fits file produced by the outlier_detection step, where the DQ array marks the pixels flagged as outliers.\n\na final combined, rectified image with name *_i2d.fits,\n\na source catalog with name *_cat.ecsv,\n\na segmentation map file (*_segm.fits) which has integer values at the pixel locations where a source is detected where the pixel values match the source ID number in the catalog.\n\n# Run Stage 3\nif doimage3:\n    i2d_result = Image3Pipeline.call(association_im3, output_dir=image3_dir, steps=image3dict, save_results=True)\nelse:\n    print('Skipping Spec3 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image3: {time1 - time_image3:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#run-image3-stage-of-the-pipeline","position":35},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run and reference files used","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#verify-which-pipeline-steps-were-run-and-reference-files-used-1","position":36},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run and reference files used","lvl2":"7. Image3 Pipeline"},"content":"\n\nif doimage3:\n    # Identify *_i2d file and open as datamodel\n    i2d = glob.glob(os.path.join(image3_dir, \"*_i2d.fits\"))[0]\n    i2d_f = datamodels.open(i2d)\n\n    # Check which steps were run\n    i2d_f.meta.cal_step.instance\n\n    # Check which reference files were used to calibrate the dataset\n    i2d_f.meta.ref_file.instance\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#verify-which-pipeline-steps-were-run-and-reference-files-used-1","position":37},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"8. Visualize the drizzle-combined image"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-8-visualize-the-drizzle-combined-image","position":38},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"8. Visualize the drizzle-combined image"},"content":"We will use matplotlib routines for visualizing the data. Display the combined i2d image.\n\nif doviz:\n    # Look at the final i2d image (combined mosaic)\n    sstring = os.path.join(image3_dir, '*i2d.fits')\n    miri_mosaic_file = glob.glob(sstring)\n    print(miri_mosaic_file)\n\n    # Read your mosaic image into an ImageModel datamodel\n    miri_mosaic = ImageModel(miri_mosaic_file[0])\n    \n    # Autoscale the stretch\n    display_vals = [np.nanpercentile(miri_mosaic.data, 1), np.nanpercentile(miri_mosaic.data, 99)]\n\n    plt.figure(figsize=(8, 8))\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Set up image\n    cax = ax.imshow(miri_mosaic.data, cmap='Greys', origin='lower', vmin=display_vals[0], vmax=display_vals[1])\n\n    # Set up colorbar\n    cb = fig.colorbar(cax, fraction=0.046)\n    cb.ax.set_ylabel('MJy/str', fontsize=14)\n\n    # Set labels \n    ax.set_xlabel('X', fontsize=16)\n    ax.set_ylabel('Y', fontsize=16)\n    ax.set_title('Final MIRI mosaic', fontsize=16)\n    plt.tight_layout()\n\n\n\n\n\n\n\ndisplay_vals\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#id-8-visualize-the-drizzle-combined-image","position":39},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"Visualize Detected Sources"},"type":"lvl2","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#visualize-detected-sources","position":40},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl2":"Visualize Detected Sources"},"content":"Using the source catalog created by the IMAGE3 stage of the pipeline,\nmark the detected sources, using different markers for point sources\nand extended sources. The source catalog is saved in\nimage3/image3_association_cat.ecsv file.\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#visualize-detected-sources","position":41},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Read in catalog file and identify point/extended sources","lvl2":"Visualize Detected Sources"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#read-in-catalog-file-and-identify-point-extended-sources","position":42},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Read in catalog file and identify point/extended sources","lvl2":"Visualize Detected Sources"},"content":"\n\nif doviz:\n    catalog_file = glob.glob(os.path.join(image3_dir, \"*_cat.ecsv\"))[0]\n    catalog = Table.read(catalog_file)\n\n    # find where sources are considered extended or point sources\n    pt_src, = np.where(~catalog['is_extended'])\n    ext_src, = np.where(catalog['is_extended'])\n\n    # Get x and y coordinates of the objects found \n    miri_x = catalog['xcentroid'][pt_src]\n    miri_y = catalog['ycentroid'][pt_src]\n\n    ext_x = catalog['xcentroid'][ext_src]\n    ext_y = catalog['ycentroid'][ext_src]\n\n    # Show catalog\n    catalog\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#read-in-catalog-file-and-identify-point-extended-sources","position":43},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Mark the extended and point sources on the image","lvl2":"Visualize Detected Sources"},"type":"lvl3","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#mark-the-extended-and-point-sources-on-the-image","position":44},{"hierarchy":{"lvl1":"MIRI Imaging Pipeline Notebook","lvl3":"Mark the extended and point sources on the image","lvl2":"Visualize Detected Sources"},"content":"Display combined image with point sources marked with red dots and extended sources marked with blue triangles. You will see that there are a grouping of sources near the top edge of the MIRI image, several of which may be spurious sources, which tend to be found near image edges.\n\nif doviz:\n    # Look at mosaic data and sources found with source_catalog\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Set up image\n    cax = ax.imshow(miri_mosaic.data, cmap='Greys', origin='lower', vmin=display_vals[0], vmax=display_vals[1])\n    ax.scatter(miri_x, miri_y, lw=1, s=10, color='red')  # overplot point source positions\n    ax.scatter(ext_x, ext_y, lw=1, s=20, color='blue', marker='v')  # overplot extended source positions\n\n    # Set up colorbar\n    cb = fig.colorbar(cax, fraction=0.046)\n    cb.ax.set_ylabel('MJy/str', fontsize=14)\n\n    # Set labels\n    ax.set_xlabel('X', fontsize=16)\n    ax.set_ylabel('Y', fontsize=16)\n    ax.set_title('Final MIRI mosaic', fontsize=16)\n    plt.tight_layout()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/imaging/jwpipenb-miri-imaging#mark-the-extended-and-point-sources-on-the-image","position":45},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit","position":0},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit","position":1},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#miri-lrs-slit-mode-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook"},"content":"\n\nAuthors: Ian Wong; MIRI branch\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing generic Mid-Infrared\nInstrument (MIRI) Low Resolution Spectroscopy (LRS) slit mode data through all\nthree James Webb Space Telescope (JWST) pipeline stages.  The data are assumed\nto be located in the observation directory located in the path set up below.\nIt should not be necessary to edit any cells other than in the \n\nConfiguration section unless modifying the standard pipeline processing options.\n\nData:\nThis example is set up to use observations of the A-type standard star BD+60 1753, which were obtained as part of the Cycle 1 JWST flux calibration campaign by Proposal ID (PID) 1536 Observation 27. The target is a\npoint source that is dithered within the slit using the standard 2-point along-slit nod pattern. The two dithered observations will be used together to remove the background flux.\nThe example uncalibrated data will be downloaded automatically unless\ndisabled (i.e., to run with user-supplied local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements. Any \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nFeb 1 2025: Notebook created.\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes)\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#miri-lrs-slit-mode-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#table-of-contents","position":4},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup\n\nDirectory Setup\n\nDetector1 Pipeline\n\nSpec2 Pipeline\n\nSpec3 Pipeline\n\nPlot the spectrum\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#table-of-contents","position":5},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"1.-Configuration"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-1-configuration","position":6},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"1.-Configuration"},"content":"","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-1-configuration","position":7},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl3":"Install dependencies","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#install-dependencies","position":8},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl3":"Install dependencies","lvl2":"1.-Configuration"},"content":"To make sure that the pipeline version is compatabile with this notebook and the required dependencies and packages are installed,\nit is recommended that users create a new dedicated conda environment and install the provided\nrequirements.txt file before starting this notebook: conda create -n lrs_demo python=3.11\nconda activate lrs_demo\npip install -r requirements.txt","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#install-dependencies","position":9},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl3":"Set run parameters","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#set-run-parameters","position":10},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl3":"Set run parameters","lvl2":"1.-Configuration"},"content":"Set basic parameters to use with the notebook. These will affect\nwhat observation is used, where the uncalibrated data are located (if already on disk), which\npipeline modules to run on the data, and whether background subtraction is carried out. The list of parameters are:\n\ndemo_mode\n\ndirectory with data\n\npipeline steps\n\nbkg_sub\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this mode, this\nnotebook will download the example data from the\nBarbara A. Mikulski Archive for Space Telescopes (\n\nMAST) and process them through the pipeline.\nAll input and output data will be stored in the local directory unless modified\nin \n\nSection 3 below.\n\nSet demo_mode = False to process user-specified data that have already\nbeen downloaded and provide the location of the data.\n\nThe bkg_sub flag instructs the pipeline whether to carry out nod subtraction (i.e., A-B subtraction) to remove the background flux from each exposure. This is the default treatment for slit mode observations that use the standard nod pattern.\n\n# Set parameters for demo_mode, data directory, and processing steps\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to the user's local directory setup (paths below are given as\n    # examples).\n    basedir = os.path.join(os.getcwd(), '')\n\n    # Point to where the observation data are stored.\n    # Assumes uncalibrated data in obs_dir/uncal/, with results stored in stage1,\n    # stage2, stage3 directories.\n    obs_dir = os.path.join(basedir, 'PID01536Obs027/')\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Pipeline processing\ndo_det1 = True  # calwebb_detector1\ndo_spec2 = True  # calwebb_spec2\ndo_spec3 = True  # calwebb_spec3\ndo_viz = True  # Visualize calwebb_spec3 results\n\n# Background subtraction\nbkg_sub = True  # Set as true to carry out nod subtraction for background removal (recommended)\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#set-run-parameters","position":11},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#set-crds-context-and-server","position":12},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set already, it will be automatically created in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#os.environ['CRDS_CONTEXT'] = 'jwst_1322.pmap'  # CRDS context for 1.17.1\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory.\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n    \n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Print out CRDS path and context that will be used\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#set-crds-context-and-server","position":13},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"2.-Package Imports"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-2-package-imports","position":14},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"2.-Package Imports"},"content":"\n\nAutomatically import necessary Python packages for use in the data processing and visualization.\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\nfrom pathlib import Path\n\n# Numpy for doing calculations\nimport numpy as np\n\n# -----------------------Astropy Imports-----------------------------------\n# Astropy utilities for opening FITS and ASCII files and downloading demo files\nfrom astropy.io import fits\n\n# -----------------------Astroquery Imports-----------------------------------\nfrom astroquery.mast import Observations\n\n# -----------------------Plotting Imports----------------------------------\n# Matplotlib for making plots\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n\n\n# --------------JWST Calibration Pipeline Imports---------------------------\n# Import the base JWST and calibration reference data packages\nimport jwst\nimport crds\n\n# JWST pipelines (each encompassing many steps)\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Spec2Pipeline\nfrom jwst.pipeline import Spec3Pipeline\n\n# JWST pipeline utilities\n#from jwst import datamodels  # JWST datamodels\n#from jwst.stpipe import Step  # Import the wrapper class for pipeline steps\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\n# Print out pipeline version and CRDS context that will be used\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(\"Using CRDS Context = {}\".format(crds.get_context_name('jwst')))\n\n\n\n\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-2-package-imports","position":15},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":16},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"content":"If running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    program = \"01536\"\n    sci_obs = \"027\"\n    basedir = os.path.join('.', 'lrs_demo_data')\n    obs_dir = os.path.join(basedir, 'PID' + program + 'Obs' + sci_obs)\n    uncal_dir = os.path.join(obs_dir, 'uncal')\n\n    # Ensure filepath for input data exists\n    os.makedirs(uncal_dir, exist_ok=True)\n\n\n\nIdentify the list of uncalibrated files associated with the observation.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/SLIT\"], provenance_name=[\"CALJWST\"], obs_id=[\"jw\" + program + \"-o\" + sci_obs + \"*\"])\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE', \n                           'productSubGroupDescription': 'UNCAL', \n                           'calib_level': [1]}}\n\n    # Files to download\n    files_to_download = []\n    # Loop over visits, identifying uncalibrated files that are associated with them\n    for exposure in obs_id_table:\n        products = Observations.get_product_list(exposure)\n        \n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'], productSubGroupDescription=query_dict['productSubGroupDescription'], calib_level=query_dict['calib_level'])\n            files_to_download.extend(filtered_products['dataURI'])\n\n    print(\"Number of files selected for downloading: \", len(files_to_download))\n\n\n\nDownload all the uncal files and place them into the appropriate directories.\n\nWarning: If this notebook is halted during this step, the downloaded files may be incomplete and cause crashes later on!\n\nif demo_mode:\n    for filename in files_to_download:\n        obs_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_dir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":17},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"4.-Directory Setup"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-4-directory-setup","position":18},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"4.-Directory Setup"},"content":"Set up detailed paths to input/output stages here.\n\n# Define output subdirectories to keep data products organized\nuncal_dir = os.path.join(obs_dir, 'uncal')   # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(obs_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nspec2_dir = os.path.join(obs_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\nspec3_dir = os.path.join(obs_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n\n# Create desired output directories, if needed\nos.makedirs(det1_dir, exist_ok=True)\nos.makedirs(spec2_dir, exist_ok=True)\nos.makedirs(spec3_dir, exist_ok=True)\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-4-directory-setup","position":19},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-5-detector1-pipeline","position":20},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"content":"In this section, the uncalibrated data are processed through the Detector1\npipeline to create Stage 1 data products, which include 2D countrate\nimages that have been averaged over all integrations (*_rate.fits files) and 3D cubes containing fitted ramp slopes for each integration (*_rateints.fits files).  The Stage 1 data products have units of DN/s.\n\nBy default, all steps in the Detector1 stage of the pipeline are run for\nMIRI LRS slit mode data sets except the group_scale, ipc, refpix, clean_flicker_noise, and gain_scale steps.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_detector1 for a detailed overview of the various pipeline steps that comprise Detector1.\n\nTo override certain steps and reference files, use the examples provided below. E.g., turn on detection of cosmic ray showers.\n\nSet up a dictionary to define how the Detector1 pipeline should be configured.\n\ntime_det1 = time.perf_counter()\n\n\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'], det1dict['saturation'], det1dict['ipc'] = {}, {}, {}, {}, {}\ndet1dict['firstframe'], det1dict['lastframe'], det1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}, {}, {}\ndet1dict['dark_current'], det1dict['refpix'], det1dict['charge_migration'], det1dict['jump'], det1dict['ramp_fit'] = {}, {}, {}, {}, {}\ndet1dict['gain_scale'] = {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#det1dict['emicorr']['skip'] = True\n\n# Overrides for various reference files.\n# If the files are not in the base local directory, provide full path.\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n\n# Turn on multi-core processing for jump step (off by default).  \n# Choose what fraction of cores to use (quarter, half, or all)\n#det1dict['jump']['maximum_cores'] = 'half'\n\n# Turn on detection of cosmic ray showers if desired (off by default)\ndet1dict['jump']['find_showers'] = True\n\n# Adjust the flagging threshold for cosmic rays (default is 3.0)\ndet1dict['jump']['rejection_threshold'] = 5.0\n\n\n\nSelect for only the science data from the observation, excluding target acquisition and/or pointing verification exposures. For the demo example, there should be two files that are selected — one for each nod position.\n\n# Grab all downloaded uncal files\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n\n# Only choose science exposures, which have the exposure type setting 'MIR_LRS-FIXEDSLIT'\ninput_files = np.array([fi for fi in uncal_files if fits.getheader(fi, 'PRIMARY')['EXP_TYPE'] == 'MIR_LRS-FIXEDSLIT'])\n\nprint('Found ' + str(len(input_files)) + ' input uncal files')\n\n\n\nRun the Detector1 pipeline on the selected uncalibrated data using the call method. This process may take several minutes per file.\n\n# Run the Detector1 pipeline on the selected input files one by one with the custom parameter dictionary \nif do_det1:\n    for file in input_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_dir)\nelse:\n    print('Skipping Detector1 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Detector1: {time1 - time_det1} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-5-detector1-pipeline","position":21},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"6.-Spec2 Pipeline"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-6-spec2-pipeline","position":22},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"6.-Spec2 Pipeline"},"content":"This stage of the pipeline passes the countrate (ramp slope) image products (*_rate.fits files) previously generated from\nDetector1 through the Spec2 (calwebb_spec2) pipeline to yield Stage 2\ndata products (i.e., flux-calibrated flat-fielded detector images *_cal.fits, 2D rectified and truncated slit spectrum images *_s2d.fits, and quick-look 1D extracted spectra *_x1d.fits) for each exposure.  These data products have units of MJy/sr.\n\nIf bkg_sub = True, an association file will be created that pairs each nod exposure with the other, and the bkg_subtract step will be activated to carry out pixel-by-pixel background subtraction. Otherwise, the countrate images will be passed directly through the Spec2 pipeline.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_spec2 for a detailed overview of the various pipeline steps that comprise Spec2.\n\nTo override certain steps and reference files, use the examples below.\n\ntime_spec2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Spec2 pipeline should be configured\n\n# Boilerplate dictionary setup\nspec2dict = {}\nspec2dict['assign_wcs'], spec2dict['badpix_selfcal'], spec2dict['bkg_subtract'] = {}, {}, {}\nspec2dict['flat_field'], spec2dict['srctype'], spec2dict['photom'], spec2dict['pixel_replace'] = {}, {}, {}, {}\nspec2dict['pathloss'], spec2dict['resample_spec'], spec2dict['extract_1d'] = {}, {}, {}\n\n# Activate nod subtraction for background removal, if requested\nif (bkg_sub is True):\n    spec2dict['bkg_subtract']['skip'] = False\nelse:\n    spec2dict['bkg_subtract']['skip'] = True\n    \n# Overrides for whether or not certain steps should be skipped (example)\n#spec2dict['straylight']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#spec2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n#spec2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf'  # Spectral distortion (ASDF file)\n#spec2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n#spec2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array\n#spec2dict['extract_1d']['override_extract1d'] = 'myfile.asdf'  # Spectral extraction parameters (ASDF file)\n#spec2dict['extract_1d']['override_apcorr'] = 'myfile.asdf'  # Aperture correction parameters (ASDF file)\n\n\n\nDefine a function that creates an association file to enable pixel-based background subtraction within Spec2.\n\n# Function to create association.\n# scifile = list of science files\n# bkgfile = list of background files\n# asnfile = name of the association file\ndef writel2asn(scifile, bkgfile, asnfile):\n    # Define the basic association of the science exposure\n    asn = afl.asn_from_list([scifile], rule=DMSLevel2bBase)  # Wrap in array since input is single exposure\n\n    # Add the background exposure\n    asn['products'][0]['members'].append({'expname': bkgfile, 'exptype': 'background'})              \n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nConstruct lists of rate files and corresponding background exposures, ensuring the use of absolute paths.\n\n# Get rate files from the Detector1 output folder\nrate_files = sorted(glob.glob(os.path.join(det1_dir, '*rate.fits')))\n\n# Use the absolute file paths\nfor ii in range(len(rate_files)):\n    rate_files[ii] = os.path.abspath(rate_files[ii])\nrate_files = np.array(rate_files)\n\n# Background files are the opposite nod position exposures\nbkg_files = rate_files[::-1]\n\n\n\nRun the Stage 1 rate files through the Spec2 pipeline. Create ASN files if bkg_sub = True.\n\n# Run the pipeline on the selected rate files one by one with the custom parameter dictionary\nif do_spec2:\n    for ii, file in enumerate(rate_files):\n        if bkg_sub:\n            asnfile = os.path.join(det1_dir, Path(file).stem + '_asn.json')\n            writel2asn(file, bkg_files[ii], asnfile)\n            Spec2Pipeline.call(asnfile, steps=spec2dict, save_results=True, output_dir=spec2_dir)\n        else:\n            Spec2Pipeline.call(file, steps=spec2dict, save_results=True, output_dir=spec2_dir)\n            \nelse:\n    print('Skipping Spec2 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Spec2: {time1 - time_spec2} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-6-spec2-pipeline","position":23},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"7.-Spec3 Pipeline"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-7-spec3-pipeline","position":24},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"7.-Spec3 Pipeline"},"content":"The Spec3 (calwebb_spec3) pipeline produces a Stage 3\ncomposite slit spectrum image and corresponding 1D extracted spectrum.\nAn association file containing the two calibrated detector images produced previously by the Spec2 pipeline (*cal.fits files) is required for this stage. These two calibrated detector images correspond to the exposures obtained at the two nod positions. The Spec3 pipeline resamples the two images into a single combined image and carries out spectral extraction.\n\nNote that pixel values in the composite image created by the JWST pipeline are in surface brightness units (MJy/sr), not flux units. If the user desires custom spectral extraction outside the context of the extract1d step contained within the Spec3 pipeline, the pixel values must be multiplied by the width of the extraction aperture in pixels and the pixel area in steradians in order to obtain a spectrum in the appropriate flux units. This correction is built into the pipeline’s extract1d algorithm.\nThe nominal pixel area in steradians is provided in the PIXAR_SR keyword and can be found in the SCI extension header of the image outputs.\n\nThe default pipeline extraction uses a fixed box of width 8 pixels. No in-scene background subtraction is carried out by default. Users can alter the location and width of the extraction aperture and activate background subtraction strategies by providing a custom extract1d reference file. For details concerning the proper format and available parameter settings for such reference files, consult \n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/extract​_1d​/reference​_files​.html​#extract1d​-reference​-file.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_spec3 for a detailed overview of the various pipeline steps that comprise Spec3.\n\nTo override certain steps and reference files, use the examples below.\n\ntime_spec3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Spec3 pipeline should be configured\n\n# Boilerplate dictionary setup\nspec3dict = {}\nspec3dict['assign_mtwcs'], spec3dict['master_background'], spec3dict['outlier_detection'] = {}, {}, {}\nspec3dict['pixel_replace'], spec3dict['extract_1d'], spec3dict['resample_spec'] = {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#spec3dict['outlier_detection']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#spec3dict['extract_1d']['override_extract1d'] = 'myfile.json'  # Spectral extraction parameters (ASDF file)\n#spec3dict['extract_1d']['override_apcorr'] = 'myfile.asdf'  # Aperture correction parameters (ASDF file)\n\n\n\nThe pixel_replace step is not run by default, but is recommended for mitigating the effect of bad pixels and other detector artifacts. The default method within the pipeline is to fit a local profile to adjacent pixels and interpolate the flux within the problem region.\n\n# Run pixel replacement code to interpolate values for otherwise bad pixels.\nspec3dict['pixel_replace']['skip'] = False\n#spec3dict['pixel_replace']['save_results'] = True   # Enable to write out these files for spot checking\n\n\n\nDefine a function to create association files for Stage 3.\n\ndef writel3asn(cal_files, asnfile):\n    # Define the basic association of science files\n    asn = afl.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='Stage3')\n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nFind and sort all of the Stage 2 cal files, ensuring the use of absolute paths, and create the association file.\n\n# Get cal files from the Spec2 output folder\ncal_files = sorted(glob.glob(os.path.join(spec2_dir, '*cal.fits')))\n\n# Use the absolute file paths\nfor ii in range(len(cal_files)):\n    cal_files[ii] = os.path.abspath(cal_files[ii])\ncal_files = np.array(cal_files)\n\n# Create association file\nasnfile = os.path.join(spec3_dir, 'stage3_asn.json')\nwritel3asn(cal_files, asnfile)\n\n\n\nRun Spec3 using the call method.\n\nif do_spec3:\n    Spec3Pipeline.call(asnfile, steps=spec3dict, save_results=True, output_dir=spec3_dir)\nelse:\n    print('Skipping Spec3 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Spec3: {time1 - time_spec3} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-7-spec3-pipeline","position":25},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"8.-Plot the spectrum"},"type":"lvl2","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-8-plot-the-spectrum","position":26},{"hierarchy":{"lvl1":"MIRI LRS Slit Mode Pipeline Notebook","lvl2":"8.-Plot the spectrum"},"content":"Plot the extracted spectrum to see what the source looks like. The fluxes in the *x1d.fits file are in units of Jy.\n\nAs of September 2024, the absolute flux calibration has been reported to be accurate to within a few percent between 5 and 12 microns. Future improvements are planned to expand the wavelength range for which reliable fluxes can be extracted.\n\nif do_viz:\n    # Get Stage 3 extracted spectrum\n    x1d_file = os.path.join(spec3_dir, 'Stage3_x1d.fits')\n    hdu = fits.open(x1d_file)\n    objname = hdu[0].header['TARGPROP']\n    wave = hdu[1].data['WAVELENGTH']\n    flux = hdu[1].data['FLUX']\n    hdu.close()\n    \n    # Make normal plots\n    %matplotlib inline\n    # Interactive plots\n    #%matplotlib notebook\n    \n    # Plot spectrum\n    rc('axes', linewidth=2)\n    fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=150)\n    ax.plot(wave, flux, 'b-', lw=2)\n    plt.xlabel('Wavelength (μm)')\n    plt.ylabel('Flux (Jy)')\n    plt.title(objname, fontsize=14)\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(os.path.join(spec3_dir, 'lrs_slit_example_plot.png'))\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slit/jwpipenb-miri-lrs-slit#id-8-plot-the-spectrum","position":27},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso","position":0},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso","position":1},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#miri-lrs-slitless-mode-tso-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook"},"content":"\n\nAuthors: Ian Wong; MIRI branch\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing generic Mid-Infrared\nInstrument (MIRI) Low Resolution Spectroscopy (LRS) slitless mode time series observations (TSO) data through all\nthree James Webb Space Telescope (JWST) pipeline stages.  The data are assumed\nto be located in the observation directory located in the path set up below.\nIt should not be necessary to edit any cells other than in the \n\nConfiguration section unless modifying the standard pipeline processing options.\n\nA significant portion of the data processing workflow for LRS slitless TSOs is identical to the methods used to process (non-TSO) LRS slit mode observations, and much of this notebook mirrors the corresponding steps shown in the MIRI slit mode notebook.\n\nData:\nThis example is set up to use observations of the A-type standard star HD 2811, which were obtained as part of the Cycle 2 JWST flux calibration campaign by Proposal ID (PID) 4496 Observations 4 and 5. The first of these observations is of the target, while the second is a linked dedicated background observation that will be used to remove the background flux contribution from the target exposures. No dithering is carried out for standard LRS slitless mode observations. It is common for LRS slitless TSOs to lack dedicated background observations, and this notebook allows for the user to turn off the background subtraction step. The example uncalibrated data will be downloaded automatically unless disabled (i.e., to run with user-supplied local files instead).\n\nMost TSOs consist of a long series of integrations, sometimes lasting more than 10 hours, and are designed to capture transient events (e.g., exoplanet transits, phase curves). This example uses a shorter observation in order to facilitate quick execution of the full data processing workflow, while demonstrating the basic functionality of the JWST pipeline for TSOs.\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements. Any \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nFeb 1 2025: Notebook created.\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes)\nJuly 16, 2025: Updated to jwst 1.19.1 (update plotting to work with new spectral data table format)\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#miri-lrs-slitless-mode-tso-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#table-of-contents","position":4},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup\n\nDirectory Setup\n\nDetector1 Pipeline\n\nSpec2 Pipeline\n\nSpec3 Pipeline\n\nPlot white-light curve\n\nPlot spectroscopic light curves\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#table-of-contents","position":5},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"1.-Configuration"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-1-configuration","position":6},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"1.-Configuration"},"content":"","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-1-configuration","position":7},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Install dependencies","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#install-dependencies","position":8},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Install dependencies","lvl2":"1.-Configuration"},"content":"To make sure that the pipeline version is compatabile with this notebook and the required dependencies and packages are installed,\nit is recommended that users create a new dedicated conda environment and install the provided\nrequirements.txt file before starting this notebook: conda create -n lrs_demo python=3.11\nconda activate lrs_demo\npip install -r requirements.txt","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#install-dependencies","position":9},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Set run parameters","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#set-run-parameters","position":10},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Set run parameters","lvl2":"1.-Configuration"},"content":"Set basic parameters to use with the notebook. These will affect\nwhat observation is used, where the uncalibrated data are located (if already on disk), which\npipeline modules to run on the data, and whether background subtraction is carried out. The list of parameters are:\n\nSet the basic parameters to configure the notebook. These parameters determine what data gets used and where the data is located (if already on disk). The list of parameters includes:\n\ndemo_mode:\n\nDetermines what data is used in the notebook.\n\nDirectories with data:\n\nsci_dir: Directory where science observation data is stored.\n\nbkg_dir: Directory where background observation data is stored.\n\npipeline modules:\n\ndo_det1 = True runs the Detector1 module on the selected data.\n\ndo_spec2 = True runs calwebb_spec2 module on the selected data.\n\ndo_tso3 = True runs calwebb_tso3 module on the selected data.\n\ndo_viz = True Creates plots to visualize calwebb_tso3 results.\n\nbkg_sub:\n\nbkg_data = True set to False if not carrying out background substraction\n\nbkg_sub = True instructs the pipeline whether to carry out dedicated background subtraction.\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this mode, this\nnotebook will download the example data from the\nBarbara A. Mikulski Archive for Space Telescopes (\n\nMAST) and process them through the pipeline.\nAll input and output data will be stored in the local directory unless modified\nin \n\nSection 3 below.\n\nSet demo_mode = False to process user-specified data that have already\nbeen downloaded and provide the location of the data.\n\n# Set parameters for demo_mode, data directory, and processing steps\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to the user's local directory setup (paths below are given as\n    # examples).\n    basedir = os.path.join(os.getcwd(), 'lrs_tso_demo_data')\n\n    # Point to where the observation data are stored.\n    # Assumes uncalibrated data in sci_dir/uncal/ and bkg_dir/uncal/, with the results stored in stage1,\n    # stage2, stage3 directories.\n    sci_dir = os.path.join(basedir, 'PID04496Obs004/')\n    bkg_dir = os.path.join(basedir, 'PID04496Obs005/')\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Pipeline processing\ndo_det1 = True  # calwebb_detector1\ndo_spec2 = True  # calwebb_spec2\ndo_tso3 = True  # calwebb_tso3\ndo_viz = True  # Visualize calwebb_tso3 results\n\n# Background subtraction\nbkg_data = True  # Set as true if using background data\nbkg_sub = True  # Set as true to carry out dedicated background removal\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#set-run-parameters","position":11},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#set-crds-context-and-server","position":12},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set already, it will be automatically created in the home directory.\n\n# ------------------------Set CRDS context and paths------------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#os.environ['CRDS_CONTEXT'] = 'jwst_1322.pmap'  # CRDS context for 1.17.1\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory.\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Print out CRDS path and context that will be used\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#set-crds-context-and-server","position":13},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"2.-Package Imports"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-2-package-imports","position":14},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"2.-Package Imports"},"content":"\n\nAutomatically import necessary Python packages for use in the data processing and visualization.\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\nimport system utilities and other packages\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\nfrom pathlib import Path\n\n# Numpy for doing calculations\nimport numpy as np\n\n# -----------------------Astropy Imports-----------------------------------\n# Astropy utilities for opening FITS and ASCII files and downloading demo files\nfrom astropy.io import fits, ascii\nfrom astroquery.mast import Observations\n\n# -----------------------Plotting Imports----------------------------------\n# Matplotlib for making plots\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n\n\n# --------------JWST Calibration Pipeline Imports---------------------------\n# Import the base JWST and calibration reference data packages\nimport jwst\nimport crds\n\n# JWST pipelines (each encompassing many steps)\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Spec2Pipeline\nfrom jwst.pipeline import Tso3Pipeline\n\n# JWST pipeline utilities\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\n# Print out pipeline version and CRDS context that will be used\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(\"Using CRDS Context = {}\".format(crds.get_context_name('jwst')))\n\n\n\n\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-2-package-imports","position":15},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":16},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"content":"If running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    program = \"04496\"\n    sci_obs = \"004\"\n    bkg_obs = \"005\"  # bkg_obs = \"\" if no background observations \n    basedir = os.path.join('.', 'lrs_tso_demo_data')\n    sci_dir = os.path.join(basedir, 'PID' + program + 'Obs' + sci_obs)\n    uncal_dir = os.path.join(sci_dir, 'uncal')\n    if bkg_obs and bkg_data:\n        bkg_dir = os.path.join(basedir, 'PID' + program + 'Obs' + bkg_obs)\n        uncal_bkgdir = os.path.join(bkg_dir, 'uncal')\n        print('Science data will be background subtracted')\n    elif bkg_sub:\n        if not bkg_data or not bkg_obs:\n            raise ValueError('bkg_data is set to False or directory for background observations not set')\n    else:\n        bkg_dir = ''\n        print('No background observations will be used')\n\n    # Ensure filepaths for input data exists\n    os.makedirs(uncal_dir, exist_ok=True)\n    if bkg_data:\n        os.makedirs(uncal_bkgdir, exist_ok=True)\n\n\n\nIdentify the list of uncalibrated files associated with the science and background observations.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/SLITLESS\"],\n                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n                                                   obs_id=['jw' + program + '-o' + sci_obs + '*']\n                                                   )\n\n    if bkg_data:\n        bkg_obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/SLITLESS\"],\n                                                       provenance_name=[\"CALJWST\"],  # Executed observations\n                                                       obs_id=['jw' + program + bkg_obs + '*']\n                                                       )\n\n\n\n# Turn the list of observations into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE', \n                           'productSubGroupDescription': 'UNCAL', \n                           'calib_level': [1]}}\n\n    # Science files\n    sci_files_to_download = []\n    # Loop over visits identifying uncalibrated files that are associated with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files_to_download.extend(filtered_products['dataURI'])\n\n    # Background files\n    if bkg_data:\n        bkg_files_to_download = []\n        # Loop over visits identifying uncalibrated files that are associated with them\n        for exposure in (bkg_obs_id_table):\n            products = Observations.get_product_list(exposure)\n            for filetype, query_dict in file_dict.items():\n                filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                                 productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                                 calib_level=query_dict['calib_level'])\n                bkg_files_to_download.extend(filtered_products['dataURI'])\n\n    print(\"Number of science files selected for downloading: \", len(sci_files_to_download))\n    if bkg_data:\n        print(\"Number of background files selected for downloading: \", len(bkg_files_to_download))\n\n\n\nDownload all the uncal files and place them into the appropriate directories.\n\nWarning: If this notebook is halted during this step, the downloaded files may be incomplete and cause crashes later on!\n\nif demo_mode:\n    for filename in sci_files_to_download:\n        obs_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_dir, Path(filename).name))\n\n    if bkg_data:\n        for filename in bkg_files_to_download:\n            obs_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_bkgdir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":17},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"4.-Directory Setup"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-4-directory-setup","position":18},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"4.-Directory Setup"},"content":"Set up detailed paths to input/output stages here. When running this notebook outside of demo mode, the uncalibrated pipeline input files must be placed into the appropriate directories before proceeding to the JWST pipeline processing.\n\n# Define output subdirectories to keep science data products organized\nuncal_dir = os.path.join(sci_dir, 'uncal')     # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')     # calwebb_detector1 pipeline outputs will go here\nspec2_dir = os.path.join(sci_dir, 'stage2')    # calwebb_spec2 pipeline outputs will go here\ntso3_dir = os.path.join(sci_dir, 'stage3')     # calwebb_tso3 pipeline outputs will go here\n\n# Output subdirectories to keep background data products organized\nif bkg_data:\n    uncal_bkgdir = os.path.join(bkg_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\n    det1_bkgdir = os.path.join(bkg_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\n\n    # Create desired output directories, if needed\n    os.makedirs(det1_bkgdir, exist_ok=True)\n\n# Create desired output directories, if needed\nos.makedirs(det1_dir, exist_ok=True)\nos.makedirs(spec2_dir, exist_ok=True)\nos.makedirs(tso3_dir, exist_ok=True)\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-4-directory-setup","position":19},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-5-detector1-pipeline","position":20},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"content":"In this section, the uncalibrated data are processed through the Detector1\npipeline to create Stage 1 data products, which include 2D countrate\nimages that have been averaged over all integrations (*_rate.fits files) and 3D cubes containing fitted ramp slopes for each integration (*_rateints.fits files).  For TSOs, the integrations must be calibrated separately in the subsequent stages, so the *_rateints.fits files are the relevant outputs. The Stage 1 data products have units of DN/s.\n\nUnlike in the case of MIRI LRS slit mode observations, the firstframe and rscd steps are skipped by default of TSOs.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_detector1 for a detailed overview of the various pipeline steps that comprise Detector1.\n\nTo override certain steps and reference files, use the examples provided below. E.g., turn on detection of cosmic ray showers.\n\nSet up a dictionary to define how the Detector1 pipeline should be configured.\n\ntime_det1 = time.perf_counter()\n\n\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'], det1dict['saturation'], det1dict['ipc'] = {}, {}, {}, {}, {}\ndet1dict['firstframe'], det1dict['lastframe'], det1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}, {}, {}\ndet1dict['dark_current'], det1dict['refpix'], det1dict['charge_migration'], det1dict['jump'], det1dict['ramp_fit'] = {}, {}, {}, {}, {}\ndet1dict['gain_scale'] = {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#det1dict['emicorr']['skip'] = True\n\n# Overrides for various reference files.\n# If the files are not in the base local directory, provide full path.\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits' # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits' # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits' # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits' # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits' # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits' # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits' # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits' # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits' # Read noise used by ramp fitting step\n\n# Turn on multi-core processing for jump step (off by default).  Choose what fraction of cores to use (quarter, half, or all)\n#det1dict['jump']['maximum_cores'] = 'half'\n\n# Turn on detection of cosmic ray showers if desired (off by default)\ndet1dict['jump']['find_showers'] = True\n\n# Adjust the flagging threshold for cosmic rays (default is 3.0)\ndet1dict['jump']['rejection_threshold'] = 5.0\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-5-detector1-pipeline","position":21},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Processing Science Files","lvl2":"5.-Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#processing-science-files","position":22},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Processing Science Files","lvl2":"5.-Detector1 Pipeline"},"content":"Select for only the science data from the target observation, excluding target acquisition and/or pointing verification exposures. For the demo example, there should be only one file, corresponding to a contiguous segment of time-resolved integrations, but for longer TSOs, the full series of exposures may be split into several segments due to file size constraints.\n\n# Grab all downloaded uncal files\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n\n# Only choose science exposures, which have the exposure type setting 'MIR_LRS-FIXEDSLIT'\ninput_files = np.array([fi for fi in uncal_files if fits.getheader(fi, 'PRIMARY')['EXP_TYPE'] == 'MIR_LRS-SLITLESS'])\n\nprint('Found ' + str(len(input_files)) + ' science uncal files')\n\n\n\nRun the Detector1 pipeline on the selected uncalibrated data using the call method. This process may take several minutes per file.\n\n# Run the pipeline on the selected input files one by one with the custom parameter dictionary \nif do_det1:\n    for file in input_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_dir)\nelse:\n    print('Skipping Detector1 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#processing-science-files","position":23},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Processing Background Files","lvl2":"5.-Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#processing-background-files","position":24},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl3":"Processing Background Files","lvl2":"5.-Detector1 Pipeline"},"content":"Select for only the science data from the dedicated background observation, excluding target acquisition and/or pointing verification exposures.\n\nif bkg_data:\n    # Grab all downloaded uncal files\n    uncal_files = sorted(glob.glob(os.path.join(uncal_bkgdir, '*_uncal.fits')))\n\n    # Only choose science exposures, which have the exposure type setting 'MIR_LRS-FIXEDSLIT'\n    input_files = np.array([fi for fi in uncal_files if fits.getheader(fi, 'PRIMARY')['EXP_TYPE'] == 'MIR_LRS-SLITLESS'])\n\n    print('Found ' + str(len(input_files)) + ' background uncal files')\nelse:\n    print('No background data provided')\n\n\n\nRun the Detector1 pipeline on the selected uncalibrated backgtound data using the call method.\n\n# Run the pipeline on the selected input files one by one with the custom parameter dictionary \nif do_det1 and bkg_data:\n    for file in input_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_bkgdir)\nelse:\n    print('Skipping Detector1 for background files')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Detector1: {time1 - time_det1} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#processing-background-files","position":25},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"6.-Spec2 Pipeline"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-6-spec2-pipeline","position":26},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"6.-Spec2 Pipeline"},"content":"This stage of the pipeline passes the per-integration countrate (ramp slope) images (*_rateints.fits files) previously generated from\nDetector1 through the Spec2 (calwebb_spec2) pipeline to yield Stage 2\ndata products (i.e., flux-calibrated flat-fielded subarray images *_calints.fits and quick-look 1D extracted spectra *_x1dints.fits) for each exposure.  These data products have units of MJy/sr.\n\nIf bkg_sub = True, an association file will be created that pairs each science file with the dedicated background files, and the bkg_subtract step will be activated to carry out pixel-by-pixel background subtraction. Otherwise, the countrate files will be passed directly through the Spec2 pipeline.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_spec2 for a detailed overview of the various pipeline steps that comprise Spec2.\n\nTo override certain steps and reference files, use the examples below.\n\ntime_spec2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Spec2 pipeline should be configured\n\n# Boilerplate dictionary setup\nspec2dict = {}\nspec2dict['assign_wcs'], spec2dict['badpix_selfcal'], spec2dict['bkg_subtract'], spec2dict['flat_field'], spec2dict['srctype'] = {}, {}, {}, {}, {}\nspec2dict['straylight'], spec2dict['fringe'], spec2dict['photom'], spec2dict['residual_fringe'], spec2dict['pixel_replace'] = {}, {}, {}, {}, {}\nspec2dict['cube_build'], spec2dict['extract_1d'] = {}, {}\n\n# Activate dedicated background subtraction, if requested\nif (bkg_sub is True) and bkg_data:\n    spec2dict['bkg_subtract']['skip'] = False\nelse:\n    spec2dict['bkg_subtract']['skip'] = True\n\n# Overrides for whether or not certain steps should be skipped (example)\n#spec2dict['straylight']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#spec2dict['assign_wcs']['override_distortion'] = 'myfile.asdf' # Spatial distortion (ASDF file)\n#spec2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf' # Spectral distortion (ASDF file)\n#spec2dict['flat_field']['override_flat'] = 'myfile.fits' # Pixel flatfield\n#spec2dict['photom']['override_photom'] = 'myfile.fits' # Photometric calibration array\n#spec2dict['extract_1d']['override_extract1d'] = 'myfile.asdf' # Spectral extraction parameters (ASDF file)\n#spec2dict['extract_1d']['override_apcorr'] = 'myfile.asdf' # Aperture correction parameters (ASDF file)\n\n\n\nDefine a function that creates an association file to enable pixel-based background subtraction within Spec2.\n\ndef writel2asn(scifile, bkgfiles, asnfile):\n    # Define the basic association of the science exposure\n    asn = afl.asn_from_list([scifile], rule=DMSLevel2bBase)  # Wrap in array since input is single exposure\n\n    # Add the background exposure\n    for file in bkgfiles:\n        asn['products'][0]['members'].append({'expname': file, 'exptype': 'background'})              \n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nConstruct lists of science rate files and corresponding background exposures, ensuring the use of absolute paths.\n\n# Get science rate files from the Detector1 output folder\nsci_files = sorted(glob.glob(os.path.join(det1_dir, '*rateints.fits')))\n\n# Use the absolute file paths\nfor ii in range(len(sci_files)):\n    sci_files[ii] = os.path.abspath(sci_files[ii])\nsci_files = np.array(sci_files)\n\n# Get background rate files\nif bkg_data:\n    bkg_files = sorted(glob.glob(os.path.join(det1_bkgdir, '*rateints.fits')))\n\n    # Use the absolute file paths\n    for ii in range(len(bkg_files)):\n        bkg_files[ii] = os.path.abspath(bkg_files[ii])\n    bkg_files = np.array(bkg_files)\n\n\n\nRun the Stage 1 rate files through the Spec2 pipeline. Create ASN files if bkg_sub = True.\n\n# Run the pipeline on the selected science rate files one by one with the custom parameter dictionary\nif do_spec2:\n    for ii, file in enumerate(sci_files):\n        if bkg_sub and bkg_data:\n            # Create association file to associate science and background observatons \n            asnfile = os.path.join(det1_dir, Path(file).stem + '_asn.json')\n            writel2asn(file, bkg_files, asnfile)\n            Spec2Pipeline.call(asnfile, steps=spec2dict, save_results=True, output_dir=spec2_dir)\n        else:\n            # For cases with only science observation in the data\n            Spec2Pipeline.call(file, steps=spec2dict, save_results=True, output_dir=spec2_dir)\n            print('Running Spec2 with no background subtraction')\n\nelse:\n    print('Skipping Spec2 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Spec2: {time1 - time_spec2} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-6-spec2-pipeline","position":27},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"7.-Tso3 Pipeline"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-7-tso3-pipeline","position":28},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"7.-Tso3 Pipeline"},"content":"The JWST calibration pipeline has a specialized final stage for TSOs (calwebb_tso3) that produces outlier-flagged multi-integration calibrated subarray images (*crfints.fits files) and corresponding 1D extracted spectra (*x1dints.fits files). In addition, the white-light photometric light curve is produced (*whtlt.ecsv file), which is computed by integrating the total flux contained within the extraction aperture in each integration.\nAn association file containing the Stage 2 calibrated subarray images (*calints.fits files) is required for this stage.\n\nUnlike for non-TSO MIRI slit mode observations, no resampling of the subarray is done. The outlier_detection step for TSOs has an additional functionality that uses moving median filtering across the stack of individual integrations for detecting outlier pixels, which works to prevent the pipeline from flagging points due to astrophysical variability.\n\nNote that pixel values in the composite image created by the JWST pipeline are in surface brightness units (MJy/sr), not flux units. If the user desires custom spectral extraction outside the context of the extract1d step contained within the Tso3 pipeline, the pixel values must be multiplied by the width of the extraction aperture in pixels and the pixel area in steradians in order to obtain a spectrum in the appropriate flux units. This correction is built into the pipeline’s extract1d algorithm.\nThe nominal pixel area in steradians is provided in the PIXAR_SR keyword and can be found in the SCI extension header of the image outputs.\n\nThe default pipeline extraction uses a fixed box of width 12 pixels centered on the expected spectral trace. No in-scene background subtraction is carried out by default. Users can alter the location and width of the extraction aperture and activate background subtraction strategies by providing a custom extract1d reference file. For details concerning the proper format and available parameter settings for such reference files, consult \n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/extract​_1d​/reference​_files​.html​#extract1d​-reference​-file.\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_tso3 for a detailed overview of the various pipeline steps that comprise TSO3.\n\nTo override certain steps and reference files, use the examples below.\n\ntime_tso3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Tso3 pipeline should be configured\n\n# Boilerplate dictionary setup\ntso3dict = {}\ntso3dict['outlier_detection'], tso3dict['extract_1d'], tso3dict['white_light'] = {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#tso3dict['outlier_detection']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#tso3dict['extract_1d']['override_extract1d'] = 'myfile.json'  # Spectral extraction parameters (ASDF file)\n#tso3dict['extract_1d']['override_apcorr'] = 'myfile.asdf'  # Aperture correction parameters (ASDF file)\n\n# Adjust moving median outlier detection parameters \n#tso3dict['outlier_detection']['rolling_window_width'] = 31  # Default is 25\n\n\n\nDefine a function to create association files for Stage 3.\n\ndef writel3asn(cal_files, asnfile):\n    # Define the basic association of science files\n    asn = afl.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='Stage3')\n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nFind and sort all of the Stage 2 cal files, ensuring the use of absolute paths, and create the association file.\n\n# Get cal files from the Spec2 output folder\ncal_files = sorted(glob.glob(os.path.join(spec2_dir, '*calints.fits')))\n\n# Use the absolute file paths\nfor ii in range(len(cal_files)):\n    cal_files[ii] = os.path.abspath(cal_files[ii])\ncal_files = np.array(cal_files)\n\n# Create association file\nasnfile = os.path.join(tso3_dir, 'stage3_asn.json')\nwritel3asn(cal_files, asnfile)\n\n\n\nRun Tso3 using the call method.\n\nif do_tso3:\n    Tso3Pipeline.call(asnfile, steps=tso3dict, save_results=True, output_dir=tso3_dir)\nelse:\n    print('Skipping Spec3 processing...')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Tso3: {time1 - time_tso3} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-7-tso3-pipeline","position":29},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"8.-Plot white-light curve"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-8-plot-white-light-curve","position":30},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"8.-Plot white-light curve"},"content":"Plot the extracted white-light photometric light curve. The fluxes are in units of Jy.\n\nAs of September 2024, the absolute flux calibration has been reported to be accurate to within a few percent between 5 and 12 microns. Future improvements are planned to expand the wavelength range for which reliable fluxes can be extracted.\n\nif do_viz:\n    # Get Stage 3 white-light photometric light curve\n    whtlt_file = os.path.join(tso3_dir, 'Stage3_whtlt.ecsv')\n    data = ascii.read(whtlt_file, comment='#', delimiter=' ')\n    mjd = data['MJD_UTC']\n    wlc = data['whitelight_flux']\n\n    # Make normal plots\n    %matplotlib inline\n    # Interactive plots\n    #%matplotlib notebook\n\n    # Plot light curve\n    rc('axes', linewidth=2)\n    fig, ax = plt.subplots(1, 1, figsize=(10, 3), dpi=150)\n    ax.plot(mjd, wlc, 'b-', lw=2)\n    plt.xlabel('MJD_UTC (d)')\n    plt.ylabel('Flux (Jy)')\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(os.path.join(tso3_dir, 'lrs_slitless_example_wlc.png'))\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-8-plot-white-light-curve","position":31},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"9.-Plot spectroscopic light curves"},"type":"lvl2","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-9-plot-spectroscopic-light-curves","position":32},{"hierarchy":{"lvl1":"MIRI LRS Slitless Mode TSO Pipeline Notebook","lvl2":"9.-Plot spectroscopic light curves"},"content":"Plot a subset of the spectroscopic light curves contained in the *x1dints.fits file. The fluxes are in units of Jy.\n\nif do_viz:\n    # Get x1dints files\n    x1d_file = os.path.join(tso3_dir, 'Stage3_x1dints.fits')\n\n    # Choose arbitrary wavelength elements to extract\n    wave_idxs = [100, 200, 350]\n    colors = ['r', 'g', 'b']\n\n    # Read in file\n    hdul = fits.open(x1d_file)\n    int_times = hdul[1].data['int_mid_MJD_UTC']\n    spec_table = hdul[2].data\n    wave = spec_table['WAVELENGTH'][0]\n\n    # Plot light curves\n    rc('axes', linewidth=2)\n    fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=150)\n    for ii in range(len(wave_idxs)):\n        lc = spec_table['FLUX'][:, wave_idxs[ii]]\n        ax.plot(int_times, lc, colors[ii] + '-', lw=2, label=\"{:.3f} um\".format(wave[wave_idxs[ii]]))\n    plt.xlabel('MJD_UTC (d)')\n    plt.ylabel('Flux (Jy)')\n    plt.grid()\n    plt.legend(loc='best')\n    plt.tight_layout()\n    plt.savefig(os.path.join(tso3_dir, 'lrs_slitless_example_speclcs.png'))\n    hdul.close()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/lrs-slitless-tso/jwpipenb-miri-lrs-slitless-tso#id-9-plot-spectroscopic-light-curves","position":33},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs","position":0},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs","position":1},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook"},"type":"lvl1","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#miri-mrs-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook"},"content":"\n\nAuthors: David Law, Kirsten Larson; MIRI branch\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing generic Mid-Infrared\nInstrument (MIRI) Medium Resolution Spectroscopy (MRS) data through all\nthree James Webb Space Telescope (JWST) pipeline stages.  Data is assumed\nto be located in two observation folders (science and background)\naccording to paths set up below.  It should not be necessary to edit any\ncells other than in the \n\nConfiguration section\nunless modifying the standard pipeline processing options.\n\nData:\nThis example is set up to use observations of the LMC planetary nebula\nSMP LMC 058 obtained by Proposal ID (PID) 1523 Observation 3. This is a\npoint source that uses a standard 4-point dither in all three grating\nsettings.  It incorporates a dedicated background in observation 4.\nExample input data to use will be downloaded automatically unless\ndisabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the\ncalibration pipeline version given above.  If you use it with a different pipeline\nversion or specify a non-default reference file context please see the relevant\nrelease notes\n(\n\nhere for pipeline,\n\n\nhere for CRDS) for possibly relevant\nchanges.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nJan 31 2024: Update to 1.13.4 pipeline, enabling spectral leak\ncorrection\nJul 1 2024: Migrate from MRS_FlightNB1 notebook, adapt to .call()\nformat, add post-hook example, add demo mode capability.\nOct 11 2024: Update to Build 11.0 (jwst 1.15.1); move pixel_replacement to spec3 and enable by default, add option for bad pixel self-calibration in spec2.\nJan 16 2025: Update to Build 11.2 (jwst 1.17.1); no significant changes.\nMay 5 2025: Update to Build 11.3 (jwst 1.18.0); add optional command to remove residual showers, plot spectra from updated x1d.fits data model with rf-corrected columns.\nMay 22 2025: Update example plot use of regular and rf-corrected spectra.\nJuly 16 2025: No significant updates.\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#miri-mrs-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#table-of-contents","position":4},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup\n\nDirectory Setup\n\nDetector1 Pipeline\n\nSpec2 Pipeline\n\nSpec3 Pipeline\n\nPlot the spectra\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#table-of-contents","position":5},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"1.-Configuration"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-1-configuration","position":6},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"1.-Configuration"},"content":"Set basic parameters to use with notebook. These will affect\nwhat data is used, where data is located (if already in disk),\npipeline modules run in this data, and type of background\nsubtraction (if any). The list of parameters are:\n\ndemo_mode\n\nchannel\n\nband\n\ndirectories with data\n\npipeline modules\n\nBackgroud subtraction method\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this mode this\nnotebook will download example data from the\nBarbara A. Mikulski Archive for Space Telescopes (MAST) and process it through the pipeline.\nThis will all happen in a local directory unless modified\nin \n\nSection 3 below.\n\nSet demo_mode = False if you want to process your own data that has already\nbeen downloaded and provide the location of the data.\n\n# Set parameters for demo_mode, channel, band, data mode directories, and \n# processing steps.\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    user_home_dir = os.path.expanduser('~')\n\n    # Point to where science observation data are\n    # Assumes uncalibrated data in sci_dir/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    sci_dir = os.path.join(user_home_dir, 'FlightData/APT1523/data/Obs003/')\n\n    # Point to where background observation data are\n    # Assumes uncalibrated data in bg_dir/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    bg_dir = os.path.join(user_home_dir, 'FlightData/APT1523/data/Obs004/')\n    #bg_dir = '' # If no background observation, use an empty string\n\n# --------------------------Set Processing Steps--------------------------\n# Whether or not to process only data from a given MRS band/channel (useful\n# if overriding reference files)\n# Note that BOTH parameters must be set in order to work\nuse_ch = ''  # '12' or '34'\nuse_band = ''  # 'SHORT', 'MEDIUM', or 'LONG'\n\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndodet1 = True  # calwebb_detector1\ndospec2 = True  # calwebb_spec2\ndospec3 = True  # calwebb_spec3\ndoviz = True # Visualize calwebb_spec3 results\n\n# Background processing\ndodet1bg = True  # calwebb_detector1\ndospec2bg = True  # calwebb_spec2 (needed for Master Background subtraction)\n\n# How should background subtraction using any dedicated backgrounds be done?\n# If none are selected, cubes will not be background subtracted.  1d spectra\n# will always use local annular background subtraction for point sources.\n# Note that if using master-background subtraction, background observations\n# must be selected above to process through spec2 (dospec2bg = True).\nmaster_bg = True  # Master-background subtraction in spec3 (subtract spectrum generated from the backgrounds).  This is the default pipeline setting.\npixel_bg = False  # Pixel-based background subtraction in spec2 (direct pixel subtraction).\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-1-configuration","position":7},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"type":"lvl3","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#set-crds-context-and-server","position":8},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1.-Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set already, it will be set to create one in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n\n# Set CRDS reference file context.  Leave commented-out to use the default context\n# (latest reference files associated with the calibration pipeline version)\n# or set a specific context here.\n#%env CRDS_CONTEXT  jwst_1295.pmap\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path and context in use\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#set-crds-context-and-server","position":9},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"2.-Package Imports"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-2-package-imports","position":10},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"2.-Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport copy\nimport time\nfrom pathlib import Path\n\n# Numpy for doing calculations\nimport numpy as np\n\n# -----------------------Astropy Imports-----------------------------------\n# Astropy utilities for opening FITS and ASCII files, and downloading demo files\nfrom astropy.io import fits\nfrom astroquery.mast import Observations\n\n# -----------------------Plotting Imports----------------------------------\n# Matplotlib for making plots\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n\n\n# --------------JWST Calibration Pipeline Imports---------------------------\n# Import the base JWST and calibration reference data packages\nimport jwst\nimport crds\n\n# JWST pipelines (each encompassing many steps)\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Spec2Pipeline\nfrom jwst.pipeline import Spec3Pipeline\n\n# JWST pipeline utilities\nfrom jwst import datamodels  # JWST datamodels\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\nfrom jwst.stpipe import Step  # Import the wrapper class for pipeline steps\n\n# Echo pipeline version and CRDS context in use\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(\"Using CRDS Context = {}\".format(crds.get_context_name('jwst')))\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-2-package-imports","position":11},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Define convenience functions","lvl2":"2.-Package Imports"},"type":"lvl3","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#define-convenience-functions","position":12},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Define convenience functions","lvl2":"2.-Package Imports"},"content":"\n\n# Define a convenience function to select only files of a given channel/band from an input set\ndef select_ch_band_files(files, use_ch, use_band):\n    if ((use_ch != '') & (use_band != '')):\n        keep = np.zeros(len(files))\n        for ii in range(0, len(files)):\n            with fits.open(files[ii]) as hdu:\n                hdu.verify()\n                hdr = hdu[0].header\n                if ((hdr['CHANNEL'] == use_ch) & (hdr['BAND'] == use_band)):\n                    keep[ii] = 1\n        indx = np.where(keep == 1)\n        files_culled = files[indx]\n    else:\n        files_culled = files\n        \n    return files_culled\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#define-convenience-functions","position":13},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":14},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"3.-Demo Mode Setup (ignore if not using demo data)"},"content":"If running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    print('Running in demonstration mode and will download example data from MAST!')\n    program = \"01523\"\n    sci_observtn = \"003\"\n    back_observtn = \"004\"\n    visit = \"001\"\n    basedir = os.path.join('.', 'mrs_demo_data')\n    download_dir = basedir\n    sci_dir = os.path.join(basedir, 'Obs' + sci_observtn)\n    bg_dir = os.path.join(basedir, 'Obs' + back_observtn)\n    uncal_dir = os.path.join(sci_dir, 'uncal')\n    uncal_bgdir = os.path.join(bg_dir, 'uncal')\n\n    # Ensure filepaths for input data exist\n    if not os.path.exists(uncal_dir):\n        os.makedirs(uncal_dir)\n    if not os.path.exists(uncal_bgdir):\n        os.makedirs(uncal_bgdir)\n\n\n\nIdentify list of science (SCI) and background (BG) uncalibrated files associated with visits.\n\nSelects only mirifu data (ignores MIRI imager).\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    # Science data\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/IFU\"],\n                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n                                                   )\n\n    # Background data\n    bg_obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/IFU\"],\n                                                  provenance_name=[\"CALJWST\"],  # Executed observations\n                                                  obs_id=['jw' + program + '-o' + back_observtn + '*']\n                                                  )\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE', 'productSubGroupDescription': 'UNCAL', 'calib_level': [1]}}\n\n    # Science files\n    sci_files_to_download = []\n    # Loop over visits identifying uncalibrated files that are associated with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files_to_download.extend(filtered_products['dataURI'])\n\n    # Background files\n    bg_files_to_download = []\n    # Loop over visits identifying uncalibrated files that are associated with them\n    for exposure in (bg_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            bg_files_to_download.extend(filtered_products['dataURI'])\n\n    # Cull to a unique list of files that contain 'mirifu' in the filename\n    # (i.e., not MIRI imager)\n    sci_files_to_download = np.unique([i for i in sci_files_to_download if 'mirifu' in i])\n    bg_files_to_download = np.unique([i for i in bg_files_to_download if 'mirifu' in i])\n\n    print(\"Science files selected for downloading: \", len(sci_files_to_download))\n    print(\"Background selected for downloading: \", len(bg_files_to_download))\n\n\n\nDownload all the uncal files and place them into the appropriate directories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\nif demo_mode:\n    for filename in sci_files_to_download:\n        sci_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_dir, Path(filename).name))\n    for filename in bg_files_to_download:\n        bg_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_bgdir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":15},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"4.-Directory Setup"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-4-directory-setup","position":16},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"4.-Directory Setup"},"content":"Set up detailed paths to input/output stages here.\n\n# Define output subdirectories to keep science data products organized\nuncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nspec2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\nspec3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n\n# Output subdirectories to keep background data products organized\nuncal_bgdir = os.path.join(bg_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_bgdir = os.path.join(bg_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nspec2_bgdir = os.path.join(bg_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\n\n# We need to check that the desired output directories exist, and if not create them\nif not os.path.exists(det1_dir):\n    os.makedirs(det1_dir)\nif not os.path.exists(spec2_dir):\n    os.makedirs(spec2_dir)\nif not os.path.exists(spec3_dir):\n    os.makedirs(spec3_dir)\nif (bg_dir != ''):\n    if not os.path.exists(det1_bgdir):\n        os.makedirs(det1_bgdir)\n    if not os.path.exists(spec2_bgdir):\n        os.makedirs(spec2_bgdir)\n\n\n\nIf there is no background folder, ensure we don't try to process it.\n\nif (bg_dir == ''):\n    dodet1bg = False\n    dospec2bg = False\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-4-directory-setup","position":17},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-5-detector1-pipeline","position":18},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"5.-Detector1 Pipeline"},"content":"In this section we process our data through the calwebb_detector1\npipeline to create Stage 1 data products (i.e., uncalibrated slope\nimages of the form *rate.fits).  These data products have units of DN/s.\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_detector1\n\nTo override certain steps and reference files, use the examples provided below. E.g., turn on detection of cosmic ray showers.\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'], det1dict['saturation'], det1dict['ipc'] = {}, {}, {}, {}, {}\ndet1dict['firstframe'], det1dict['lastframe'], det1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}, {}, {}\ndet1dict['dark_current'], det1dict['refpix'], det1dict['charge_migration'], det1dict['jump'], det1dict['ramp_fit'] = {}, {}, {}, {}, {}\ndet1dict['gain_scale'] = {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#det1dict['emicorr']['skip'] = True\n\n# Option to use the first frame for very bright MIRI data that otherwise saturates fast enough to provide no slope\n#det1dict['firstframe']['bright_use_group1'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits' # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits' # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits' # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits' # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits' # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits' # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits' # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits' # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits' # Read noise used by ramp fitting step\n\n# Turn on multi-core processing for jump step (off by default).  Choose what fraction of cores to use (quarter, half, or all)\ndet1dict['jump']['maximum_cores'] = 'half'\n\n# Toggle detection of cosmic ray showers if desired (on by default)\n#det1dict['jump']['find_showers'] = True\n\n\n\nBelow an example of how to insert custom pipeline steps using the pre-hook/post-hook framework.\n\nFor more information see \n\nTips and Trick for working with the JWST Pipeline\n\n\n# Define a new step called XplyStep that multiplies everything by 1.0\n# I.e., it does nothing, but could be changed to do something more interesting.\nclass XplyStep(Step):\n    spec = '''\n    '''\n    class_alias = 'xply'\n\n    def process(self, input_data):\n        with datamodels.open(input_data) as model:\n            result = model.copy()\n        sci = result.data\n        sci = sci * 1.0\n        result.data = sci\n        self.log.info('Multiplied everything by one in custom step!')\n        return result\n\n\n# And here we'll insert it into our pipeline dictionary to be run at the end right after the gain_scale step\ndet1dict['gain_scale']['post_hooks'] = [XplyStep]\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-5-detector1-pipeline","position":19},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Calibrating Science Files","lvl2":"5.-Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#calibrating-science-files","position":20},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Calibrating Science Files","lvl2":"5.-Detector1 Pipeline"},"content":"Look for input science files and run calwebb_detector1 pipeline using the call method.\n\n# Look for input files of the form *uncal.fits from the science observation\nsstring = os.path.join(uncal_dir, 'jw*mirifu*uncal.fits')\nuncal_files = np.array(sorted(glob.glob(sstring)))\n# Check that these are the band/channel to use\nuncal_files = select_ch_band_files(uncal_files, use_ch, use_band)\n\nprint('Found ' + str(len(uncal_files)) + ' science input files')\n\n\n\n# Run the pipeline on these input files by a simple loop over files using\n# our custom parameter dictionary\nif dodet1:\n    for file in uncal_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_dir)\nelse:\n    print('Skipping Detector1 processing for SCI data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#calibrating-science-files","position":21},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Calibrating Background Files","lvl2":"5.-Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#calibrating-background-files","position":22},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl3":"Calibrating Background Files","lvl2":"5.-Detector1 Pipeline"},"content":"Look for input background files and run calwebb_detector1\npipeline using the call method.\n\n# Now let's look for input files of the form *uncal.fits from the background\n# observations\nsstring = os.path.join(uncal_bgdir, 'jw*mirifu*uncal.fits')\nuncal_files = np.array(sorted(glob.glob(sstring)))\n# Check that these are the band/channel to use\nuncal_files = select_ch_band_files(uncal_files, use_ch, use_band)\n\nprint('Found ' + str(len(uncal_files)) + ' background input files')\n\n\n\n# Run the pipeline on these input files by a simple loop over files using\n# our custom parameter dictionary\nif dodet1bg:\n    for file in uncal_files:\n        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_bgdir)\nelse:\n    print('Skipping Detector1 processing for BG data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#calibrating-background-files","position":23},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"6.-Spec2 Pipeline"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-6-spec2-pipeline","position":24},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"6.-Spec2 Pipeline"},"content":"In this section we process our countrate (slope) image products from\nStage 1 (calwebb_detector1) through the Spec2 (calwebb_spec2) pipeline\nin order to produce Stage 2\ndata products (i.e., calibrated slope images and quick-look data cubes\nand 1d spectra).  These data products have units of MJy/sr (or Jy for\nextracted point-source spectra).\n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_spec2\n\nIf pixel-based background subtraction was chosen above, this will be applied during this stage.\n\nTo override certain steps and reference files use the examples below.\n\ntime_spec2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Spec2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nspec2dict = {}\nspec2dict['assign_wcs'], spec2dict['badpix_selfcal'], spec2dict['bkg_subtract'], spec2dict['flat_field'], spec2dict['srctype'] = {}, {}, {}, {}, {}\nspec2dict['straylight'], spec2dict['fringe'], spec2dict['photom'], spec2dict['residual_fringe'], spec2dict['pixel_replace'] = {}, {}, {}, {}, {}\nspec2dict['cube_build'], spec2dict['extract_1d'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#spec2dict['straylight']['skip'] = True\n\n# Pixel-based background usage was set up above, propagate that here\nif (pixel_bg is True):\n    spec2dict['bkg_subtract']['skip'] = False\nelse:\n    spec2dict['bkg_subtract']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#spec2dict['assign_wcs']['override_distortion'] = 'myfile.asdf' # Spatial distortion (ASDF file)\n#spec2dict['assign_wcs']['override_regions'] = 'myfile.asdf' # IFU slice regions on detector (ASDF file)\n#spec2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf' # Spectral distortion (ASDF file)\n#spec2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf' # Wavelength channel mapping (ASDF file)\n#spec2dict['flat_field']['override_flat'] = 'myfile.fits' # Pixel flatfield\n#spec2dict['straylight']['override_mrsxartcorr'] = 'myfile.fits' # Cross-artifact model parameters\n#spec2dict['fringe']['override_fringe'] = 'myfile.fits' # Static fringe-flat\n#spec2dict['photom']['override_photom'] = 'myfile.fits' # Photometric calibration array\n#spec2dict['cube_build']['override_cubepar'] = 'myfile.fits' # Cube-building parameters\n#spec2dict['extract_1d']['override_extract1d'] = 'myfile.asdf' # Spectral extraction parameters (ASDF file)\n#spec2dict['extract_1d']['override_apcorr'] = 'myfile.asdf' # Aperture correction parameters (ASDF file)\n\n# Turn on residual cosmic-ray shower correction (off by default)\n# (see https://jwst-docs.stsci.edu/known-issues-with-jwst-data/shower-and-snowball-artifacts)\n#spec2dict['straylight']['clean_showers'] = True\n\n# Turn on 2d residual fringe correction (off by default)\n# This can sometimes improve residual fringing in science results, but takes\n# a long time to run and often does not work as well as 1d residual fringe\n# correction (in calwebb_spec3)\n#spec2dict['residual_fringe']['skip'] = False\n\n# Turn on bad pixel self-calibration, where all exposures on a given detector are used to find and\n# flag bad pixels that may have been missed by the bad pixel mask.\n# This step is experimental, and works best when dedicated background observations are included\n#spec2dict['badpix_selfcal']['skip'] = False\n#spec2dict['badpix_selfcal']['flagfrac_upper']=0.005 # Fraction of pixels to flag (dial as desired; 1.0 would be 100% of pixels)\n\n\n\nDefine a function to create association files for Stage 2. This will enable use of the pixel-based background subtraction, if chosen above. This requires one input SCI file, but can have multiple input background files.\n\nNote that the background will not be applied properly to all files if more than *one* SCI file is included in the association.\n\ndef writel2asn(onescifile, bgfiles, selfcalfiles, asnfile, prodname):\n    # Define the basic association of science files\n    asn = afl.asn_from_list([onescifile], rule=DMSLevel2bBase, product_name=prodname)  # Wrap in array since input was single exposure\n\n    #Channel/band configuration for this sci file\n    with fits.open(onescifile) as hdu:\n        hdu.verify()\n        hdr = hdu[0].header\n        this_channel, this_band = hdr['CHANNEL'], hdr['BAND']\n\n    # If backgrounds were provided, find which are appropriate to this\n    # channel/band and add to association\n    for file in bgfiles:\n        with fits.open(file) as hdu:\n            hdu.verify()\n            if ((hdu[0].header['CHANNEL'] == this_channel) & (hdu[0].header['BAND'] == this_band)):\n                asn['products'][0]['members'].append({'expname': file, 'exptype': 'background'})\n                \n    # If provided with a list of files to use for bad pixel self-calibration, find which\n    # are appropriate to this detector and add to association\n    for file in selfcalfiles:\n        with fits.open(file) as hdu:\n            hdu.verify()\n            if (hdu[0].header['CHANNEL'] == this_channel):\n                asn['products'][0]['members'].append({'expname': file, 'exptype': 'selfcal'})                \n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\nsstring = os.path.join(det1_dir, 'jw*mirifu*rate.fits')  # Use files from the detector1 output folder\nratefiles = sorted(glob.glob(sstring))\nfor ii in range(0, len(ratefiles)):\n    ratefiles[ii] = os.path.abspath(ratefiles[ii])\nratefiles = np.array(ratefiles)\n# Check that these are the band/channel to use\nratefiles = select_ch_band_files(ratefiles, use_ch, use_band)\n\n# Background Files\nsstring = os.path.join(det1_bgdir, 'jw*mirifu*rate.fits')\nbgfiles = sorted(glob.glob(sstring))\nfor ii in range(0, len(bgfiles)):\n    bgfiles[ii] = os.path.abspath(bgfiles[ii])\nbgfiles = np.array(bgfiles)\n# Check that these are the band/channel to use\nbgfiles = select_ch_band_files(bgfiles, use_ch, use_band)\n\n# Define any files to use for self-calibration (if step enabled)\n# Typically this is all science and background exposures\nselfcalfiles = ratefiles.copy()\nselfcalfiles = np.append(selfcalfiles, bgfiles)\n\nprint('Found ' + str(len(ratefiles)) + ' science files')\nprint('Found ' + str(len(bgfiles)) + ' background files')\nprint('Found ' + str(len(selfcalfiles)) + ' potential selfcal files')\n\n\n\nStep through each of the science files, using relevant associated backgrounds in calwebb_spec2 processing.\n\nThe background files are used in this step to perform pixel-based background subtraction (if desired), otherwise background subtraction is done later with Spec3 files.\n\n# To save runtime, make a new version of our spec2 parameter dictionary\n# that turns off creation of quicklook cubes and 1d spectra for science\n# data\nspec2dict_sci = copy.deepcopy(spec2dict)\nspec2dict_sci['cube_build']['skip'] = True\nspec2dict_sci['extract_1d']['skip'] = True\n\nif dospec2:\n    for file in ratefiles:\n        asnfile = os.path.join(sci_dir, 'l2asn.json')\n        writel2asn(file, bgfiles, selfcalfiles, asnfile, 'Level2')\n        Spec2Pipeline.call(asnfile, steps=spec2dict_sci, save_results=True, output_dir=spec2_dir)\nelse:\n    print('Skipping Spec2 processing for SCI data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReduce the backgrounds individually. This will be needed for the Master Background step in calwebb_spec3, but is unnecessary if doing calwebb_spec2 pixel based background instead.\n\nif dospec2bg:\n    for file in bgfiles:\n        asnfile = os.path.join(bg_dir, 'l2asn.json')\n        writel2asn(file, '', selfcalfiles, asnfile, 'Level2')\n        Spec2Pipeline.call(asnfile, steps=spec2dict, save_results=True, output_dir=spec2_bgdir)\nelse:\n    print('Skipping Spec2 processing for BG data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Spec2: {time1 - time_spec2} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-6-spec2-pipeline","position":25},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"7.-Spec3 Pipeline"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-7-spec3-pipeline","position":26},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"7.-Spec3 Pipeline"},"content":"In this section we’ll run the Spec3 (calwebb_spec3) pipeline to produce a\ncomposite data cube and extracted spectrumfrom all dithered exposures.\nWe will need to create an association file from all science (*cal.fits)\nand background (*x1d.fits) data in order for the pipeline to use them\nappropriately.\n\nNote that the data cubes created by the JWST pipeline are in SURFACE\nBRIGHTNESS units (MJy/steradian), not flux units. What that means is\nthat if you intend to sum spectra within an aperture you need to be sure\nto multiply by the pixel area in steradians first in order to get a\nspectrum in flux units. This correction is already build into the pipeline\nExtract1D algorithm.\nThe nominal pixel area in steradians is provided in the\nPIXAR_SR keyword and can be found in the SCI\nextension header.\n\nSpectral extraction for point sources uses a conical aperture extraction whose radius increases with wavelength, with annular background subtraction and aperture correction.  Spectral extraction for extended sources sums the entire image at each wavelength plane (note this is different for each channel). \n\nSee \n\nhttps://​jwst​-docs​.stsci​.edu​/jwst​-science​-calibration​-pipeline​/stages​-of​-jwst​-data​-processing​/calwebb​_spec3\n\nIf master background subtraction was selected above this will be applied during this stage. To override certain steps and reference files use the examples below.\n\ntime_spec3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Spec3 pipeline should be configured\n\n# Boilerplate dictionary setup\nspec3dict = {}\nspec3dict['assign_mtwcs'], spec3dict['master_background'], spec3dict['outlier_detection'], spec3dict['mrs_imatch'], spec3dict['cube_build'] = {}, {}, {}, {}, {}\nspec3dict['pixel_replace'], spec3dict['extract_1d'], spec3dict['spectral_leak'] = {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#spec3dict['outlier_detection']['skip'] = True\n\n# Master background usage was set up above, propagate that here\nif (master_bg is True):\n    spec3dict['master_background']['skip'] = False\nelse:\n    spec3dict['master_background']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#spec3dict['cube_build']['override_cubepar'] = 'myfile.fits'  # Cube-building parameters\n#spec3dict['extract_1d']['override_extract1d'] = 'myfile.asdf'  # Spectral extraction parameters (ASDF file)\n#spec3dict['extract_1d']['override_apcorr'] = 'myfile.asdf'  # Aperture correction parameters (ASDF file)\n\n\n\nSet certain parameters here to:\n\nadjusting performance for the outlier detection step\n\nadjust the cube building step\n\nadjust the 1d spectral extraction\n\n# Options for adjusting performance for the outlier detection step\n#spec3dict['outlier_detection']['kernel_size'] = '11 1'  # Dial this to adjust the detector kernel size\n#spec3dict['outlier_detection']['threshold_percent'] = 99.5  # Dial this to be more/less aggressive in outlier flagging (values closer to 100% are less aggressive)\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels\n# This can help mitigate 5-10% negative dips in spectra of bright sources\n# Use the 'mingrad' algorithm\nspec3dict['pixel_replace']['skip'] = False\nspec3dict['pixel_replace']['algorithm'] = 'mingrad'\n#spec3dict['pixel_replace']['save_results'] = True # Enable if desired to write out these files for spot checking\n\n# Options for adjusting the cube building step\n#spec3dict['cube_build']['output_file'] = 'mycube'  # Custom output name\nspec3dict['cube_build']['output_type'] = 'band'  # 'band', 'channel' (default), or 'multi' type cube output.  'band' is best for 1d residual fringe correction.\n#spec3dict['cube_build']['channel'] = '1'  # Build everything from just channel 1 into a single cube (we could also choose '2','3','4', or 'ALL')\n#spec3dict['cube_build']['weighting'] = 'drizzle'  # Algorithm used: 'emsm' or 'drizzle' (default)\n#spec3dict['cube_build']['coord_system'] = 'ifualign'  # Cube rotation: 'ifualign', 'skyalign' (default), or 'internal_cal'\n#spec3dict['cube_build']['scalexy'] = 0.5  # Output cube spaxel scale (arcsec) if setting it by hand\n#spec3dict['cube_build']['scalew'] = 0.002  # Output cube voxel depth in wavelength (micron) if setting it by hand\n#spec3dict['cube_build']['ra_center'] = 65.0  # Force cube to be centered at this R.A.\n#spec3dict['cube_build']['dec_center'] = -35.0  # Force cube to be centered at this Decl.\n#spec3dict['cube_build']['cube_pa'] = 45.0  # Force cube to have this position angle\n#spec3dict['cube_build']['nspax_x'] = 61  # Force cube to have this number of spaxels in cube X direction\n#spec3dict['cube_build']['nspax_y'] = 61  # Force cube to have this number of spaxels in cube Y direction\n#spec3dict['cube_build']['wavemin'] = 4.8  # Custom minimum wavelength for the cube\n#spec3dict['cube_build']['wavemax'] = 6.3  # Custom maximum wavelength for the cube\n\n# Options for adjusting the 1d spectral extraction\n#spec3dict['extract_1d']['ifu_set_srctype'] = 'POINT' # Force a certain type of spectral extraction ('POINT' or 'EXTENDED')\n#spec3dict['extract_1d']['ifu_rscale'] = 2  # Number of FWHM to use for point-source conical aperture extraction radius (default is 2)\nspec3dict['extract_1d']['ifu_autocen'] = True  # Enable auto-centering of the extraction aperture (default is True)\n#spec3dict['extract_1d']['center_xy'] = (20,20)  # Override aperture location if desired\n\n\n\nDefine a function to create association files for Stage 3.\n\ndef writel3asn(scifiles, bgfiles, asnfile, prodname):\n    # Define the basic association of science files\n    asn = afl.asn_from_list(scifiles, rule=DMS_Level3_Base, product_name=prodname)\n\n    # Add background files to the association\n    for file in bgfiles:\n        asn['products'][0]['members'].append({'expname': file, 'exptype': 'background'})\n\n    # Write the association to a json file\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\n# Science Files need the cal.fits files\nsstring = os.path.join(spec2_dir, 'jw*mirifu*_cal.fits')\ncalfiles = sorted(glob.glob(sstring))\nfor ii in range(0, len(calfiles)):\n    calfiles[ii] = os.path.abspath(calfiles[ii])\ncalfiles = np.array(calfiles)\n# Check that these are the band/channel to use\ncalfiles = select_ch_band_files(calfiles, use_ch, use_band)\n\n# Background Files need the x1d.fits files for Master Background subtraction\nsstring = os.path.join(spec2_bgdir, 'jw*mirifu*x1d.fits')\nbgfiles = sorted(glob.glob(sstring))\nfor ii in range(0, len(bgfiles)):\n    bgfiles[ii] = os.path.abspath(bgfiles[ii])\nbgfiles = np.array(bgfiles)\n# Check that these are the band/channel to use\nbgfiles = select_ch_band_files(bgfiles, use_ch, use_band)\n\nprint('Found ' + str(len(calfiles)) + ' science files to process')\nprint('Found ' + str(len(bgfiles)) + ' background files to process')\n\n\n\nMake an association file that includes all of the different exposures. If using Master Background subtraction include the background data.\n\nNote that science data must be of type cal.fits and background exposures must be of type x1d.fits\n\nasnfile = os.path.join(sci_dir, 'l3asn.json')\nif dospec3:\n    writel3asn(calfiles, bgfiles, asnfile, 'Level3')\n\n\n\nRun calwebb_spec3 using the call method.\n\nif dospec3:\n    Spec3Pipeline.call(asnfile, steps=spec3dict, save_results=True, output_dir=spec3_dir)\nelse:\n    print('Skipping Spec3 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\nprint(f\"Runtime for Spec3: {time1 - time_spec3} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-7-spec3-pipeline","position":27},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"8.-Plot the spectra"},"type":"lvl2","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-8-plot-the-spectra","position":28},{"hierarchy":{"lvl1":"MIRI MRS Pipeline Notebook","lvl2":"8.-Plot the spectra"},"content":"Here we’ll plot the spectra to see what our source looks like.\n\nif doviz:\n    # Find and sort all of the input files\n\n    # Science Files\n    # Use the final extracted spectra (x1d.fits)\n    sstring = sorted(glob.glob(os.path.join(spec3_dir, '*x1d.fits')))\n    x1dfiles = np.array(sorted(sstring))\n\n\n\nif doviz:\n    # Make normal plots\n    %matplotlib inline\n    # Interactive plots\n    #%matplotlib notebook\n\n    rc('axes', linewidth=2)\n    fig, ax = plt.subplots(1, 1, figsize=(10, 3), dpi=150)\n\n    if (len(x1dfiles) > 0):\n        hdu = fits.open(x1dfiles[0])\n        objname = hdu[0].header['TARGPROP']\n        hdu.close()\n    else:\n        objname = 'Unknown'\n\n    ymin, ymax = np.nan, np.nan\n    for file in x1dfiles:\n        x1d = fits.open(file)\n        x1ddata = x1d[1].data\n        wave = x1ddata['WAVELENGTH']\n        # MRS x1d files have both regular ('flux') and residual-fringe (RF) corrected ('rf_flux') spectra.\n        # The RF-corrected spectra will have NaN values if RF correction was disabled or failed to converge.\n        # Plot the RF corrected spectrum if available, otherwise plot the regular spectrum.\n        if np.nansum(x1ddata['RF_FLUX'] != 0):\n            flux = x1ddata['RF_FLUX']\n        else:\n            flux = x1ddata['FLUX']\n        ymin = np.nanmin([ymin, np.nanpercentile(flux, 2)])\n        ymax = np.nanmax([ymax, np.nanpercentile(flux, 99.5)])\n\n        # labels\n        label = x1d[0].header['CHANNEL'] + x1d[0].header['BAND']\n\n        plt.plot(wave, flux, label=label)\n\n        x1d.close()\n\n    plt.xlabel(r'Wavelength ($\\mu$m)')\n    plt.ylabel('Flux (Jy)')\n    plt.title(objname)\n    plt.ylim(ymin, ymax)\n    plt.legend(fontsize=8, loc='center left', bbox_to_anchor=(1, 0.5))\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig('mrs_example_plot.png')\n\n\n\n\n\n","type":"content","url":"/notebooks/miri/mrs/jwpipenb-miri-mrs#id-8-plot-the-spectra","position":29},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy","position":0},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy","position":1},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#nircam-coronagraphy-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook"},"content":"Authors: B. Sunnquist, based on the NIRISS/NIRCam imaging notebooks by R. Diaz and B. Hilbert\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing generic Near-Infrared\nCamera (NIRCam) Coronagraphy data through all three James Webb Space Telescope\n(JWST) pipeline stages.  Data is assumed to be located in a folder structure\nfollowing the paths set up below. It should not be necessary to edit\nany cells other than in the \n\nConfiguration section unless\nmodifying the standard pipeline processing options.\n\nData:\nThis example is set up to use an example dataset from\n\n\nProgram ID\n1386 (PI: Sasha Hinkley).\nThe science PSF is HIP-65426 which is taken using 2 different roll angles in observations 2 and 3. These observations use the DEEP8 readout pattern with 2 integrations per exposure and 15 groups per intergration. The PSF reference star is HIP-68245 taken in observation 1 using a 9-POINT-CIRCLE dither pattern. This observation uses the MEDIUM8 readout pattern with 2 integrations per exposure and 4 groups per integration. All data is observed on the NRCALONG detector with the SUB320A335R subarray and uses the F444W filter and MASK335R round coronagraphic mask.\nExample input data to use will be downloaded automatically unless\ndisabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements.\nAny \n\nknown issues for this build are provided in the JWST User Documentaion.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nFeb 26, 2025: original notebook created\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes)\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#nircam-coronagraphy-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#table-of-contents","position":4},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup (ignore if not using demo data)\n\nDirectory Setup\n\nDetector1 Pipeline\n\nImage2 Pipeline\n\nCoron3 Pipeline\n\nVisualize the final PSF-subtracted images\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#table-of-contents","position":5},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-1-configuration","position":6},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"1. Configuration"},"content":"\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-1-configuration","position":7},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl4","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#install-dependencies-and-parameters","position":8},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"To make sure that the pipeline version is compatabile with the steps\ndiscussed below and the required dependencies and packages are installed,\nyou can create a fresh conda environment and install the provided\nrequirements.txt file:conda create -n nircam_coronagraphy_pipeline python=3.11\nconda activate nircam_coronagraphy_pipeline\npip install -r requirements.txt","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#install-dependencies-and-parameters","position":9},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl4":"Set the basic parameters to use with this notebook.","lvl2":"1. Configuration"},"type":"lvl4","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#set-the-basic-parameters-to-use-with-this-notebook","position":10},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl4":"Set the basic parameters to use with this notebook.","lvl2":"1. Configuration"},"content":"These parameters will affect\nwhat data is used, where data is located (if already in disk), and\npipeline modules run in this data. The list of parameters are:\n\ndemo_mode\n\ndirectories with data\n\npipeline modules\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this\nmode this notebook will download example data from the Barbara A.\nMikulski Archive for Space Telescopes\n(\n\nMAST) and process it through\nthe pipeline. This will all happen in a local directory unless modified in\n\n\nSection 3 below.\n\nSet demo_mode = False if you want to process your own data\nthat has already been downloaded and provide the location of the data.\n\n# Set parameters for demo_mode, channel, band, data mode directories, and \n# processing steps.\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    basedir = os.path.join(os.getcwd(), '')\n\n    # Point to where science observation data are\n    # Assumes uncalibrated data in <sci_dir>/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    sci_dir = os.path.join(basedir, 'PID1386/')\n\n    # Create directory if it does not exist\n    if not os.path.isdir(sci_dir):\n        os.mkdir(sci_dir)\n\n    print('Using user provided files')\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndodet1 = True  # calwebb_detector1\ndoimage2 = True  # calwebb_image2\ndocoron3 = True  # calwebb_coron3\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#set-the-basic-parameters-to-use-with-this-notebook","position":11},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#set-crds-context-and-server","position":12},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need\nto configure our environment. This includes defining a CRDS cache\ndirectory in which to keep the reference files that will be used by the\ncalibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set\nalready, it will be set to create one in the home directory.\n\n\nBuild Context Table\n\n# ------------------------Set CRDS context and paths----------------------\n\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#os.environ['CRDS_CONTEXT'] = 'jwst_1322.pmap'  # CRDS context for 1.17.1\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path in use\nprint(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\nprint(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")\nif os.getenv('CRDS_CONTEXT'):\n    print(f\"CRDS CONTEXT: {os.environ['CRDS_CONTEXT']}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#set-crds-context-and-server","position":13},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-2-package-imports","position":14},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\n\n# To display full ouptut of cell, not just the last result\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n# -----------------------Astropy/Astroquery Imports--------------------------------\n# for viewing astropy images and tables\nfrom astropy.io import fits\nfrom astropy.table import Table\n\n# for downloading demo files\nfrom astroquery.mast import Observations\n\n# ------------ Pipeline and  Visualization Imports -----------------------\n# for visualizing images\nimport matplotlib.pyplot as plt\n\n# for JWST calibration pipeline\nimport jwst\nimport crds\n\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Image2Pipeline\nfrom jwst.pipeline import Coron3Pipeline\n\n# JWST pipeline utilities\nfrom jwst import datamodels\nfrom jwst.associations import asn_from_list  # Tools for creating association files\nfrom jwst.associations.lib.rules_level3 import Asn_Lv3NRCCoron  # Definition of a Lvl3 association file\n\n# Echo pipeline version and CRDS context in use\nprint(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\nprint(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")\n\n\n\n\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-2-package-imports","position":15},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":16},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"\n\n\n\nIf running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nWe will download data from\n\n\nProgram ID\n1386 (PI: Sasha Hinkley).\nThe science target is HIP-65426 which is taken using 2 different roll angles in observations 2 and 3 (2 total uncal files). The reference PSF is HIP-68245 taken in observation 1 using a 9-POINT-CIRCLE dither pattern (9 total uncal files). All data is observed on the NRCALONG detector with the SUB320A335R subarray and uses the F444W filter and MASK335R round coronagraphic mask.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    print('Running in demonstration mode and will download example data from MAST!')\n\n    program = \"01386\"\n    data_dir = os.path.join('.', 'nrc_coron_demo_data')\n    download_dir = data_dir\n    sci_dir = data_dir\n    uncal_dir = os.path.join(sci_dir, 'uncal')\n\n    # Ensure filepaths for input data exist\n    if not os.path.exists(uncal_dir):\n        os.makedirs(uncal_dir)\n\n    # Create directory if it does not exist\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n\n\n\nIdentify list of science (SCI) uncalibrated files associated with visits.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRCAM/CORON\"],\n                                                   proposal_id=program,\n                                                   filters=['F444W']\n                                                   )\n\n\n\nif demo_mode:\n    sci_obs_id_table\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE',\n                           'productSubGroupDescription': 'UNCAL',\n                           'filters': 'F444W;MASKRND',\n                           'calib_level': [1]}}\n\n    # Science files\n    sci_files_to_download = []\n\n    # Loop over visits identifying uncalibrated files that are associated with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             filters=query_dict['filters'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files_to_download.extend(filtered_products['dataURI'])\n    sci_files_to_download = sorted(sci_files_to_download)\n    print(f\"Science files selected for downloading: {len(sci_files_to_download)}\")\n\n\n\n# List the files to download\nif demo_mode:\n    sci_files_to_download\n\n\n\nDownload all the uncal files and place them into the appropriate\ndirectories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\n# Download the demo data if it does not already exist\nif demo_mode:\n    for filename in sci_files_to_download:\n        sci_manifest = Observations.download_file(filename,\n                                                  local_path=uncal_dir)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":17},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-4-directory-setup","position":18},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"\n\n\n\nSet up detailed paths to input/output stages here.\n\n# Define output subdirectories to keep science data products organized\n\nuncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\ncoron3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_coron3 pipeline outputs will go here\n\n# We need to check that the desired output directories exist, and if not create them\nif not os.path.exists(det1_dir):\n    os.makedirs(det1_dir)\nif not os.path.exists(image2_dir):\n    os.makedirs(image2_dir)\nif not os.path.exists(coron3_dir):\n    os.makedirs(coron3_dir)\n\n\n\nLook at the first file to determine exposure parameters and practice using\nJWST datamodels to show basic exposure information.\n\n# List uncal files\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n\ncolnames = ('Instrument', 'Filter', 'Pupil', 'Number of Integrations', 'Number of Groups',\n            'Readout pattern', 'Dither position number')\ndtypes = ('S7', 'S10', 'S10', 'i4', 'i4', 'S15', 'i4')\nmeta_check = Table(names=(colnames), dtype=dtypes)\n\n# Open example files and get metadata for display\nif len(uncal_files) > 0:\n    lw_examine = datamodels.open(uncal_files[0])\n    lw_row = [lw_examine.meta.instrument.name, lw_examine.meta.instrument.filter,\n              lw_examine.meta.instrument.pupil, lw_examine.meta.exposure.nints,\n              lw_examine.meta.exposure.ngroups, lw_examine.meta.exposure.readpatt,\n              lw_examine.meta.dither.position_number]\n    meta_check.add_row(lw_row)\n\n# Print out exposure info\nmeta_check\n\n\n\n# Print out the time benchmark\ntime_det1 = time.perf_counter()\nprint(f\"Runtime so far: {time_det1 - time0:0.0f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-4-directory-setup","position":19},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-5-detector1-pipeline","position":20},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"content":"Run the datasets through the\n\n\nDetector1\nstage of the pipeline to apply detector level calibrations and create a\ncountrate data product where slopes are fitted to the integration ramps.\nThese *_rate.fits products are 2D (nrows x ncols), averaged over all\nintegrations. 3D countrate data products (*_rateints.fits) are also\ncreated (nintegrations x nrows x ncols) which have the fitted ramp slopes\nfor each integration.\n\nBy default, all steps in the Detector1 stage of the pipeline are run for\nNIRCam except the ipc correction step and the gain_scale step. Note\nthat the \n\npersistence step\nhas been turned off by default starting with CRDS context jwst_1264.pmap.\nThis step does not automatically correct the science data for persistence.\nThe persistence step creates a *_trapsfilled.fits file which is a model\nthat records the number of traps filled at each pixel at the end of an exposure.\nThis file would be used as an input to the persistence step, via the input_trapsfilled\nargument, to correct the subsequent science exposure for persistence. Since persistence\nis not well calibrated for NIRCam, the step has been turned off in order to speed up\ncalibration and to not create empty *_trapsfilled.fits files. This step\ncan be turned on when running the pipeline by setting skip = False in the cell below using a dictionary.\n\nAn additional 1/f noise-cleaning algorithm, clean_flicker_noise, has been implemented at the group stage in the Detector1Pipeline. This step is also off by default. The cell bellow provides an example on how to turn it on and change parameters.\n\nAs of CRDS context jwst_1155.pmap and later, the \n\njump step of the Detector1 stage of the pipeline will remove signal associated with \n\nsnowballs in the NIRCam imaging and coronagraphy modes. This correction is turned on using the parameter expand_large_events=True. This and other parameters related to the snowball correction are specified in the pars-jumpstep parameter reference file. Users may wish to alter parameters to optimize removal of snowball residuals. Available parameters are discussed in the \n\nDetection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023).\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\ndet1dict['ipc'], det1dict['superbias'], det1dict['refpix'] = {}, {}, {}\ndet1dict['linearity'], det1dict['persistence'], det1dict['dark_current'], = {}, {}, {}\ndet1dict['charge_migration'], det1dict['jump'], det1dict['clean_flicker_noise'] = {}, {}, {}\ndet1dict['ramp_fit'], det1dict['gain_scale'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped\n# skipping the persistence step\ndet1dict['persistence']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits'  # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n\n# Turn on multi-core processing (This is off by default). Choose what fraction\n# of cores to use (quarter, half, all, or an integer number)\ndet1dict['jump']['maximum_cores'] = 'half'\n\n# Explicitly turn on snowball correction. (Even though it is on by default)\ndet1dict['jump']['expand_large_events'] = True\n\n# Turn on 1/f correction if desired\n# For guidance see https://jwst-docs.stsci.edu/known-issues-with-jwst-data/1-f-noise\n#det1dict['clean_flicker_noise']['skip'] = False\n#det1dict['clean_flicker_noise']['fit_method'] = 'median' # 'median' or 'fft'\n#det1dict['clean_flicker_noise']['background_method'] = 'median' # 'median' or 'model'\n#det1dict['clean_flicker_noise']['fit_by_channel'] = False\n\n\n\nRun the Detector1 pipeline on all input data, regardless of filter.\n\n# Run Detector1 stage of pipeline, specifying:\n# output directory to save *_rate.fits files\n# save_results flag set to True so the rate files are saved\nif dodet1:\n    for uncal in uncal_files:\n        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_dir, steps=det1dict, save_results=True)\nelse:\n    print('Skipping Detector1 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Detector1: {time1 - time_det1:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-5-detector1-pipeline","position":21},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#exploring-the-data","position":22},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"content":"Identify *_rateints.fits files and verify which pipeline steps were run and\nwhich calibration reference files were applied.\n\nThe header contains information about which calibration steps were\ncompleted and skipped and which reference files were used to process the\ndata.\n\nif dodet1:\n    # find rate files\n    rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rateints.fits')))\n\n    # Read in file as datamodel\n    rate_f = datamodels.open(rate_files[0])\n\n    # Check which steps were run\n    rate_f.meta.cal_step.instance\n\n\n\nFor this particular rate file, show which reference files were used to calibrate the dataset. Note that these files will be different for each NIRCam detector.\n\nif dodet1:\n    rate_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#exploring-the-data","position":23},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-6-image2-pipeline","position":24},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"content":"In the \n\nImage2 stage  of the science calibration pipeline,\ncalibrated unrectified data products are created (*_cal.fits or\n*_calints.fits files, depending on whether the input files are\n*_rate.fits or *_rateints.fits). For the coronagraphy pipeline, we use the _rateints.fits files as input.\n\nIn this pipeline processing stage, the \n\nworld coordinate system (WCS)\nis assigned, the data are \n\nflat fielded,\nand a \n\nphotometric calibration\nis applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n\ntime_image2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nimage2dict = {}\nimage2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\nimage2dict['photom'], image2dict['resample'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image2dict['resample']['skip'] = False\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf'  # Imager filter offsets (ASDF file)\n#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf'  # Spectral distortion (ASDF file)\n#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf'  # Wavelength channel mapping (ASDF file)\n#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n#image2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths.\n\nsstring = os.path.join(det1_dir, 'jw*rateints.fits')  # Use files from the detector1 output folder\nrate_files = sorted(glob.glob(sstring))\nrate_files = [os.path.abspath(fname) for fname in rate_files]\n\nprint(f\"Found  {len(rate_files)} science files\")\n\n\n\n# List rate files\nrate_files\n\n\n\nRun the Image2 pipeline on all of the rateints files.\n\n# Run Image2 stage of pipeline, specifying:\n# output directory to save *_calints.fits files\n# save_results flag set to True so the calints files are saved\n\nif doimage2:\n    for rate in rate_files:\n        cal_result = Image2Pipeline.call(rate, output_dir=image2_dir, steps=image2dict, save_results=True)\nelse:\n    print(\"Skipping Image2 processing.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-6-image2-pipeline","position":25},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"6. Image2 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#verify-which-pipeline-steps-were-run","position":26},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"6. Image2 Pipeline"},"content":"\n\nif doimage2:\n    # Identify *_cal.fits file products\n    cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_calints.fits')))\n\n    # Select first file to gather information\n    cal_f = datamodels.open(cal_files[0])\n\n    # Check which steps were run:\n    cal_f.meta.cal_step.instance\n\n\n\nCheck which reference files were used to calibrate the first file. Some of these will be detector-dependent.\n\nif doimage2:\n    cal_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#verify-which-pipeline-steps-were-run","position":27},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"7. Coron3 Pipeline"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-7-coron3-pipeline","position":28},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"7. Coron3 Pipeline"},"content":"In the \n\nCoron3 stage of the calibration pipeline, the *_calints.fits files from the reference PSF images are aligned and subtracted from the science PSF images, and the PSF-subtracted science images are combined into a single undistorted product.\n\nFirst, we need to create \n\nAssociations, to inform the pipeline which files are the reference and science PSFs.\n\nBy default, the Coron3 stage of the pipeline performs the following steps on NIRCam data:\n\noutlier_detection - flags outlier pixels in all input images.\n\nstack_refs - stacks all of the reference PSF images together into a single product.\n\nalign_refs - aligns all of the reference PSF images to the science target images.\n\nklip - fits and subtracts a PSF from each science target image.\n\nresample - combines all of the PSF-subtracted science images into a single undistorted product.\n\ntime_coron3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Coron3 pipeline should be configured\n\n# Boilerplate dictionary setup\ncoron3dict = {}\ncoron3dict['outlier_detection'], coron3dict['stack_refs'], coron3dict['align_refs'] = {}, {}, {}\ncoron3dict['klip'], coron3dict['resample'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#coron3dict['outlier_detection']['skip'] = True\n\n# Reduce the SNR required for a pixel to be flagged as an outlier\n#coron3dict['outlier_detection']['snr'] = '4.5 3.5'\n\n# Define which pixels types are bad based on the images' data quality arrays \n# (only DO_NOT_USE by default). New bad pixels can be flagged in the images' data \n# quality arrays to avoid issues with the psf alignment or subtraction steps.\n#coron3dict['align_refs']['bad_bits'] = 'DO_NOT_USE, OTHER_BAD_PIXEL'\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths.\n\n# Science Files need the calints.fits files\nsstring = os.path.join(image2_dir, '*_calints.fits')\n\n# Identify calints files\ncal_files = sorted(glob.glob(os.path.join(image2_dir, '*_calints.fits')))\n\n# Expand the relative paths into absolute paths\ncal_files = [os.path.abspath(fname) for fname in cal_files]\n\nprint(f'Found {len(cal_files)} science files to process')\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-7-coron3-pipeline","position":29},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Coron3 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#create-association-file","position":30},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Coron3 Pipeline"},"content":"An association file lists the files to calibrate together in Stage3 of the pipeline. For the Coron3 pipeline, the reference and science psfs must be specified in the association file. Note that association files are available for download from MAST, with filenames of *_asn.json. Here we show how to create an association file to point to the data products created in the steps above. This is useful in cases where you want to work with a set of data that is different than that in the association files from MAST.\n\nUsing the associations.asn_from_list command and Asn_lv3NRCCoron helps identify the PSF reference from the science PSF using the header information in the files.\n\n# List of data to use\nprint('\\nList of calints files to use:')\ncal_files\n\n\n\n\n\n# Create Level 3 Association for the Coron3 pipeline\n\n# Look through the input files for exptype SCIENCE to set default output names\nproduct_name = 'L3product'\nfor file in cal_files:\n    hdr = fits.getheader(file)\n    if (~hdr['IS_PSF']):\n        product_name = hdr['TARGNAME'].replace(\" \", \"\") + \"-\" + hdr['FILTER']\n\nasn_filename = os.path.join(coron3_dir, product_name + '.json')\nasn = asn_from_list.asn_from_list(cal_files, rule=Asn_Lv3NRCCoron, \n                                  product_name=product_name)\n\n# observations 2 and 3 are the science targets, observation 1 is the reference PSF\nfor member in asn['products'][0]['members']:\n    if fits.getheader(member['expname'])['IS_PSF']:\n        member['exptype'] = 'psf'\n    else:\n        member['exptype'] = 'science'\n\n# Level 3 coronagraphic associations require at least one PSF\n# Validates the association for this case.\nasn.validity['has_psf']['validated'] = True  # set to True since psfs were added to the asn above\nasn['asn_type'] = 'coron3'\nwith open(asn_filename, 'w') as outfile:\n    outfile.write(asn.dump()[1])\nasn\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#create-association-file","position":31},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Run Coron3 stage of the pipeline","lvl2":"7. Coron3 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#run-coron3-stage-of-the-pipeline","position":32},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Run Coron3 stage of the pipeline","lvl2":"7. Coron3 Pipeline"},"content":"The Coron3 stage of the pipeline will produce the following outputs:\n\na _crf.fits file produced by the outlier_detection step for each input image, where the DQ array marks the pixels flagged as outliers.\n\na _psfstack image containing a stack of all of the reference PSF images.\n\na _psfalign image for each science PSF, where the reference PSFs have been aligned to the science PSF.\n\na _psfsub image for each science PSF, where the aligned reference PSFs have been subtracted from the science PSF.\n\na final combined, undistorted PSF-subtracted image with suffix _i2d.fits.\n\n# Run Coron3 stage of pipeline, specifying:\n# output directory to save output files\n# save_results flag set to True so the files are saved\n\nif docoron3:\n    result = Coron3Pipeline.call(asn_filename,\n                                 output_dir=coron3_dir,\n                                 steps=coron3dict,\n                                 save_results=True)\nelse:\n    print(\"Skipping Coron3 processing.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Coron3: {time1 - time_coron3:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#run-coron3-stage-of-the-pipeline","position":33},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"7. Coron3 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#verify-which-pipeline-steps-were-run-1","position":34},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"7. Coron3 Pipeline"},"content":"\n\n# Identify *_i2d file and open as datamodel\nif docoron3:\n    i2d_file = os.path.join(coron3_dir, f'{product_name}_i2d.fits')\n    i2d_model = datamodels.open(i2d_file)\n    step_check_model = i2d_model\n\n    # Check which steps were run.\n    step_check_model.meta.cal_step.instance\n\n\n\nCheck which reference files were used to calibrate the dataset\n\nif docoron3:\n    step_check_model.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#verify-which-pipeline-steps-were-run-1","position":35},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"8. Visualize the final PSF subtracted images"},"type":"lvl2","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-8-visualize-the-final-psf-subtracted-images","position":36},{"hierarchy":{"lvl1":"NIRCam Coronagraphy Pipeline Notebook","lvl2":"8. Visualize the final PSF subtracted images"},"content":"Below we show each individual psf-subtracted science roll and integration, as well as the final combined PSF-subtracted image from the Coron3 pipeline run:\n\n# Inspect the psf-subtracted images generated in the coron3 pipeline run\nif docoron3:\n    files = sorted(glob.glob(os.path.join(coron3_dir, '*_psfsub.fits')))\n    grid = plt.GridSpec(2, 4, hspace=0.3, wspace=0.3)\n    fig = plt.figure(figsize=(14, 7))\n\n    # Plot the psf-subtracted science images for each roll and integration\n    for roll in range(len(files)):\n        data = fits.getdata(files[roll])\n        for integ in range(data.shape[0]):\n            data_int = data[integ]\n            ax = fig.add_subplot(grid[roll, integ])\n            ax.imshow(data_int, vmin=-2, vmax=2, origin='lower', cmap='coolwarm')\n            ax.set_title('Roll {} Int {}'.format(roll + 1, integ + 1))\n\n    # Plot the final combined psf-subtracted science image\n    i2d_file = os.path.join(coron3_dir, f'{product_name}_i2d.fits')\n    ax = fig.add_subplot(grid[0:2, 2:4])\n    data = fits.getdata(i2d_file)\n    ax.imshow(data, vmin=-2, vmax=2, origin='lower', cmap='coolwarm')\n    ax.set_title('Combined')\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/coronagraphy/jwpipenb-nircam-coronagraphy#id-8-visualize-the-final-psf-subtracted-images","position":37},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging","position":0},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging","position":1},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#nircam-imaging-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook"},"content":"Authors: B. Hilbert, based on the NIRISS imaging notebook by R. Diaz\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing generic Near-Infrared\nCamera (NIRCam) Imaging data through all three James Webb Space Telescope\n(JWST) pipeline stages.  Data is assumed to be located in a folder structure\nfollowing the paths set up below. It should not be necessary to edit\nany cells other than in the \n\nConfiguration section unless\nmodifying the standard pipeline processing options.\n\nData:\nThis example is set up to use an example dataset is from\n\n\nProgram ID\n2739 (PI: Pontoppidan) which is a Cycle 1 Outreach program.\nWe focus on the data from Observation 001 Visit 002, in which M-16, or the\n“Pillars of Creation” were observed.\nExample input data to use will be downloaded automatically unless\ndisabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the calibration pipeline version given\nabove. It sets the CRDS context to the latest context in the JWST\nCalibration Reference Data System (CRDS) associated with that\npipeline version. If you use different pipeline versions or\nCRDS context, please read the relevant release notes\n(\n\nhere for pipeline,\n\n\nhere for CRDS) for possibly relevant\nchanges.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nSept 5, 2024: original notebook created\nNov 11, 2024: Comment out line to set the context\nNov 18, 2024: Do not require both SW and LW user-provided data\nNovember 22, 2024: Updates to workflow when skipping pipeline modules\nJanuary 31, 2025: Update to build 11.2, update JDAViz Links Control to Orientation call\nFebruary 25, 2025: Add optional call to clean_flicker_noise\nApril 02, 2025: Update JDAviz call to work with JDAviz 4.2.1\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes)\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#nircam-imaging-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#table-of-contents","position":4},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup (ignore if not using demo data)\n\nDirectory Setup\n\nDetector1 Pipeline\n\nImage2 Pipeline\n\nImage3 Pipeline\n\nVisualize the resampled images\n\nVisualize Detected Sources\n\nNotes\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#table-of-contents","position":5},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-1-configuration","position":6},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"1. Configuration"},"content":"\n\n\n\nSet basic configuration for runing notebook.\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-1-configuration","position":7},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl4","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#install-dependencies-and-parameters","position":8},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"\n\nTo make sure that the pipeline version is compatabile with the steps\ndiscussed below and the required dependencies and packages are installed,\nyou can create a fresh conda environment and install the provided\nrequirements.txt file:conda create -n nircam_imaging_pipeline python=3.11\nconda activate nircam_imaging_pipeline\npip install -r requirements.txt\n\nSet the basic parameters to use with this notebook. These will affect\nwhat data is used, where data is located (if already in disk), and\npipeline modules run in this data. The list of parameters are:\n\ndemo_mode\n\ndirectories with data\n\npipeline modules\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this\nmode this notebook will download example data from the Barbara A.\nMikulski Archive for Space Telescopes\n(\n\nMAST) and process it through\nthe pipeline. This will all happen in a local directory unless modified in\n\n\nSection 3 below.\n\nSet demo_mode = False if you want to process your own data\nthat has already been downloaded and provide the location of the data.\n\n# Set parameters for demo_mode, channel, band, data mode directories, and \n# processing steps.\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    user_home_dir = os.path.expanduser('~')\n\n    # Point to where science observation data are\n    # Assumes uncalibrated data in <sci_dir>/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    sci_dir = os.path.join(user_home_dir, 'PID2739/Obs001/')\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndodet1 = True  # calwebb_detector1\ndoimage2 = True  # calwebb_image2\ndoimage3 = True  # calwebb_image3\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#install-dependencies-and-parameters","position":9},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#set-crds-context-and-server","position":10},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need\nto configure our environment. This includes defining a CRDS cache\ndirectory in which to keep the reference files that will be used by the\ncalibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set\nalready, it will be set to create one in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#%env CRDS_CONTEXT jwst_1293.pmap\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path in use\nprint(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\nprint(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")\nif os.getenv('CRDS_CONTEXT'):\n    print(f\"CRDS CONTEXT: {os.environ['CRDS_CONTEXT']}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#set-crds-context-and-server","position":11},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-2-package-imports","position":12},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\nfrom pathlib import Path\n\n# Numpy for doing calculations\nimport numpy as np\n\n# To display full ouptut of cell, not just the last result\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n# -----------------------Astroquery Imports--------------------------------\n# ASCII files, and downloading demo files\nfrom astroquery.mast import Observations\n\n# Astropy routines for visualizing detected sources:\nfrom astropy.table import Table\nfrom astropy.coordinates import SkyCoord\n\n# ------------ Pipeline and  Visualization Imports -----------------------\n\n# for JWST calibration pipeline\nimport jwst\nimport crds\n\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Image2Pipeline\nfrom jwst.pipeline import Image3Pipeline\n\n# JWST pipeline utilities\nfrom asdf import AsdfFile\nfrom jwst import datamodels\nfrom jwst.associations import asn_from_list  # Tools for creating association files\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\n# For visualizing images\nfrom jdaviz import Imviz\n\n# Echo pipeline version and CRDS context in use\nprint(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\nprint(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")\n\n\n\n\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-2-package-imports","position":13},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":14},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"\n\n\n\nIf running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nFor illustrative purposes, we focus on data taken using the NIRCam\n\n\nF200W and F444W filters\nand start with uncalibrated data products. The files are named\njw02739001002_02105_0000<dither>_nrc<det>_uncal.fits, where dither refers to the\ndither step number, and det is the detector name. Through this notebook we will refer to data\nwith filter F200W as SW data and F444W as LW data.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    print('Running in demonstration mode and will download example data from MAST!')\n    program = \"02739\"\n    sci_observtn = \"001\"\n    \n    data_dir = os.path.join('.', 'nrc_im_demo_data')\n    download_dir = data_dir\n    sci_dir = os.path.join(data_dir, 'Obs' + sci_observtn)\n    uncal_dir = os.path.join(sci_dir, 'uncal')\n\n    # Ensure filepaths for input data exist\n    if not os.path.exists(uncal_dir):\n        os.makedirs(uncal_dir)\n        \n    # Create directory if it does not exist\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n\n\n\nIdentify list of science (SCI) uncalibrated files associated with visits.\n\nWork one filter at a time, so that we can more easily filter by detector and keep only the module A files.\n\nFirst download the F200W data.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    # Science data\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRCAM/IMAGE\"],\n                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n                                                   filters=['F200W'],  # Data for Specific Filter\n                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n                                                   )\n\n\n\nif demo_mode:\n    sci_obs_id_table\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE',\n                           'productSubGroupDescription': 'UNCAL',\n                           'calib_level': [1]}}\n\n    # Science files\n    sci_files_to_download = []\n    # Loop over visits identifying uncalibrated files that are associated\n    # with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files_to_download.extend(filtered_products['dataURI'])\n\n    # To limit data volume, keep only files from visit 002, dithers 1 and 2, and only A-module\n    sw_sci_files_to_download = [fname for fname in sci_files_to_download if 'jw02739001002_02105' in fname and \n                                ('nrca2' in fname or 'nrca4' in fname) and ('00001' in fname or '00002' in fname)]\n    sw_sci_files_to_download = sorted(sw_sci_files_to_download)\n    print(f\"Science files selected for downloading: {len(sw_sci_files_to_download)}\")\n\n\n\n# List the SW files to download\nif demo_mode:\n    sw_sci_files_to_download\n\n\n\nNow repeat the process for the F444W data.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    # Science data\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRCAM/IMAGE\"],\n                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n                                                   filters=['F444W'],  # Data for Specific Filter\n                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n                                                   )\n\n\n\nif demo_mode:\n    sci_obs_id_table\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE',\n                           'productSubGroupDescription': 'UNCAL',\n                           'calib_level': [1]}}\n\n    # Science files\n    sci_files_to_download = []\n    # Loop over visits identifying uncalibrated files that are associated\n    # with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files_to_download.extend(filtered_products['dataURI'])\n\n    # To limit data volume, keep only files from visit 002, dithers 1 and 2, and only A-module\n    lw_sci_files_to_download = [fname for fname in sci_files_to_download if 'jw02739001002_02105' in fname and \n                                'nrca' in fname and ('00001' in fname or '00002' in fname)]\n    lw_sci_files_to_download = sorted(lw_sci_files_to_download)\n    print(f\"Science files selected for downloading: {len(lw_sci_files_to_download)}\")\n\n\n\n# List the LW files to download\nif demo_mode:\n    lw_sci_files_to_download\n\n\n\n# Full list the science files to download\nif demo_mode:\n    sci_files_to_download = sw_sci_files_to_download + lw_sci_files_to_download\n    sci_files_to_download\n\n\n\nDownload all the uncal files and place them into the appropriate\ndirectories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\n# Download the demo data if it does not already exist\nif demo_mode:\n    for filename in sci_files_to_download:\n        sci_manifest = Observations.download_file(filename,\n                                                  local_path=os.path.join(uncal_dir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":15},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-4-directory-setup","position":16},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"\n\n\n\nSet up detailed paths to input/output stages here.\n\n# Define output subdirectories to keep science data products organized\nuncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\nimage3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n\n# We need to check that the desired output directories exist, and if not\n# create them\nif not os.path.exists(det1_dir):\n    os.makedirs(det1_dir)\nif not os.path.exists(image2_dir):\n    os.makedirs(image2_dir)\nif not os.path.exists(image3_dir):\n    os.makedirs(image3_dir)\n\n\n\nLook at the first file to determine exposure parameters and practice using\nJWST datamodels¶\n\n# List uncal files\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n    \n# Separate SW from LW files\nsw_uncal_files = [uncfile for uncfile in uncal_files if 'long' not in uncfile]\nlw_uncal_files = [uncfile for uncfile in uncal_files if 'long' in uncfile]\n\ncolnames = ('Instrument', 'Filter', 'Pupil', 'Number of Integrations', 'Number of Groups',\n            'Readout pattern', 'Dither position number')\ndtypes = ('S7', 'S10', 'S10', 'i4', 'i4', 'S15', 'i4')\nmeta_check = Table(names=(colnames), dtype=dtypes)\n\n# Open example files and get metadata for display\nif len(sw_uncal_files) > 0:\n    sw_examine = datamodels.open(sw_uncal_files[0])\n    sw_row = [sw_examine.meta.instrument.name, sw_examine.meta.instrument.filter,\n              sw_examine.meta.instrument.pupil, sw_examine.meta.exposure.nints,\n              sw_examine.meta.exposure.ngroups, sw_examine.meta.exposure.readpatt,\n              sw_examine.meta.dither.position_number]\n    meta_check.add_row(sw_row)\n\nif len(lw_uncal_files) > 0:\n    lw_examine = datamodels.open(lw_uncal_files[0])\n    lw_row = [lw_examine.meta.instrument.name, lw_examine.meta.instrument.filter,\n              lw_examine.meta.instrument.pupil, lw_examine.meta.exposure.nints,\n              lw_examine.meta.exposure.ngroups, lw_examine.meta.exposure.readpatt,\n              lw_examine.meta.dither.position_number]\n    meta_check.add_row(lw_row)\n\n# Print out exposure info\nmeta_check\n\n\n\nThe table above shows basic exposure information from the first shortwave as well as the first longwave file. When using\nthe demo data, we confirm that the data file is for the NIRCam instrument\nusing the F200W and F444W filters in the \n\nFilter Wheel\ncrossed with the CLEAR filter in the Pupil Wheel. This observation uses\nthe \n\nBRIGHT1 readout pattern,\n8 groups per integration, and 1 integration per exposure. This data file\nis the 1st dither position in this exposure sequence. For more information\nabout how JWST exposures are defined by up-the-ramp sampling, see the\n\n\nUnderstanding Exposure Times JDox article.\n\nThis metadata will be the same for all exposures in this observation, except for the dither position number.\n\n# Print out the time benchmark\ntime_det1 = time.perf_counter()\nprint(f\"Runtime so far: {time_det1 - time0:0.0f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-4-directory-setup","position":17},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-5-detector1-pipeline","position":18},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"5. Detector1 Pipeline"},"content":"Run the datasets through the\n\n\nDetector1\nstage of the pipeline to apply detector level calibrations and create a\ncountrate data product where slopes are fitted to the integration ramps.\nThese *_rate.fits products are 2D (nrows x ncols), averaged over all\nintegrations. 3D countrate data products (*_rateints.fits) are also\ncreated (nintegrations x nrows x ncols) which have the fitted ramp slopes\nfor each integration.\n\nBy default, all steps in the Detector1 stage of the pipeline are run for\nNIRCam except the ipc correction step and the gain_scale step. Note\nthat the \n\npersistence step\nhas been turned off by default starting with CRDS context jwst_1264.pmap.\nThis step does not automatically correct the science data for persistence.\nThe persistence step creates a *_trapsfilled.fits file which is a model\nthat records the number of traps filled at each pixel at the end of an exposure.\nThis file would be used as an input to the persistence step, via the input_trapsfilled\nargument, to correct the subsequent science exposure for persistence. Since persistence\nis not well calibrated for NIRCam, the step has been turned off in order to speed up\ncalibration and to not create empty *_trapsfilled.fits files. This step\ncan be turned on when running the pipeline in Python by doing:rate_result = Detector1Pipeline.call(uncal, steps={'persistence': {'skip': False}})\n\nor as indicated in the cell bellow using a dictionary.\n\nAs of CRDS context jwst_1155.pmap and later, the\n\n\njump step\nof the Detector1 stage of the pipeline will remove signal associated\nwith \n\nsnowballs\nin the NIRCam imaging mode. This correction is turned on using the parameter\nexpand_large_events=True. This and other parameters related to the snowball correction\nare specified in the pars-jumpstep parameter reference file. Users may wish to alter\nparameters to optimize removal of snowball residuals. Available parameters are discussed\nin the \n\nDetection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023).\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\ndet1dict['ipc'], det1dict['superbias'], det1dict['refpix'] = {}, {}, {}\ndet1dict['linearity'], det1dict['persistence'], det1dict['dark_current'], = {}, {}, {}\ndet1dict['charge_migration'], det1dict['jump'], det1dict['clean_flicker_noise'] = {}, {}, {}\ndet1dict['ramp_fit'], det1dict['gain_scale'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped\n# skipping the persistence step\ndet1dict['persistence']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n\n# Turn on multi-core processing (This is off by default). Choose what fraction\n# of cores to use (quarter, half, all, or an integer number)\ndet1dict['jump']['maximum_cores'] = 'half'\n\n# Explicitly turn on snowball correction. (Even though it is on by default)\ndet1dict['jump']['expand_large_events'] = True\n\n# Turn on 1/f correction if desired\n# For guidance see https://jwst-docs.stsci.edu/known-issues-with-jwst-data/1-f-noise\n#det1dict['clean_flicker_noise']['skip'] = False\n#det1dict['clean_flicker_noise']['fit_method'] = 'median' # 'median' or 'fft'\n#det1dict['clean_flicker_noise']['background_method'] = 'median' # 'median' or 'model'\n#det1dict['clean_flicker_noise']['fit_by_channel'] = False\n\n\n\nRun the Detector1 pipeline on all input data, regardless of filter.\n\n# Run Detector1 stage of pipeline, specifying:\n# output directory to save *_rate.fits files\n# save_results flag set to True so the rate files are saved\nif dodet1:\n    for uncal in uncal_files:\n        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_dir, steps=det1dict, save_results=True)\nelse:\n    print('Skipping Detector1 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Detector1: {time1 - time_det1:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-5-detector1-pipeline","position":19},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#exploring-the-data","position":20},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"content":"Identify *_rate.fits files and verify which pipeline steps were run and\nwhich calibration reference files were applied.\n\nThe header contains information about which calibration steps were\ncompleted and skipped and which reference files were used to process the\ndata.\n\nif dodet1:\n    # find rate files\n    rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rate.fits')))\n\n    # Read in file as datamodel\n    rate_f = datamodels.open(rate_files[0])\n\n    # Check which steps were run\n    rate_f.meta.cal_step.instance\n\n\n\nFor this particular rate file, show which reference files were used to calibrate the dataset. Note that these files will be different for each NIRCam detector.\n\nif dodet1:\n    rate_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#exploring-the-data","position":21},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-6-image2-pipeline","position":22},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"6. Image2 Pipeline"},"content":"In the \n\nImage2 stage of the pipeline,\ncalibrated unrectified data products are created (*_cal.fits or\n*_calints.fits files, depending on whether the input files are\n*_rate.fits or *_rateints.fits).\n\nIn this pipeline processing stage, the \n\nworld coordinate system (WCS)\nis assigned, the data are \n\nflat fielded,\nand a \n\nphotometric calibration\nis applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n\nBy default, the \n\nbackground subtraction step\nand the \n\nresampling step\nare turned off for NIRCam. The background\nsubtraction is turned off since there is no background template for the\nimaging mode and the local background is subtracted as part of the photometry\nperfoemd in the source catalog step in the Image3 pipeline.\n\nThe\nresampling step occurs during the Image3 stage by default.\n\nWhile the\nresampling step can be run on individual images in the Image2 stage, e.g.,\nto prepare for generating a source catalog for each image, the default behavior\nis to run the step only in the Image3 stage, where multiple images are\ncombined into a final mosaic after the \n\noutlier detection step\nflags bad pixels.\n\nTo turn on the resampling step in the Image2 stage, uncomment the line in the\ndicitionary below which sets image2dict['resample']['skip'] = False\n\ntime_image2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nimage2dict = {}\nimage2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\nimage2dict['photom'], image2dict['resample'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image2dict['resample']['skip'] = False\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf' # Spatial distortion (ASDF file)\n#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf' # Imager filter offsets (ASDF file)\n#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf' # Spectral distortion (ASDF file)\n#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf' # Wavelength channel mapping (ASDF file)\n#image2dict['flat_field']['override_flat'] = 'myfile.fits' # Pixel flatfield\n#image2dict['photom']['override_photom'] = 'myfile.fits' # Photometric calibration array\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\nsstring = os.path.join(det1_dir, 'jw*rate.fits')  # Use files from the detector1 output folder\nrate_files = sorted(glob.glob(sstring))\nrate_files = [os.path.abspath(fname) for fname in rate_files]\n\nprint(f\"Found  {len(rate_files)} science files\")\n\n\n\n# List rate files\nrate_files\n\n\n\nRun the Image2 pipeline on all of the rate files, regardless of filter. Note that if you have exposures with multiple integrations and you wish to keep the integrations separate, you should call the pipeline on the *rateints.fits files, rather than the *rate.fits files.\n\n# Run Image2 stage of pipeline, specifying:\n# output directory to save *_cal.fits files\n# save_results flag set to True so the rate files are saved\n\nif doimage2:\n    for rate in rate_files:\n        cal_result = Image2Pipeline.call(rate, output_dir=image2_dir, steps=image2dict, save_results=True)\nelse:\n    print(\"Skipping Image2 processing.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-6-image2-pipeline","position":23},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"6. Image2 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#verify-which-pipeline-steps-were-run","position":24},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"6. Image2 Pipeline"},"content":"\n\nif doimage2:\n    # Identify *_cal.fits file products\n    cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_cal.fits')))\n\n    # Select first file to gather information\n    cal_f = datamodels.open(cal_files[0])\n\n    # Check which steps were run:\n    cal_f.meta.cal_step.instance\n\n\n\nCheck which reference files were used to calibrate the first file. Some of these will be detector-dependent.\n\nif doimage2:\n    cal_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#verify-which-pipeline-steps-were-run","position":25},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"7. Image3 Pipeline"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-7-image3-pipeline","position":26},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"7. Image3 Pipeline"},"content":"In the \n\nImage3 stage of the pipeline, the individual *_cal.fits files for each filter are combined to one single distortion corrected image. Unlike the previous stages, we must run the Image3 stage separately for the files from each filter as well as channel (i.e. shortwave vs longwave).\n\nFirst, we need to create \n\nAssociations, to inform the pipeline which files are linked together for each filter.\n\nBy default, the Image3 stage of the pipeline performs the following steps on NIRCam data:\n\ntweakreg - creates source catalogs of pointlike sources for each input image. The source catalog for each input image is compared to each other to derive coordinate transforms to align the images relative to each other.\n\ntweakreg has many \n\ninput parameters that can be adjusted to improve the image alignment in cases where the default values do not perform well.\n\nOne tweakreg parameter that is not set by default but can be very useful is abs_refcat. When this parameter is set to GAIADR3, the tweakreg step performs an absolute astrometric correction of the data using the GAIA data release 3 catalog. In cases where multiple unsaturated GAIA stars are present in the input images, this can improve the absolute astrometric alignment. However, in sparse or very crowded fields, this can potentially result in poor performance, so users are encouraged to check astrometric accuracy and revisit this step if necessary.\n\nAs of pipeline version 1.14.0, the default source finding algorithm in the tweakreg step is IRAFStarFinder. Other options include DAOStarFinder, whose results are not as good in cases where the PSF is undersampled, such as in the blue filters of the NIRCam shortwave channel. Finally \n\nphotutils segmentation SourceFinder, which does not assume sources are point-like.\n\nskymatch - measures the background level from the sky to use as input into the subsequent outlier detection and resample steps.\n\noutlier detection - flags any remaining cosmic rays, bad pixels, or other artifacts not already flagged during the Detector1 stage of the pipeline, using all input images to create a median image so that outliers in individual images can be identified.\n\nresample - resamples each input image based on its WCS and distortion information and creates a single undistorted image.\n\nsource catalog - creates a catalog of detected sources along with photometric results and morphologies (i.e., point-like vs extended). These catalogs are generally useful for quick checks, but optimization is likely needed for specific science cases. Users may wish to experiment with changing the snr_threshold and deblend options. Modifications to the following parameters will not significantly improve data quality and it is advised to keep them at their default values: aperture_ee1, aperture_ee2, aperture_ee3, ci1_star_threshold, ci2_star_threshold.\n\ntime_image3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image3 pipeline should be configured\n\n# Boilerplate dictionary setup\nimage3dict = {}\nimage3dict['assign_mtwcs'], image3dict['tweakreg'], image3dict['skymatch'] = {}, {}, {}\nimage3dict['outlier_detection'], image3dict['resample'], image3dict['source_catalog'] = {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image3dict['outlier_detection']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image3dict['source_catalog']['override_apcorr'] = 'myfile.fits'  # Aperture correction parameters\n#image3dict['source_catalog']['override_abvegaoffset'] = 'myfile.asdf'  # Data to convert from AB to Vega magnitudes (ASDF file)\n\n# Turn on alignment to GAIA in the tweakreg step\n# For data such as these demo data, where there are some heavily saturated stars in the field\n# of view, alignment to GAIA sometimes does not work well due to tweakreg doing a poor job\n# finding the centroids of the sources.\n#image3dict['tweakreg']['abs_refcat'] = 'GAIADR3'\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths.\nKeep files for the two filters separated.\n\n# Science Files need the cal.fits files\nsw_sstring = os.path.join(image2_dir, 'jw*nrc??_cal.fits')     # shortwave files. Detectors a1-a4, b1-b4\nlw_sstring = os.path.join(image2_dir, 'jw*nrc*long_cal.fits')  # longwave files. Detectors along, blong \n\n# Identify SW and LW cal files\nsw_cal_files = sorted(glob.glob(sw_sstring))\nlw_cal_files = sorted(glob.glob(lw_sstring))\n\n# Expand the relative paths into absolute paths\nsw_cal_files = [os.path.abspath(fname) for fname in sw_cal_files]\nlw_cal_files = [os.path.abspath(fname) for fname in lw_cal_files]\n\nprint(f'Found {len(sw_cal_files)} shortwave science files to process')\nprint(f'Found {len(lw_cal_files)} longwave science files to process')\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-7-image3-pipeline","position":27},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#create-association-file","position":28},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Create Association File","lvl2":"7. Image3 Pipeline"},"content":"An association file lists the files to calibrate together in Stage3 of the pipeline. Note that association files are available for download from MAST, with filenames of *_asn.json. Here we show how to create an association file to point to the data products created in the steps above. This is useful in cases where you want to work with a set of data that is different than that in the association files from MAST.\n\nNote that the output products will have a rootname that is specified by the product_name in the association file. For this tutorial, the rootnames of the output products will be image3_sw for filter F200W and image3_lw for filter F444W.\n\n# List of data to use\nprint('List of SW cal files to use:')\nsw_cal_files\nprint('\\nList of LW cal files to use:')\nlw_cal_files\n\n\n\n\n\n\n\n\n\n# Create Level 3 Association for SW products\ndo_swimage3 = False\nif doimage3:\n    if len(sw_cal_files) > 0:\n        # Only create an association file if there are SW data files to process\n        do_swimage3 = True\n        sw_product_name = 'image3_sw'\n        sw_association = asn_from_list.asn_from_list(sw_cal_files,\n                                                     rule=DMS_Level3_Base,\n                                                     product_name=sw_product_name)\n    \n        sw_association.data['asn_type'] = 'image3'\n        program = datamodels.open(sw_cal_files[0]).meta.observation.program_number\n        sw_association.data['program'] = program\n    \n        # Format association as .json file\n        sw_asn_filename, sw_serialized = sw_association.dump(format=\"json\")\n\n        # Write out association file\n        sw_association_im3 = os.path.join(sci_dir, sw_asn_filename)\n        with open(sw_association_im3, \"w\") as fd:\n            fd.write(sw_serialized)\n\n\n\n# Create Level 3 Associations for LW products\ndo_lwimage3 = False\nif doimage3:\n    if len(lw_cal_files) > 0:\n        # Only create an association file if there are SW data files to process\n        do_lwimage3 = True\n        lw_product_name = 'image3_lw'\n        lw_association = asn_from_list.asn_from_list(lw_cal_files,\n                                                     rule=DMS_Level3_Base,\n                                                     product_name=lw_product_name)\n    \n        lw_association.data['asn_type'] = 'image3'\n        program = datamodels.open(lw_cal_files[0]).meta.observation.program_number\n        lw_association.data['program'] = program\n    \n        # Format association as .json file\n        lw_asn_filename, lw_serialized = lw_association.dump(format=\"json\")\n\n        # Write out association file. Note that you can use your own filename in\n        # place of lw_asn_filename and everything will still work.\n        lw_association_im3 = os.path.join(sci_dir, lw_asn_filename)\n        with open(lw_association_im3, \"w\") as fd:\n            fd.write(lw_serialized)\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#create-association-file","position":29},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#run-image3-stage-of-the-pipeline","position":30},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"content":"For each set of  grouped exposures in an association file, the Image3 stage of the pipeline will produce:\n\na *_crf.fits file produced by the outlier_detection step, where the DQ array marks the pixels flagged as outliers.\n\na final combined, rectified image with name *_i2d.fits,\n\na source catalog with name *_cat.ecsv,\n\na segmentation map file (*_segm.fits) which has integer values at the pixel locations where a source is detected where the pixel values match the source ID number in the catalog.\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#run-image3-stage-of-the-pipeline","position":31},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl4":"Run Image3 on the LW data","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"type":"lvl4","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#run-image3-on-the-lw-data","position":32},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl4":"Run Image3 on the LW data","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"content":"\n\n# Run Stage3 on the LW data\nif doimage3 and do_lwimage3:\n    lw_i2d_result = Image3Pipeline.call(lw_association_im3, output_dir=image3_dir, steps=image3dict, save_results=True)\nelse:\n    print('Skipping Image3 LW processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome users wish to resample data from multiple filters onto the same WCS and pixel grid in order to create color images or help with subsequent analyses. In order to do that, we’ll save the gWCS from the *i2d.fits file created with the LW data above. The gWCS will be saved into an asdf file.\n\nif doimage3 and do_lwimage3:\n    # First we identify the dataset and read it using datamodels.\n    lw_i2d_file = os.path.join(image3_dir, f'{lw_product_name}_i2d.fits')\n    lw_data = datamodels.open(lw_i2d_file)\n    \n    # Pull out the resulting gWCS and save it in an asdf file\n    tree = {\"wcs\": lw_data.meta.wcs}\n    wcs_file = AsdfFile(tree)\n    gwcs_filename = os.path.join(image3_dir + 'lw_gwcs.asdf')\n    print(f'Saving gWCS into {gwcs_filename}')\n    wcs_file.write_to(gwcs_filename)\n\n    # Get the size of the mosaic image\n    ysize, xsize = lw_data.data.shape\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#run-image3-on-the-lw-data","position":33},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl4":"Run Image3 on the SW data","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"type":"lvl4","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#run-image3-on-the-sw-data","position":34},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl4":"Run Image3 on the SW data","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"content":"\n\nPrepare to call the Image3 pipeline on the SW data. If you wish to resample the SW data onto the same pixel grid as the LW data above, uncomment the lines below. This will tell the resample step to use the gWCS and the array size from the LW data when resampling the SW data.\n\n# Uncoment this cell in order to resample the SW data onto the same pixel grid as the LW data\n#if doimage3:\n#    image3dict['resample']['output_wcs'] = gwcs_filename\n#    image3dict['resample']['output_shape'] = (xsize, ysize)\n\n\n\nif doimage3 and do_swimage3:\n    sw_i2d_result = Image3Pipeline.call(sw_association_im3, output_dir=image3_dir, steps=image3dict, save_results=True)\nelse:\n    print('Skipping Image3 SW processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image3: {time1 - time_image3:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#run-image3-on-the-sw-data","position":35},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#verify-which-pipeline-steps-were-run-1","position":36},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Verify which pipeline steps were run","lvl2":"7. Image3 Pipeline"},"content":"\n\n# Identify *_i2d file and open as datamodel\nif doimage3:\n    if do_swimage3:\n        sw_i2d_file = os.path.join(image3_dir, f'{sw_product_name}_i2d.fits')\n        i2d_sw_model = datamodels.open(sw_i2d_file)\n        step_check_model = i2d_sw_model\n        \n    if do_lwimage3:\n        lw_i2d_file = os.path.join(image3_dir, f'{lw_product_name}_i2d.fits')\n        i2d_lw_model = datamodels.open(lw_i2d_file)\n        step_check_model = i2d_lw_model\n\n    # Check which steps were run. This should be the same regardless of whether\n    # a sw or lw file is used.\n    step_check_model.meta.cal_step.instance\n\n\n\nCheck which reference files were used to calibrate the dataset\n\nif doimage3:\n    step_check_model.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#verify-which-pipeline-steps-were-run-1","position":37},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"8. Visualize the resampled images"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-8-visualize-the-resampled-images","position":38},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"8. Visualize the resampled images"},"content":"If you specified that the LW and SW outputs should be resampled onto the same pixel grid, you should be able to open the two i2d files and overlay them and see that the sources and pixel grids line up. If there is any misalignment, you may need to adjust tweakreg parameters in the calls to the Image3 pipeline in order to improve the alignment.\n\nBelow we use the \n\nImviz tool within the jdaviz package to visualize the images, one filter at a time.\n\n# Create an Imviz instance and set up default viewer for the F200W data\nif doimage3 and do_swimage3:\n    imviz_sw_i2d = Imviz()\n    viewer_sw_i2d = imviz_sw_i2d.default_viewer\n\n    # Read in the science array for our visualization dataset:\n    i2d_sw_science = i2d_sw_model.data\n\n    # Load the dataset into Imviz\n    imviz_sw_i2d.load_data(i2d_sw_science)\n\n    # Visualize the dataset:\n    imviz_sw_i2d.show()\n\n\n\nRemember that in this mosaic we have only two detectors: NRC2 and NRC4 (left and right, respectively). The dither is not large enough to cover the gap between the detectors, and so that gap is still visible in the mosaic.\n\nif doimage3 and do_swimage3:\n    viewer_sw_i2d.stretch = 'sqrt'\n    viewer_sw_i2d.set_colormap('Viridis')\n    viewer_sw_i2d.cuts = '95%'\n\n\n\n# Create an Imviz instance and set up default viewer for the F444W data\nif doimage3 and do_lwimage3:\n    imviz_lw_i2d = Imviz()\n    viewer_lw_i2d = imviz_lw_i2d.default_viewer\n\n    # Read in the science array for our visualization dataset:\n    i2d_lw_science = i2d_lw_model.data\n\n    # Load the dataset into Imviz\n    imviz_lw_i2d.load_data(i2d_lw_science)\n\n    # Visualize the dataset:\n    imviz_lw_i2d.show()\n\n\n\nif doimage3 and do_lwimage3:\n    viewer_lw_i2d.stretch = 'sqrt'\n    viewer_lw_i2d.set_colormap('Viridis')\n    viewer_lw_i2d.cuts = '95%'\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-8-visualize-the-resampled-images","position":39},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Ovelaying the LW and SW images","lvl2":"8. Visualize the resampled images"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#ovelaying-the-lw-and-sw-images","position":40},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Ovelaying the LW and SW images","lvl2":"8. Visualize the resampled images"},"content":"Let’s try putting the SW and LW images on top of one another to create a color image. This should work regardless of whether you resampled the two images onto the same pixel grid.\n\nLet’s get the data first\n\nif doimage3 and do_swimage3 and do_lwimage3:\n    imviz_color = Imviz()\n    viewer_color = imviz_color.default_viewer\n\n    # Load the datasets into Imviz\n    imviz_color.load_data(sw_i2d_file, data_label='sw')\n    imviz_color.load_data(lw_i2d_file, data_label='lw')\n\n    # Link images by WCS\n    imviz_color.link_data(align_by='wcs')\n\n\n\nNow define some options to make the picture look nice.\n\n# Set the colors for the two images. \nif doimage3 and do_swimage3 and do_lwimage3:\n    plot_options = imviz_color.plugins['Plot Options']\n    plot_options.image_color_mode = 'Color'\n    img_settings = {'sw': {'image_color': '#61d3e1',\n                           #'stretch_vmin': 0,\n                           #'stretch_vmax': 4,\n                           #'image_opacity': 0.32,\n                           #'image_contrast': 0.69,\n                           #'image_bias': 0.39\n                           },\n                    'lw': {'image_color': '#ff767c',\n                           #'stretch_vmin': 0,\n                           #'stretch_vmax': 16,\n                           #'image_opacity': 0.4,\n                           #'image_contrast': 0.94,\n                           #'image_bias': 0.74\n                           }\n                    }\n\n\n\nPopulate the imviz instance with the settings in the cell above and visualize the dataset\n\n# Now populate the imviz instance with the settings in the cell above.\nif doimage3 and do_swimage3 and do_lwimage3:\n    for layer, settings in img_settings.items():\n        plot_options.layer = f'{layer}[DATA]'\n        for k, v in settings.items():\n            setattr(plot_options, k, v)\n\n\n\n# Visualize the dataset\nif doimage3 and do_swimage3 and do_lwimage3:\n    imviz_color.show()\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#ovelaying-the-lw-and-sw-images","position":41},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"9. Visualize Detected Sources"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-9-visualize-detected-sources","position":42},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"9. Visualize Detected Sources"},"content":"Using the source catalogs created by the Image3 stage of the pipeline, mark the detected sources, using different markers for point sources and extended sources. The source catalogs are saved in image3/image3_sw_cat.ecsv and image3/image3_lw_cat.ecsv. This time, we will provide the i2d filename to the imviz load_data function, rather than just the array of pixel values. This way, imviz will be able to make use of the WCS in the file. This will allow the sources in the source catalog to be accurately marked in the display.\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-9-visualize-detected-sources","position":43},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Read in catalog file and identify point/extended sources","lvl2":"9. Visualize Detected Sources"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#read-in-catalog-file-and-identify-point-extended-sources","position":44},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Read in catalog file and identify point/extended sources","lvl2":"9. Visualize Detected Sources"},"content":"\n\nif doimage3:\n    if do_swimage3:\n        sw_catalog_file = sw_i2d_file.replace('i2d.fits', 'cat.ecsv')\n        sw_catalog = Table.read(sw_catalog_file)\n    \n        # To identify point/extended sources, use the 'is_extended' column in the source catalog\n        sw_pt_src, = np.where(~sw_catalog['is_extended'])\n        sw_ext_src, = np.where(sw_catalog['is_extended'])\n    \n        # Define coordinates of point and extended sources\n        sw_pt_coord = Table({'coord': [SkyCoord(ra=sw_catalog['sky_centroid'][sw_pt_src].ra,\n                                                dec=sw_catalog['sky_centroid'][sw_pt_src].dec)]})\n        sw_ext_coord = Table({'coord': [SkyCoord(ra=sw_catalog['sky_centroid'][sw_ext_src].ra,\n                                                 dec=sw_catalog['sky_centroid'][sw_ext_src].dec)]})\n\n    if do_lwimage3:\n        lw_catalog_file = lw_i2d_file.replace('i2d.fits', 'cat.ecsv')\n        lw_catalog = Table.read(lw_catalog_file)\n\n        # To identify point/extended sources, use the 'is_extended' column in the source catalog\n        lw_pt_src, = np.where(~lw_catalog['is_extended'])\n        lw_ext_src, = np.where(lw_catalog['is_extended'])\n\n        # Define coordinates of point and extended sources\n        lw_pt_coord = Table({'coord': [SkyCoord(ra=lw_catalog['sky_centroid'][lw_pt_src].ra,\n                                                dec=lw_catalog['sky_centroid'][lw_pt_src].dec)]})\n        lw_ext_coord = Table({'coord': [SkyCoord(ra=lw_catalog['sky_centroid'][lw_ext_src].ra,\n                                                 dec=lw_catalog['sky_centroid'][lw_ext_src].dec)]})\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#read-in-catalog-file-and-identify-point-extended-sources","position":45},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Mark the extended and point sources on the images","lvl2":"9. Visualize Detected Sources"},"type":"lvl3","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#mark-the-extended-and-point-sources-on-the-images","position":46},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl3":"Mark the extended and point sources on the images","lvl2":"9. Visualize Detected Sources"},"content":"Display the image with sources indicated by circles. Point sources will be marked by small pink circles and extended sources will be marked by white circles. Looking at the entire mosaic, there are so many sources found that it’s hard to see much of anything. To get a clearer view, try zooming in on various areas using the magnifying glass icon on the banner immediately above the image.\n\nFirst we visualize the data without the point sources.\n\n# Read in SW i2d file to Imviz\nif doimage3 and do_swimage3:\n    imviz_sw_cat = Imviz()\n    viewer_sw_cat = imviz_sw_cat.default_viewer\n    imviz_sw_cat.load_data(sw_i2d_file)\n\n    # Adjust settings for viewer\n    viewer_sw_cat.stretch = 'sqrt'\n    viewer_sw_cat.set_colormap('Viridis')\n    viewer_sw_cat.cuts = '95%'\n\n    imviz_sw_cat.show()\n\n\n\nNow we add the point sources\n\n# Add marker for point sources:\nif doimage3 and do_swimage3:\n    viewer_sw_cat.marker = {'color': 'pink', 'markersize': 50, 'fill': False}\n\n    viewer_sw_cat.add_markers(sw_pt_coord, use_skycoord=True, marker_name='point_sources')\n\n    # Add marker for extended sources:\n    viewer_sw_cat.marker = {'color': 'white', 'markersize': 100, 'fill': False}\n\n    viewer_sw_cat.add_markers(sw_ext_coord, use_skycoord=True, marker_name='extended_sources')\n\n\n\nWe do the same with the LW file. First we visualize the data.\n\n# Repeat using the LW file\nif doimage3 and do_lwimage3:\n    imviz_lw_cat = Imviz()\n    viewer_lw_cat = imviz_lw_cat.default_viewer\n    imviz_lw_cat.load_data(lw_i2d_file)\n\n    # Adjust settings for viewer\n    viewer_lw_cat.stretch = 'sqrt'\n    viewer_lw_cat.set_colormap('Viridis')\n    viewer_lw_cat.cuts = '95%'\n\n    imviz_lw_cat.show()\n\n\n\nNow we mark the point sources\n\n# Add marker for point sources:\nif doimage3 and do_lwimage3:\n    viewer_lw_cat.marker = {'color': 'pink', 'markersize': 50, 'fill': False}\n\n    viewer_lw_cat.add_markers(lw_pt_coord, use_skycoord=True, marker_name='point_sources')\n\n    # Add marker for extended sources:\n    viewer_lw_cat.marker = {'color': 'white', 'markersize': 100, 'fill': False}\n\n    viewer_lw_cat.add_markers(lw_ext_coord, use_skycoord=True, marker_name='extended_sources')\n\n\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#mark-the-extended-and-point-sources-on-the-images","position":47},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"10. Notes"},"type":"lvl2","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-10-notes","position":48},{"hierarchy":{"lvl1":"NIRCam Imaging Pipeline Notebook","lvl2":"10. Notes"},"content":"\n\nNote that the strategy presented in this notebook for placing the SW data onto the same pixel grid as the LW data can be applied to data from any two datasets, regardless of filter or channel. By saving the gWCS from the first dataset into an asdf file and providing that file to the Image3 call with the second dataset, the resulting i2d images will be aligned onto the same pixel grid.\n\nIf you notice poor alignment across tiles within a single i2d image, or between i2d images that you expect to be aligned, try adjusting the parameters in the tweakreg step. With these, you can customize which sources tweakreg identifies and uses for the alignment.\n\n\n\n","type":"content","url":"/notebooks/nircam/imaging/jwpipenb-nircam-imaging#id-10-notes","position":49},{"hierarchy":{"lvl1":"NIRISS AMI Pipeline Notebook"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami","position":0},{"hierarchy":{"lvl1":"NIRISS AMI Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami","position":1},{"hierarchy":{"lvl1":"NIRISS AMI Pipeline Notebook","lvl4":"NIRISS AMI Pipeline Notebook"},"type":"lvl4","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#niriss-ami-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"NIRISS AMI Pipeline Notebook","lvl4":"NIRISS AMI Pipeline Notebook"},"content":"Authors: R. Cooper\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\nPurpose:\nThis notebook provides a framework for processing Near-Infrared\nImager and Slitless Spectrograph (NIRISS) Aperture Masking Interferometry (AMI) data through all\nthree James Webb Space Telescope (JWST) pipeline stages.  Data is assumed\nto be located in one observation folder according to paths set up below.\nIt should not be necessary to edit any cells other than in the\n\n\nConfiguration section unless modifying the standard\npipeline processing options.\n\nData:\nThis notebook uses an example dataset from\n\n\nProgram ID\n1093 (PI: Thatte) which is the AMI commissioning program. For illustrative\npurposes, we will use a single target and reference star pair. Each exposure\nwas taken in the F480W filter filter with the non-redundant mask (NRM) that\nenables AMI in the pupil. The observations used are\nobservation 12 for the target and observation 15 for the reference star.\n\nExample input data to use will be downloaded automatically unless\ndisabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated\nbuild context for this version of the JWST Calibration Pipeline. Information about\nthis and other contexts can be found in the JWST Calibration Reference Data System\n(CRDS \n\nserver). If you use different pipeline versions,\nplease refer to the table \n\nhere\nto determine what context to use. To learn more about the differences for the pipeline,\nread the relevant\n\n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results\nin some cases may be slightly different if a subsequent version is used. For optimal\nresults, users are strongly encouraged to reprocess their data using the most recent\npipeline version and\n\n\nassociated CRDS context,\ntaking advantage of bug fixes and algorithm improvements.\nAny \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nMarch 31, 2025: original notebook released\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#niriss-ami-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"Table of Contents"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#table-of-contents","position":4},{"hierarchy":{"lvl1":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup (ignore if not using demo data)\n\nDirectory Setup\n\nDetector 1 Pipeline\n\nImage2 Pipeline\n\nAMI3 Pipeline\n\nVisualize the data\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#table-of-contents","position":5},{"hierarchy":{"lvl1":"1. Configuration"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-1-configuration","position":6},{"hierarchy":{"lvl1":"1. Configuration"},"content":"\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-1-configuration","position":7},{"hierarchy":{"lvl1":"1. Configuration","lvl3":"Install dependencies and parameters"},"type":"lvl3","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#install-dependencies-and-parameters","position":8},{"hierarchy":{"lvl1":"1. Configuration","lvl3":"Install dependencies and parameters"},"content":"\n\nTo make sure that the pipeline version is compatabile with the steps\ndiscussed below and the required dependencies and packages are installed,\nyou can create a fresh conda environment and install the provided\nrequirements.txt file:conda create -n niriss_ami_pipeline python=3.11\nconda activate niriss_ami_pipeline\npip install -r requirements.txt\n\nSet the basic parameters to use with this notebook. These will affect\nwhat data is used, where data is located (if already in disk), and\npipeline modules run in this data. The list of parameters are:\n\ndemo_mode\n\ndirectories with data\n\npipeline modules\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this\nmode this notebook will download example data from the Barbara A.\nMikulski Archive for Space Telescopes (\n\nMAST)\nand process it through the\npipeline. This will all happen in a local directory unless modified\nin \n\nSection 3\nbelow.\n\nSet demo_mode = False if you want to process your own data\nthat has already been downloaded and provide the location of the data.\n\n# Set parameters for demo_mode, channel, band, data mode directories, and \n# processing steps.\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    basedir = os.path.join(os.getcwd(), '')\n\n    # Point to location of science observation data.\n    # Assumes both science and PSF reference data are in the same directory\n    # with uncalibrated data in sci_dir/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    sci_dir = os.path.join(basedir, 'JWSTData/PID_1093/')\n\n# Set which filter to process (empty will process all)\nuse_filter = '' # E.g., F480M\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndodet1 = True  # calwebb_detector1\ndoimage2 = True  # calwebb_image2\ndoami3 = True  # calwebb_ami3\ndoviz = True  # Visualize calwebb_ami3 output\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#install-dependencies-and-parameters","position":9},{"hierarchy":{"lvl1":"1. Configuration","lvl2":"Set CRDS context and server"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#set-crds-context-and-server","position":10},{"hierarchy":{"lvl1":"1. Configuration","lvl2":"Set CRDS context and server"},"content":"Before importing CRDS and JWST modules, we need\nto configure our environment. This includes defining a CRDS cache\ndirectory in which to keep the reference files that will be used by the\ncalibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set\nalready, it will be set to create one in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#os.environ['CRDS_CONTEXT'] = 'jwst_1322.pmap'  # CRDS context for 1.16.0\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n    \n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path in use\nprint(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\nprint(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#set-crds-context-and-server","position":11},{"hierarchy":{"lvl1":"2. Package Imports"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-2-package-imports","position":12},{"hierarchy":{"lvl1":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\nimport json\nfrom pathlib import Path\nfrom collections import defaultdict\n\n# Numpy for doing calculations\nimport numpy as np\n\n# -----------------------Astroquery Imports--------------------------------\n# ASCII files, and downloading demo files\nfrom astroquery.mast import Observations\n\n# For visualizing data\nimport matplotlib.pyplot as plt\nfrom astropy.visualization import (MinMaxInterval, SqrtStretch,\n                                   ImageNormalize)\n\n# For file manipulation\nfrom astropy.io import fits\nimport asdf\n\n# for JWST calibration pipeline\nimport jwst\nimport crds\n\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Image2Pipeline\nfrom jwst.pipeline import Ami3Pipeline\n\n# JWST pipeline utilities\nfrom jwst import datamodels\nfrom jwst.associations import asn_from_list  # Tools for creating association files\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\n# Echo pipeline version and CRDS context in use\nprint(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\nprint(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-2-package-imports","position":13},{"hierarchy":{"lvl1":"2. Package Imports","lvl2":"Define convenience functions"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#define-convenience-functions","position":14},{"hierarchy":{"lvl1":"2. Package Imports","lvl2":"Define convenience functions"},"content":"\n\n# Define a convenience function to select only files of a given filter from an input set\ndef select_filter_files(files, use_filter):\n    files_culled = []\n    \n    if (use_filter != ''):\n        for file in files:\n            model = datamodels.open(file)\n            filt = model.meta.instrument.filter\n            if (filt == use_filter):\n                files_culled.append(file)\n            model.close()\n    else:\n        files_culled = files\n        \n    return files_culled\n\n\n\n# Define a convenience function to separate a list of input files into science and PSF reference exposures\ndef split_scipsf_files(files):\n    psffiles = []\n    scifiles = []\n\n    for file in files:\n        model = datamodels.open(file)\n        if model.meta.exposure.psf_reference is True:\n            psffiles.append(file)\n        else:\n            scifiles.append(file)\n        model.close()\n    \n    return scifiles, psffiles\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#define-convenience-functions","position":15},{"hierarchy":{"lvl1":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":16},{"hierarchy":{"lvl1":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"\n\nIf running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST has a dedicated service for JWST data retrieval, so the archive can\nbe searched by instrument keywords rather than just filenames or proposal IDs.\n\nThe list of searchable keywords for filtered JWST MAST queries\nis \n\nhere.\n\nFor illustrative purposes, we will use a single target and reference star pair. Each exposure was taken in the \n\nF480W filter filter with the \n\nnon-redundant mask (NRM) that enables AMI in the pupil.\n\nWe will start with uncalibrated data products. The files are named\njw010930nn001_03102_00001_nis_uncal.fits, where nn refers to the\nobservation number: in this case, observation 12 for the target and\nobservation 15 for the reference star.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    print('Running in demonstration mode and will download example data from MAST!')\n    \n    # --------------Program and observation information--------------\n    program = '01093'\n    sci_observtn = ['012', '015']  # Obs 12 is the target, Obs 15 is the reference star\n    visit = '001'\n    visitgroup = '03'\n    seq_id = \"1\"\n    act_id = '02'\n    expnum = '00001'\n\n    # --------------Program and observation directories--------------\n    data_dir = os.path.join('.', 'nis_ami_demo_data')\n    sci_dir = os.path.join(data_dir, 'PID_1093')\n    uncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\n\n    if not os.path.exists(uncal_dir):\n        os.makedirs(uncal_dir)\n\n    # Create directory if it does not exist\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n\n\n\nIdentify list of science (SCI) uncalibrated files associated with visits.\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    # Science data\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRISS/AMI\"],\n                                                   proposal_id=[program],\n                                                   filters=['F480M;NRM'],  # Data for Specific Filter\n                                                   obs_id=['jw' + program + '*'])\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE',\n                           'productSubGroupDescription': 'UNCAL',\n                           'calib_level': [1]}}\n\n    # Science files\n    sci_files = []\n\n    # Loop over visits identifying uncalibrated files that are associated\n    # with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files.extend(filtered_products['dataURI'])\n\n    # Select only the exposures we want to use based on filename\n    # Construct the filenames and select files based on them\n    filestrings = ['jw' + program + sciobs + visit + '_' + visitgroup + seq_id + act_id + '_' + expnum for sciobs in sci_observtn]\n    sci_files_to_download = [scifile for scifile in sci_files if any(filestr in scifile for filestr in filestrings)]\n    sci_files_to_download = sorted(set(sci_files_to_download))\n    print(f\"Science files selected for downloading: {len(sci_files_to_download)}\")\n\n\n\nDownload all the uncal files and place them into the appropriate\ndirectories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\nif demo_mode:\n    for filename in sci_files_to_download:\n        sci_manifest = Observations.download_file(filename,\n                                                  local_path=os.path.join(uncal_dir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":17},{"hierarchy":{"lvl1":"4. Directory Setup"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-4-directory-setup","position":18},{"hierarchy":{"lvl1":"4. Directory Setup"},"content":"\n\nSet up detailed paths to input/output stages here.\n\n# Define output subdirectories to keep science data products organized\n# -----------------------------Science Directories------------------------------\nuncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\nami3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_ami3 pipeline outputs will go here\n\n# We need to check that the desired output directories exist, and if not create them\n# Ensure filepaths for input data exist\nif not os.path.exists(uncal_dir):\n    os.makedirs(uncal_dir)\n \nif not os.path.exists(det1_dir):\n    os.makedirs(det1_dir)\nif not os.path.exists(image2_dir):\n    os.makedirs(image2_dir)\nif not os.path.exists(ami3_dir):\n    os.makedirs(ami3_dir)\n\n\n\nPrint the exposure parameters of all potential input files:\n\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n# Restrict to selected filter if applicable\nuncal_files = select_filter_files(uncal_files, use_filter)\n\nfor file in uncal_files:\n    model = datamodels.open(file)\n    # print file name\n    print(model.meta.filename)\n    # Print out exposure info\n    print(f\"Instrument: {model.meta.instrument.name}\")\n    print(f\"Filter: {model.meta.instrument.filter}\")\n    print(f\"Pupil: {model.meta.instrument.pupil}\")\n    print(f\"Number of integrations: {model.meta.exposure.nints}\")\n    print(f\"Number of groups: {model.meta.exposure.ngroups}\")\n    print(f\"Readout pattern: {model.meta.exposure.readpatt}\")\n    print(f\"Dither position number: {model.meta.dither.position_number}\")\n    print(\"\\n\")\n    model.close()\n\n\n\nFor the demo data, files should be for the NIRISS instrument\nusing the F480M filter in the \n\nFilter Wheel\nand the NRM in the Pupil Wheel.\n\nLikewise, both demo exposures use the \n\nNISRAPID readout pattern. The target has 5 groups per integration, and 69 integrations per exposure. The reference star has 12 groups per integration, and 61 integrations per exposure. They were taken at the same dither position; primary dither pattern position 1.\n\nFor more information about how JWST exposures are defined by up-the-ramp sampling, see the\n\n\nUnderstanding Exposure Times JDox article.\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-4-directory-setup","position":19},{"hierarchy":{"lvl1":"5. Detector1 Pipeline"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-5-detector1-pipeline","position":20},{"hierarchy":{"lvl1":"5. Detector1 Pipeline"},"content":"Run the datasets through the\n\n\nDetector1\nstage of the pipeline to apply detector level calibrations and create a\ncountrate data product where slopes are fitted to the integration ramps.\nThese *_rateints.fits products are 3D (nintegrations x nrows x ncols)\nand contain the fitted ramp slopes for each integration.\n2D countrate data products (*_rate.fits) are also\ncreated (nrows x ncols) which have been averaged over all\nintegrations.\n\nBy default, all steps in the Detector1 stage of the pipeline are run for\nNIRISS except: the ipc correction step and the gain_scale step. Note\nthat while the \n\npersistence step\nis set to run by default, this step does not automatically correct the\nscience data for persistence. The persistence step creates a\n*_trapsfilled.fits file which is a model that records the number\nof traps filled at each pixel at the end of an exposure. This file would be\nused as an input to the persistence step, via the input_trapsfilled\nargument, to correct a science exposure for persistence. Since persistence\nis not well calibrated for NIRISS, we do not perform a persistence\ncorrection and thus turn off this step to speed up calibration and to not\ncreate files that will not be used in the subsequent analysis. This step\ncan be turned off when running the pipeline in Python by doing:rate_result = Detector1Pipeline.call(uncal,steps={'persistence': {'skip': True}})\n\nor as indicated in the cell bellow using a dictionary.\n\nThe \n\ncharge_migration step\nis particularly important for NIRISS images to mitigate apparent flux loss\nin resampled images due to the spilling of charge from a central pixel into\nits neighboring pixels (see \n\nGoudfrooij et al. 2023\nfor details). Charge migration occurs when the accumulated charge in a\ncentral pixel exceeds a certain signal limit, which is ~25,000 ADU. This\nstep is turned on by default for NIRISS imaging mode when using CRDS\ncontexts of jwst_1159.pmap or later. Different signal limits for each filter are provided by the\n\n\npars-chargemigrationstep parameter files.\nUsers can specify a different signal limit by running this step with the\nsignal_threshold flag and entering another signal limit in units of ADU.\nThe effect is stronger when there is high contrast between a bright pixel and neighboring faint pixel,\nas is the case for the strongly peaked AMI PSF.\n\nFor AMI mode, preliminary investigation shows that dark subtraction does not improve calibration,\nand may in fact have a detrimental effect, so we turn it off here.\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = defaultdict(dict)\n\n# Step names are copied here for reference\ndet1_steps = ['group_scale', 'dq_init', 'saturation', 'ipc', 'superbias', 'refpix',\n              'linearity', 'persistence', 'dark_current', 'charge_migration',\n              'jump', 'ramp_fit', 'gain_scale']\n\n# Overrides for whether or not certain steps should be skipped\n# skipping the ipc, persistence, and dark steps\ndet1dict['ipc']['skip'] = True\ndet1dict['persistence']['skip'] = True\ndet1dict['dark_current']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits'  # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n\n# Turn on multi-core processing (off by default). Choose what fraction of cores to use (quarter, half, or all)\ndet1dict['jump']['maximum_cores'] = 'half'\n\n# Alter parameters of certain steps (example)\n#det1dict['charge_migration']['signal_threshold'] = X\n\n\n\nThe clean_flicker_noise step removes 1/f noise from calibrated ramp images, after the jump step and prior to performing the ramp_fitting step. By default, this step is skipped in the calwebb_detector1 pipeline for all instruments and modes. Although available, this step has not been extensively tested for the NIRISS AMI subarray and is thus not recommended at the present time.\n\nRun Detector1 stage of pipeline\n\n# Run Detector1 stage of pipeline, specifying:\n# output directory to save *_rateints.fits files\n# save_results flag set to True so the *rateints.fits files are saved\n# save_calibrated_ramp set to True so *ramp.fits files are saved\n\nif dodet1:\n    for uncal in uncal_files:\n        rate_result = Detector1Pipeline.call(uncal,\n                                             output_dir=det1_dir,\n                                             steps=det1dict,\n                                             save_results=True,\n                                             save_calibrated_ramp=True)\nelse:\n    print('Skipping Detector1 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime for Detector1: {time1 - time0:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-5-detector1-pipeline","position":21},{"hierarchy":{"lvl1":"5. Detector1 Pipeline","lvl2":"Exploring the data"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#exploring-the-data","position":22},{"hierarchy":{"lvl1":"5. Detector1 Pipeline","lvl2":"Exploring the data"},"content":"Identify *_rateints.fits files and verify which pipeline steps were run and\nwhich calibration reference files were applied.\n\nThe header contains information about which calibration steps were\ncompleted and skipped and which reference files were used to process the\ndata.\n\nif dodet1:\n    # find rateints files\n    rateints_files = sorted(glob.glob(os.path.join(det1_dir, '*_rateints.fits')))\n    # Restrict to selected filter if applicable\n    rateints_files = select_filter_files(rateints_files, use_filter)\n    \n    # Read in the first file as datamodel as an example\n    rateints = datamodels.open(rateints_files[0])\n    \n    # Check which steps were run\n    for step, status in rateints.meta.cal_step.instance.items():\n        print(f\"{step}: {status}\")\n\n\n\nCheck which CRDS version and reference files were used to calibrate the dataset:\n\nif dodet1:\n    for key, val in rateints.meta.ref_file.instance.items():\n        print(f\"{key}:\")\n        for param in rateints.meta.ref_file.instance[key]:\n            print(f\"\\t{rateints.meta.ref_file.instance[key][param]}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#exploring-the-data","position":23},{"hierarchy":{"lvl1":"6. Image2 Pipeline"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-6-image2-pipeline","position":24},{"hierarchy":{"lvl1":"6. Image2 Pipeline"},"content":"In the \n\nImage2 stage of the pipeline,\ncalibrated data products are created (*_cal.fits or\n*_calints.fits files, depending on whether the input files are\n*_rate.fits or *_rateints.fits).\n\nIn this pipeline processing stage, the data are \n\nflat fielded. For AMI, we do not perform any of the other Image2 steps such as photometric calibration, so our output data products still have units of countrate (ADU/s).\n\ntime_image2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nimage2dict = defaultdict(dict)\n\nimage2steps = ['assign_wcs', 'flat_field', 'photom', 'resample']\n\n# Overrides for whether or not certain steps should be skipped (example)\nimage2dict['photom']['skip'] = True\nimage2dict['resample']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n\n\n\nFind and sort the input files, ensuring use of absolute paths:\n\n# Use files from the detector1 output folder\nrateints_files = sorted(glob.glob(os.path.join(det1_dir, 'jw*rateints.fits')))\n# Restrict to selected filter if applicable\nrateints_files = select_filter_files(rateints_files, use_filter)\n\nfor ii in range(len(rateints_files)):\n    rateints_files[ii] = os.path.abspath(rateints_files[ii])\n\nprint(f\"Found {str(len(rateints_files))} science files\")\n\n\n\n# Run Image2 stage of pipeline, specifying:\n# output directory to save *_calints.fits files\n# save_results flag set to True so the calints files are saved\n\nif doimage2:\n    for rateints in rateints_files:\n        calints_result = Image2Pipeline.call(rateints,\n                                             output_dir=image2_dir,\n                                             steps=image2dict,\n                                             save_results=True)\nelse:\n    print(\"Skipping Image2 processing.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")\n\n\n\nVerify which pipeline steps were run:\n\nif doimage2:\n    # Identify *_calints.fits files\n    calints_files = sorted(glob.glob(os.path.join(image2_dir, '*_calints.fits')))\n    # Restrict to selected filter if applicable\n    calints_files = select_filter_files(calints_files, use_filter)\n\n    # Read in the first file as datamodel as an example\n    calints = datamodels.open(calints_files[0])\n    \n    # Check which steps were run\n    for step, status in calints.meta.cal_step.instance.items():\n        print(f\"{step}: {status}\")\n\n\n\nCheck which reference files were used to calibrate the dataset:\n\nif doimage2:\n    for key, val in calints.meta.ref_file.instance.items():\n        print(f\"{key}:\")\n        for param in calints.meta.ref_file.instance[key]:\n            print(f\"\\t{calints.meta.ref_file.instance[key][param]}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-6-image2-pipeline","position":25},{"hierarchy":{"lvl1":"7. AMI3 Pipeline"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-7-ami3-pipeline","position":26},{"hierarchy":{"lvl1":"7. AMI3 Pipeline"},"content":"In the \n\nAMI3 stage of the pipeline,\nthe target and reference star *_calints.fits files are analyzed to extract interferometric observables, and then the target’s observables are normalized by those of the reference star to produce a final set of calibrated observables.\n\nIn order to run the AMI3 stage, an \n\nAssociation file\nneeds to be created to inform the pipeline which exposures should be treated as targets and which as reference stars.\n\nBy default, the AMI3 stage of the pipeline performs the following steps on NIRISS data:\n\nami_analyze - fits a model to each integration of the input image and computes interferometric observables (fringe phases, amplitudes, and derived quantities).\n\nami_normalize - normalizes the target’s observables by the reference star observables.\n\nWhile a previous version of the AMI3 pipeline included an intermediate step to average together the observables from multiple exposures (ami_average), the step is not currently supported.\n\ntime_ami3 = time.perf_counter()\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-7-ami3-pipeline","position":27},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Create ASDF File"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#create-asdf-file","position":28},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Create ASDF File"},"content":"The ami_analyze step has several \n\noptional arguments, some can be provided in an ASDF file containing a particular data tree. In here we will modify this file to provide an specific affine distortion matrix (affine2d).\n\nFor affine2d the default parameters from commissioning are accessed with a special string: ‘commissioning.’ If affine2d = None, it will perform a search for the best-fit rotation only. To use a different affine distortion, such as one measured directly from the data or an ideal distortion, it must be specified in an ASDF file as shown here.\n\n# Example of writing an ASDF file specifying an affine distortion matrix to use\n\n# Create an ASDF file\nasdf_affine2d = os.path.join(sci_dir, 'affine2d_ideal.asdf')\n\naff_tree = {'mx': 1.,  # dimensionless x-magnification\n            'my': 1.,  # dimensionless y-magnification\n            'sx': 0.,  # dimensionless x shear\n            'sy': 0.,  # dimensionless y shear\n            'xo': 0.,  # x-offset in pupil space\n            'yo': 0.,  # y-offset in pupil space\n            'rotradccw': None}\n\nwith open(asdf_affine2d, 'wb') as fh:\n    af = asdf.AsdfFile(aff_tree)\n    af.write_to(fh)\n    \naf.close()\n\n\n\nAn example of using the affine distortion ASDF file created above is shown below.\n\n# Set up a dictionary to define how the AMI3 pipeline should be configured\n# Boilerplate dictionary setup\nami3dict = defaultdict(dict)\n\n# Options for ami_analyze step\n#ami3dict['ami_analyze']['firstfew'] = 5  # Analyze only the first 5 integrations to speed up demo\n#ami3dict['ami_analyze']['affine2d'] = 11  # Increase oversampling of image plane fit (increases runtime)\n#ami3dict['ami_analyze']['bandpass'] = 'myfile.asdf'  # Provide a custom bandpass (e.g., from synphot)\nami3dict['ami_analyze']['affine2d'] = asdf_affine2d  # Use the affine distortion ASDF file we created\nami3dict['ami_analyze']['save_results'] = True  # Turn on optional output results for display purposes\n\n# Overrides for whether or not certain steps should be skipped (example)\n#ami3dict['ami_normalize']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#ami3dict['ami_analyze']['override_nrm'] = 'mynrmfile.fits'  # NRM mask geometry file\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\n# AMI3 takes the calints.fits files\ncalints_files = sorted(glob.glob(os.path.join(image2_dir, 'jw*calints.fits')))\n# Restrict to selected filter if applicable\ncalints_files = select_filter_files(calints_files, use_filter)\n    \ncalints_files = [os.path.abspath(calints) for calints in calints_files]\n\nprint(f'Found {str(len(calints_files))} science files to process')\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#create-asdf-file","position":29},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Create Association Files"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#create-association-files","position":30},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Create Association Files"},"content":"An association file lists the exposures to calibrate together in Stage 3\nof the pipeline. Note that an association file is available for download\nfrom MAST, with a filename of *_asn.json, though it may require additional manipulation for AMI.\n\nHere we create association files for each pairing of input science and reference PSF exposures.\nNote that the final output products will have a rootname that is specified by the product_name\nin the association file.\n\n# Create Level 3 Associations\nif doami3:\n    # Separate inputs into science and PSF reference exposures\n    scifiles, psffiles = split_scipsf_files(calints_files)\n    \n    # Make an association file for every valid science/psf file pair\n    for sci in scifiles:\n        hdr = fits.getheader(sci)\n        thisfilter = hdr['FILTER']\n        # Potential PSF calibration files are those for which filter matches\n        psfoptions = select_filter_files(psffiles, thisfilter)\n        \n        for psf in psfoptions:\n            # Construct product name from the input headers\n            prodname = 'ami3_' + hdr['TARGPROP'] + '_' + hdr['FILTER'] + '_' + hdr['ACT_ID']\n            prodname = prodname.replace(\" \", \"\")\n    \n            asn = asn_from_list.asn_from_list([sci],\n                                              rule=DMS_Level3_Base,\n                                              product_name=prodname)\n    \n            # Set the second observation as the psf reference star\n            asn['products'][0]['members'].append({'expname': psf, 'exptype': 'psf'})\n            asn.data['asn_type'] = 'ami3'\n            asn.data['program'] = hdr['PROGRAM']    \n    \n            # Format association as .json file\n            asn_filename = prodname + '_asn.json'\n            _, serialized = asn.dump(format=\"json\")\n\n            # Write out association file\n            association_ami3 = os.path.join(sci_dir, asn_filename)\n            with open(association_ami3, \"w\") as fd:\n                fd.write(serialized)\n\n    # List all associations            \n    all_asn = sorted(glob.glob(os.path.join(sci_dir, '*_asn.json')))\n\n\n\nCheck that file paths have been correctly updated.\n\n# Open an ASN file as an example.\nif doami3:\n    if isinstance(all_asn, str):\n        with open(all_asn, 'r') as f_obj:\n            asnfile_data = json.load(f_obj)\n    elif isinstance(all_asn, list):\n        with open(all_asn[0], 'r') as f_obj:\n            asnfile_data = json.load(f_obj)\n    expanded_json = json.dumps(asnfile_data, indent=2)  # 'expanded=True' maps to 'indent'\n    print(expanded_json)\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#create-association-files","position":31},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Run AMI3 stage of the pipeline"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#run-ami3-stage-of-the-pipeline","position":32},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Run AMI3 stage of the pipeline"},"content":"For the target and reference star exposures listed in the association file, the\nAMI3 stage of the pipeline will produce:\n\n*ami-oi.fits files (one for the target, one for the reference star) from the ami_analyze step containing averaged interferometric observables\n\n*aminorm-oi.fits file from the ami_normalize step containing normalized interferometric observables\n\nThe *ami-oi.fits and *aminorm-oi.fits files adhere to the \n\nOIFITS2 format, which is a registered FITS standard for optical and infrared interferometry data.\n\n# Run Stage 3\nif doami3:\n    for asn in all_asn:\n        ami3_result = Ami3Pipeline.call(asn,\n                                        output_dir=ami3_dir,\n                                        steps=ami3dict)\nelse:\n    print('Skipping AMI3 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for AMI3: {time1 - time_ami3:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#run-ami3-stage-of-the-pipeline","position":33},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Verify which pipeline steps were run"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#verify-which-pipeline-steps-were-run","position":34},{"hierarchy":{"lvl1":"7. AMI3 Pipeline","lvl2":"Verify which pipeline steps were run"},"content":"\n\nif doami3:\n    # Identify *ami-oi.fits file and open as datamodel\n    ami_oi = glob.glob(os.path.join(ami3_dir, \"*_ami-oi.fits\"))[0]\n\n    with datamodels.open(ami_oi) as oi_f:\n        # Check which steps were run\n        for step, status in oi_f.meta.cal_step.instance.items():\n            print(f\"{step}: {status}\")\n\n\n\nCheck which reference files were used to calibrate the dataset\n\nif doami3:\n    for key, val in oi_f.meta.ref_file.instance.items():\n        print(f\"{key}:\")\n        for param in oi_f.meta.ref_file.instance[key]:\n            print(f\"\\t{oi_f.meta.ref_file.instance[key][param]}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#verify-which-pipeline-steps-were-run","position":35},{"hierarchy":{"lvl1":"8. Visualize the results"},"type":"lvl1","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-8-visualize-the-results","position":36},{"hierarchy":{"lvl1":"8. Visualize the results"},"content":"\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#id-8-visualize-the-results","position":37},{"hierarchy":{"lvl1":"8. Visualize the results","lvl2":"Plot interferometric observables"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#plot-interferometric-observables","position":38},{"hierarchy":{"lvl1":"8. Visualize the results","lvl2":"Plot interferometric observables"},"content":"We will now plot the interferometric observables for the target, reference star, and normalized target.\n\n# Define a function for plotting observables\n\ndef plot_observables(ami_oimodel):\n    # Read the observables from the datamodel\n    # Squared visibilities and uncertainties\n    vis2 = ami_oimodel.vis2[\"VIS2DATA\"]\n    vis2_err = ami_oimodel.vis2[\"VIS2ERR\"]\n    # Closure phases and uncertainties\n    t3phi = ami_oimodel.t3[\"T3PHI\"]\n    t3phi_err = ami_oimodel.t3[\"T3PHIERR\"]\n\n    # Construct baselines between the U and V coordinates of sub-apertures\n    baselines = (ami_oimodel.vis2['UCOORD']**2 + ami_oimodel.vis2['VCOORD']**2)**0.5\n\n    # Construct baselines between combinations of three sub-apertures\n    u1 = ami_oimodel.t3['U1COORD']\n    u2 = ami_oimodel.t3['U2COORD']\n    v1 = ami_oimodel.t3['V1COORD']\n    v2 = ami_oimodel.t3['V2COORD']\n    u3 = -(u1 + u2)\n    v3 = -(v1 + v2)\n    baselines_t3 = []\n    for k in range(len(u1)):\n        B1 = np.sqrt(u1[k]**2 + v1[k]**2)\n        B2 = np.sqrt(u2[k]**2 + v2[k]**2)\n        B3 = np.sqrt(u3[k]**2 + v3[k]**2)\n        # Use longest baseline of the three for plotting\n        baselines_t3.append(np.max([B1, B2, B3])) \n    baselines_t3 = np.array(baselines_t3)\n\n    # Plot closure phases, squared visibilities against their baselines \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    ax1.errorbar(baselines_t3, t3phi, yerr=t3phi_err, fmt=\"go\")\n    ax2.errorbar(baselines, vis2, yerr=vis2_err, fmt=\"go\")\n    ax1.set_xlabel(r\"$B_{max}$ [m]\", size=12)\n    ax1.set_ylabel(\"Closure phase [deg]\", size=12)\n    ax1.set_title(\"Closure Phase\", size=14)\n    ax2.set_title(\"Squared Visibility\", size=14)\n    ax2.set_xlabel(r\"$B_{max}$ [m]\", size=12)\n    ax2.set_ylabel(\"Squared Visibility\", size=12)\n    plt.suptitle(ami_oimodel.meta.filename, fontsize=16)\n    ax1.set_ylim([-3.5, 3.5])\n    ax2.set_ylim([0.5, 1.1]) \n\n\n\nFirst we’ll look at the target and reference star’s squared visibilities and closure phases. We plot the squared visibilities against their corresponding baselines (units of meters projected back to the primary meter). We plot the closure phases against the longest of the three baselines that forms the “closure triangle” whose phases were summed to calculate the closure phase.\n\nif doviz:\n    # Get the first target ami-oi.fits file\n    oi_scifile = sorted(glob.glob(os.path.join(ami3_dir, \"jw*_ami-oi.fits\")))\n    if isinstance(oi_scifile, list):\n        oi_scifile = oi_scifile[0]\n        \n    # Get the first PSF reference ami-oi fits file\n    oi_psffile = sorted(glob.glob(os.path.join(ami3_dir, \"jw*psf-ami-oi.fits\")))\n    if isinstance(oi_psffile, list):\n        oi_psffile = oi_psffile[0]\n\n    # Open them as datamodels\n    amioi_targ = datamodels.open(oi_scifile)\n    amioi_ref = datamodels.open(oi_psffile)\n\n    # Plot the observables\n    plot_observables(amioi_targ)\n    plot_observables(amioi_ref)\n\n\n\n\n\nThe top two scatter plots show the observables from the target observation, and the lower two show the observables from the reference star. For a perfect point source observation at single wavelength, we would expect to recover closure phases of zero and squared visibilites of unity.\n\nSince the closure phases are sensitive to asymmetries in the source brightness distribution, we can tell from the larger scatter of the target that it is likely not a point source; i.e, there is a faint companion. On the other hand, the reference star has closure phases with a much smaller scatter around zero. The squared visibilities of both decrease at longer wavelengths due to an effect called bandpass smearing. We expect that calibrating the target by the reference star should correct for this, as well as other systematics.\n\nNow we will plot the final calibrated data product; the target normalized by the reference star. The reference star closure phases are subtracted from the target closure phases, and the target squared visibilities are divided by the reference star squared visibilities.\n\nFurther scientific analysis on these calibrated OIFITS files can be done with community-developed analysis software like \n\nCANDID (\n\nGallenne et al. 2015) or \n\nFouriever to extract binary parameters, or an image reconstruction code like \n\nSQUEEZE (\n\nBaron et al. 2010) or BSMEM (\n\nSkilling & Bryan 1984, \n\nBuscher 1994, \n\nBaron & Young 2008).\n\nif doviz:\n    # Identify calibrated *_aminorm-oi.fits file and open as datamodel\n    abdor_oifits = glob.glob(os.path.join(ami3_dir, \"*_aminorm-oi.fits\"))[0]\n    amioi_norm = datamodels.open(abdor_oifits)\n\n    # Plot the observables\n    plot_observables(amioi_norm)\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#plot-interferometric-observables","position":39},{"hierarchy":{"lvl1":"8. Visualize the results","lvl2":"Display the best-fit model"},"type":"lvl2","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#display-the-best-fit-model","position":40},{"hierarchy":{"lvl1":"8. Visualize the results","lvl2":"Display the best-fit model"},"content":"We can also look at the cleaned data, model, and residual images that are saved in the auxiliary *amilg.fits data products:\n\nif doviz:\n    # Find the data files\n    amilg = sorted(glob.glob(os.path.join(ami3_dir, '*amilg.fits')))\n\n    # Open the first one as an AmiLGModel\n    firstfile = amilg[0]\n    amilgmodel = datamodels.open(firstfile)\n\n    # Plot the data, model, residual\n    norm = ImageNormalize(amilgmodel.norm_centered_image[0], \n                          interval=MinMaxInterval(), \n                          stretch=SqrtStretch())\n    fig, axs = plt.subplots(1, 3, figsize=(12, 5))\n    axs[0].set_title('Normalized Data')\n    im1 = axs[0].imshow(amilgmodel.norm_centered_image[0], norm=norm)\n    axs[1].set_title('Normalized Model')\n    im2 = axs[1].imshow(amilgmodel.norm_fit_image[0], norm=norm)\n    axs[2].set_title('Normalized Residual (Data-Model)')\n    im3 = axs[2].imshow(amilgmodel.norm_resid_image[0])\n\n    for im in [im1, im2, im3]:\n        plt.colorbar(im, shrink=.95, location='bottom', pad=.05)\n    for ax in axs:\n        ax.axis('off')\n        \n    plt.suptitle(os.path.basename(firstfile))\n    plt.tight_layout()\n\n\n\nEach image has been normalized by the peak pixel value of the data, and the data and model are displayed on a square root stretch to emphasize the fainter features. By looking at the residual (data - model) image, we can see that the model is a good fit to the data. This model achieves better contrast than ground-based NRM, but has not reached the binary contrast science requirements of AMI. The faint vertical striping in the background of the residual image is 1/f noise (flicker noise), which is an active area of improvement for the NIRISS/AMI team, as is the best method of correcting for charge migration.\n\n\n\n","type":"content","url":"/notebooks/niriss/ami/jwpipenb-niriss-ami#display-the-best-fit-model","position":41},{"hierarchy":{"lvl1":"NIRISS Imaging Pipeline Notebook"},"type":"lvl1","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging","position":0},{"hierarchy":{"lvl1":"NIRISS Imaging Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging","position":1},{"hierarchy":{"lvl1":"NIRISS Imaging Pipeline Notebook"},"type":"lvl1","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#niriss-imaging-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"NIRISS Imaging Pipeline Notebook"},"content":"Authors: S. LaMassa, R. Diaz\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0)\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#niriss-imaging-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"Purpose:"},"type":"lvl1","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#purpose","position":4},{"hierarchy":{"lvl1":"Purpose:"},"content":"This notebook provides a framework for processing generic Near-Infrared\nImager and Slitless Spectrograph (NIRISS) Imaging data through all\nthree James Webb Space Telescope (JWST) pipeline stages.  Data is assumed\nto be located in one observation folder according to paths set up below.\nIt should not be necessary to edit any cells other than in the\n\n\nConfiguration section unless modifying the standard\npipeline processing options.\n\nData:\nThis example is set up to use an example dataset is from\n\n\nProgram ID\n1475 (PI: Boyer, CoI: Volk) which is a sky flat calibration program.\nNIRCam is used as the primary instrument with NIRISS as a\n\n\ncoordinated parallel instrument.\nThe NIRISS imaging dataset uses a 17-step dither pattern.\n\nExample input data to use will be downloaded automatically unless\ndisabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context This notebook was written for the\ncalibration pipeline version given above. It sets the CRDS context\nto use the most recent version available in the JWST Calibration\nReference Data System (CRDS). If you use different pipeline versions or\nCRDS context, please read the relevant release notes\n(\n\nhere for pipeline,\n\n\nhere for CRDS) for possibly relevant\nchanges.\n\nUpdates:\nThis notebook is regularly updated as improvements are made to the\npipeline. Find the most up to date version of this notebook at:\n\n\nhttps://​github​.com​/spacetelescope​/jwst​-pipeline​-notebooks/\n\nRecent Changes:\nJanuary 24, 2024: original notebook released\nSeptemer 3, 2024: Updated text to highlight that IRAFStarFinder is the default\ncentroiding algorithm used in the Image3 tweakreg step of the pipeline for NIRISS imaging, as of\npipeline version 1.14.0 (build 10.2).\nNovember 22, 2024: Updates to workflow when skipping pipeline modules\nJanuary 31, 2025: Update to build 11.2, no significant changes.\nMay 5, 2025: Updated to jwst 1.18.0 (no significant changes).\nJuly 16, 2025: Updated to jwst 1.19.1 (no significant changes)\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#purpose","position":5},{"hierarchy":{"lvl1":"Purpose:","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#table-of-contents","position":6},{"hierarchy":{"lvl1":"Purpose:","lvl2":"Table of Contents"},"content":"Configuration\n\nPackage Imports\n\nDemo Mode Setup (ignore if not using demo data)\n\nDirectory Setup\n\nDetector 1 Pipeline\n\nImage2 Pipeline\n\nImage3 Pipeline\n\nVisualize the data\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#table-of-contents","position":7},{"hierarchy":{"lvl1":"Purpose:","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-1-configuration","position":8},{"hierarchy":{"lvl1":"Purpose:","lvl2":"1. Configuration"},"content":"\n\nSet basic configuration for running notebook.\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-1-configuration","position":9},{"hierarchy":{"lvl1":"Purpose:","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl4","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#install-dependencies-and-parameters","position":10},{"hierarchy":{"lvl1":"Purpose:","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"\n\nTo make sure that the pipeline version is compatabile with the steps\ndiscussed below and the required dependencies and packages are installed,\nyou can create a fresh conda environment and install the provided\nrequirements.txt file:conda create -n niriss_imaging_pipeline python=3.11\nconda activate niriss_imaging_pipeline\npip install -r requirements.txt\n\nSet the basic parameters to use with this notebook. These will affect\nwhat data is used, where data is located (if already in disk), and\npipeline modules run in this data. The list of parameters are:\n\ndemo_mode\n\ndirectories with data\n\npipeline modules\n\n# Basic import necessary for configuration\nimport os\n\n\n\nNote that demo_mode must be set appropriately below.\n\nSet demo_mode = True to run in demonstration mode. In this\nmode this notebook will download example data from the Barbara A.\nMikulski Archive for Space Telescopes (MAST) and process it through the\npipeline. This will all happen in a local directory unless modified\nin \n\nSection 3\nbelow.\n\nSet demo_mode = False if you want to process your own data\nthat has already been downloaded and provide the location of the data.\n\n# Set parameters for demo_mode, channel, band, data mode directories, and \n# processing steps.\n\n# -----------------------------Demo Mode---------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories------------------------\n# If demo_mode = False, look for user data in these paths\nif not demo_mode:\n    # Set directory paths for processing specific data; these will need\n    # to be changed to your local directory setup (below are given as\n    # examples)\n    user_home_dir = os.path.expanduser('~')\n\n    # Point to where science observation data are\n    # Assumes uncalibrated data in sci_dir/uncal/ and results in stage1,\n    # stage2, stage3 directories\n    sci_dir = os.path.join(user_home_dir, 'FlightData/APT1475/data/Obs006/')\n\n# --------------------------Set Processing Steps--------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing\ndodet1 = True  # calwebb_detector1\ndoimage2 = True  # calwebb_image2\ndoimage3 = True  # calwebb_image3\ndoviz = True # Visualize calwebb_image3 output\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#install-dependencies-and-parameters","position":11},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#set-crds-context-and-server","position":12},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Set CRDS context and server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need\nto configure our environment. This includes defining a CRDS cache\ndirectory in which to keep the reference files that will be used by the\ncalibration pipeline.\n\nIf the root directory for the local CRDS cache directory has not been set\nalready, it will be set to create one in the home directory.\n\n# ------------------------Set CRDS context and paths----------------------\n\n# Set CRDS context (if overriding to use a specific version of reference\n# files; leave commented out to use latest reference files by default)\n#%env CRDS_CONTEXT  jwst_1254.pmap\n\n# Check whether the local CRDS cache directory has been set.\n# If not, set it to the user home directory\nif (os.getenv('CRDS_PATH') is None):\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n# Check whether the CRDS server URL has been set.  If not, set it.\nif (os.getenv('CRDS_SERVER_URL') is None):\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Echo CRDS path in use\nprint(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\nprint(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#set-crds-context-and-server","position":13},{"hierarchy":{"lvl1":"Purpose:","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-2-package-imports","position":14},{"hierarchy":{"lvl1":"Purpose:","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# Basic system utilities for interacting with files\n# ----------------------General Imports------------------------------------\nimport glob\nimport time\nfrom pathlib import Path\n#import urllib.request\n\n# Numpy for doing calculations\nimport numpy as np\n\n# -----------------------Astroquery Imports--------------------------------\n# ASCII files, and downloading demo files\nfrom astroquery.mast import Observations\n\n# For visualizing images\nfrom jdaviz import Imviz\n\n# Astropy routines for visualizing detected sources:\nfrom astropy.table import Table\nfrom astropy.coordinates import SkyCoord\n\n# for JWST calibration pipeline\nimport jwst\nimport crds\n\nfrom jwst.pipeline import Detector1Pipeline\nfrom jwst.pipeline import Image2Pipeline\nfrom jwst.pipeline import Image3Pipeline\n\n# JWST pipeline utilities\nfrom jwst import datamodels\nfrom jwst.associations import asn_from_list  # Tools for creating association files\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n\n# Echo pipeline version and CRDS context in use\nprint(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\nprint(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")\n\n\n\n\n\n\n\n# Start a timer to keep track of runtime\ntime0 = time.perf_counter()\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-2-package-imports","position":15},{"hierarchy":{"lvl1":"Purpose:","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":16},{"hierarchy":{"lvl1":"Purpose:","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"\n\nIf running in demonstration mode, set up the program information to\nretrieve the uncalibrated data automatically from MAST using\n\n\nastroquery.\nMAST allows for flexibility of searching by the proposal ID and the\nobservation ID instead of just filenames.\n\nFor illustrative purposes, we focus on data taken through the NIRISS\n\n\nF150W filter\nand start with uncalibrated data products. The files are named\njw01475006001_02201_000nn_nis_uncal.fits, where nn refers to the\ndither step number which ranges from 01 - 17.\n\nMore information about the JWST file naming conventions can be found at:\n\n\nhttps://​jwst​-pipeline​.readthedocs​.io​/en​/latest​/jwst​/data​_products​/file​_naming​.html\n\n# Set up the program information and paths for demo program\nif demo_mode:\n    print('Running in demonstration mode and will download example data from MAST!')\n    program = '01475'\n    sci_observtn = \"006\"\n    visit = \"001\"\n    data_dir = os.path.join('.', 'nis_im_demo_data')\n    download_dir = data_dir\n    sci_dir = os.path.join(data_dir, 'Obs' + sci_observtn)\n    uncal_dir = os.path.join(sci_dir, 'uncal')\n\n    # Ensure filepaths for input data exist\n    if not os.path.exists(uncal_dir):\n        os.makedirs(uncal_dir)\n        \n    # Create directory if it does not exist\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n\n\n\nIdentify list of science (SCI) uncalibrated files associated with visits.\n\nSelects only filter f150w data\n\n# Obtain a list of observation IDs for the specified demo program\nif demo_mode:\n    # Science data\n    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRISS/IMAGE\"],\n                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n                                                   filters=['F150W'],  # Data for Specific Filter\n                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n                                                   )\n\n\n\n# Turn the list of visits into a list of uncalibrated data files\nif demo_mode:\n    # Define types of files to select\n    file_dict = {'uncal': {'product_type': 'SCIENCE',\n                           'productSubGroupDescription': 'UNCAL',\n                           'calib_level': [1]}}\n\n    # Science files\n    sci_files_to_download = []\n    # Loop over visits identifying uncalibrated files that are associated\n    # with them\n    for exposure in (sci_obs_id_table):\n        products = Observations.get_product_list(exposure)\n        for filetype, query_dict in file_dict.items():\n            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n                                                             calib_level=query_dict['calib_level'])\n            sci_files_to_download.extend(filtered_products['dataURI'])\n \n    sci_files_to_download = sorted(sci_files_to_download)\n    print(f\"Science files selected for downloading: {len(sci_files_to_download)}\")\n\n\n\nDownload all the uncal files and place them into the appropriate\ndirectories.\n\nWarning: If this notebook is halted during this step the downloaded file may be incomplete, and cause crashes later on!\n\nif demo_mode:\n    for filename in sci_files_to_download:\n        sci_manifest = Observations.download_file(filename,\n                                                  local_path=os.path.join(uncal_dir, Path(filename).name))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":17},{"hierarchy":{"lvl1":"Purpose:","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-4-directory-setup","position":18},{"hierarchy":{"lvl1":"Purpose:","lvl2":"4. Directory Setup"},"content":"\n\nSet up detailed paths to input/output stages here.\n\n# Define output subdirectories to keep science data products organized\nuncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\ndet1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\nimage2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\nimage3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n\n# We need to check that the desired output directories exist, and if not\n# create them\nif not os.path.exists(det1_dir):\n    os.makedirs(det1_dir)\nif not os.path.exists(image2_dir):\n    os.makedirs(image2_dir)\nif not os.path.exists(image3_dir):\n    os.makedirs(image3_dir)\n\n\n\nLook at the first file to determine exposure parameters and practice using\nJWST datamodels¶\n\nuncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n\n# print file name\nprint(uncal_files[0])\n\n# Open file as JWST datamodel\nexamine = datamodels.open(uncal_files[0])\n\n# Print out exposure info\nprint(f\"Instrument: {examine.meta.instrument.name}\")\nprint(f\"Filter: {examine.meta.instrument.filter}\")\nprint(f\"Pupil: {examine.meta.instrument.pupil}\")\nprint(f\"Number of integrations: {examine.meta.exposure.nints}\")\nprint(f\"Number of groups: {examine.meta.exposure.ngroups}\")\nprint(f\"Readout pattern: {examine.meta.exposure.readpatt}\")\nprint(f\"Dither position number: {examine.meta.dither.position_number}\")\nprint(\"\\n\")\n\n\n\n\n\nFrom the above, we confirm that the data file is for the NIRISS instrument\nusing the F150W filter in the \n\nPupil Wheel\ncrossed with the CLEAR filter in the Filter Wheel. This observation uses\nthe \n\nNIS readout pattern,\n16 groups per integration, and 1 integration per exposure. This data file\nis the 1st dither position in this exposure sequence. For more information\nabout how JWST exposures are defined by up-the-ramp sampling, see the\n\n\nUnderstanding Exposure Times JDox article.\n\nThis metadata will be the same for all exposures in this observation other\nthan the dither position number.\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-4-directory-setup","position":19},{"hierarchy":{"lvl1":"Purpose:","lvl2":"5. Detector1 Pipeline"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-5-detector1-pipeline","position":20},{"hierarchy":{"lvl1":"Purpose:","lvl2":"5. Detector1 Pipeline"},"content":"Run the datasets through the\n\n\nDetector1\nstage of the pipelineto apply detector level calibrations and create a\ncountrate data product where slopes are fitted to the integration ramps.\nThese *_rate.fits products are 2D (nrows x ncols), averaged over all\nintegrations. 3D countrate data products (*_rateints.fits) are also\ncreated (nintegrations x nrows x ncols) which have the fitted ramp slopes\nfor each integration.\n\nBy default, all steps in the Detector1 stage of the pipeline are run for\nNIRISS except: the ipc correction step and the gain_scale step. Note\nthat while the \n\npersistence step\nis set to run by default, this step does not automatically correct the\nscience data for persistence. The persistence step creates a\n*_trapsfilled.fits file which is a model that records the number\nof traps filled at each pixel at the end of an exposure. This file would be\nused as an input to the persistence step, via the input_trapsfilled\nargument, to correct a science exposure for persistence. Since persistence\nis not well calibrated for NIRISS, we do not perform a persistence\ncorrection and thus turn off this step to speed up calibration and to not\ncreate files that will not be used in the subsequent analysis. This step\ncan be turned off when running the pipeline in Python by doing:rate_result = Detector1Pipeline.call(uncal,steps={'persistence': {'skip': True}})\n\nor as indicated in the cell bellow using a dictionary.\n\nThe \n\ncharge_migration step\nis particularly important for NIRISS images to mitigate apparent flux loss\nin resampled images due to the spilling of charge from a central pixel into\nits neighboring pixels (see \n\nGoudfrooij et al. 2023\nfor details). Charge migration occurs when the accumulated charge in a\ncentral pixel exceeds a certain signal limit, which is ~25,000 ADU. This\nstep is turned on by default for NIRISS imaging mode when using CRDS\ncontexts of jwst_1159.pmap or later. Different signal limits for each filter are provided by the\n\n\npars-chargemigrationstep parameter files.\nUsers can specify a different signal limit by running this step with the\nsignal_threshold flag and entering another signal limit in units of ADU.\n\nAs of CRDS context jwst_1155.pmap and later, the\n\n\njump step\nof the DETECTOR1 stage of the pipeline will remove residuals associated\nwith \n\nsnowballs\nfor the NIRISS imaging mode. The default parameters for this correction,\nwhere expand_large_events set to True turns on the snowball halo\nremoval algorithm, are specified in the pars-jumpstep parameter\nreference files. Users may wish to alter parameters to optimize removal of\nsnowball residuals. Available parameters are discussed in the\n\n\nDetection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023).\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured\n\n# Boilerplate dictionary setup\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\ndet1dict['ipc'], det1dict['superbias'], det1dict['refpix'] = {}, {}, {}\ndet1dict['linearity'], det1dict['persistence'], det1dict['dark_current'], = {}, {}, {}\ndet1dict['charge_migration'], det1dict['jump'], det1dict['ramp_fit'] = {}, {}, {}\ndet1dict['gain_scale'] = {}\n\n# Overrides for whether or not certain steps should be skipped\n# skipping the persistence step\ndet1dict['persistence']['skip'] = True\n#det1dict['jump']['find_showers'] = False # Turn off detection of cosmic ray showers\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['saturation']['override_saturation'] = 'myfile.fits' # Saturation\n#det1dict['reset']['override_reset'] = 'myfile.fits' # Reset\n#det1dict['linearity']['override_linearity'] = 'myfile.fits' # Linearity\n#det1dict['rscd']['override_rscd'] = 'myfile.fits' # RSCD\n#det1dict['dark_current']['override_dark'] = 'myfile.fits' # Dark current subtraction\n#det1dict['jump']['override_gain'] = 'myfile.fits' # Gain used by jump step\n#det1dict['ramp_fit']['override_gain'] = 'myfile.fits' # Gain used by ramp fitting step\n#det1dict['jump']['override_readnoise'] = 'myfile.fits' # Read noise used by jump step\n#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits' # Read noise used by ramp fitting step\n\n# Turn on multi-core processing (off by default).  Choose what fraction of cores to use (quarter, half, or all)\ndet1dict['jump']['maximum_cores'] = 'half'\n\n# Alter parameters to optimize removal of snowball residuals (example)\n#det1dict['jump']['expand_large_events'] = True\n#det1dict['charge_migration']['signal_threshold'] = X\n\n\n\n# Run Detector1 stage of pipeline, specifying:\n# output directory to save *_rate.fits files\n# save_results flag set to True so the rate files are saved\n\nif dodet1:\n    for uncal in uncal_files:\n        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_dir, steps=det1dict, save_results=True,)\nelse:\n    print('Skipping Detector1 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime for Detector1: {time1 - time0:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-5-detector1-pipeline","position":21},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#exploring-the-data","position":22},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Exploring the data","lvl2":"5. Detector1 Pipeline"},"content":"Identify *_rate.fits files and verify which pipeline steps were run and\nwhich calibration reference files were applied.\n\nThe header contains information about which calibration steps were\ncompleted and skipped and which reference files were used to process the\ndata.\n\nif dodet1:\n    # find rate files\n    rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rate.fits')))\n\n    # Read in file as datamodel\n    rate_f = datamodels.open(rate_files[0])\n\n    # Check which steps were run\n    rate_f.meta.cal_step.instance\n\n\n\nCheck which reference files were used to calibrate the dataset:\n\nif dodet1:\n    rate_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#exploring-the-data","position":23},{"hierarchy":{"lvl1":"Purpose:","lvl2":"6. Image2 Pipeline"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-6-image2-pipeline","position":24},{"hierarchy":{"lvl1":"Purpose:","lvl2":"6. Image2 Pipeline"},"content":"In the \n\nImage2 stage of the pipeline,\ncalibrated unrectified data products are created (*_cal.fits or\n*_calints.fits files, depending on whether the input files are\n*_rate.fits or *_rateints.fits).\n\nIn this pipeline processing stage, the \n\nworld coordinate system (WCS)\nis assigned, the data are \n\nflat fielded,\nand a \n\nphotometric calibration\nis applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n\nBy default, the \n\nbackground subtraction step\nand the \n\nresampling step\nare turned off for NIRISS at this stage of the pipeline. The background\nsubtraction is turned off since there is no background template for the\nimaging mode and the local background is removed during the background\ncorrection for photometric measurements around individual sources. The\nresampling step occurs during the Image3 stage by default. While the\nresampling step can be turned on during the Image2 stage to, e.g.,\ngenerate a source catalog for each image, the data quality from the\nImage3 stage will be better since the bad pixels, which adversely affect\nboth the centroids and photometry in individual images, will be mostly\nremoved.\n\ntime_image2 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image2 pipeline should be configured.\n\n# Boilerplate dictionary setup\nimage2dict = {}\nimage2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\nimage2dict['photom'], image2dict['resample'] = {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image2dict['resample']['skip'] = False\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf'  # Spatial distortion (ASDF file)\n#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf'  # Imager filter offsets (ASDF file)\n#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf'  # Spectral distortion (ASDF file)\n#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf'  # Wavelength channel mapping (ASDF file)\n#image2dict['flat_field']['override_flat'] = 'myfile.fits'  # Pixel flatfield\n#image2dict['photom']['override_photom'] = 'myfile.fits'  # Photometric calibration array\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\nsstring = os.path.join(det1_dir, 'jw*rate.fits')  # Use files from the detector1 output folder\nrate_files = sorted(glob.glob(sstring))\nfor ii in range(0, len(rate_files)):\n    rate_files[ii] = os.path.abspath(rate_files[ii])\nrate_files = np.array(rate_files)\nprint(f\"Found  {str(len(rate_files))} science files\")\n\n\n\n# Run Image2 stage of pipeline, specifying:\n# output directory to save *_cal.fits files\n# save_results flag set to True so the rate files are saved\n\nif doimage2:\n    for rate in rate_files:\n        cal_result = Image2Pipeline.call(rate, output_dir=image2_dir, steps=image2dict, save_results=True)\nelse:\n    print(\"Skipping Image2 processing.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-6-image2-pipeline","position":25},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Verify which pipeline steps were run","lvl2":"6. Image2 Pipeline"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#verify-which-pipeline-steps-were-run","position":26},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Verify which pipeline steps were run","lvl2":"6. Image2 Pipeline"},"content":"\n\nif doimage2:\n    # Identify *_cal.fits files\n    cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_cal.fits')))\n\n    cal_f = datamodels.open(cal_files[0])\n\n    # Check which steps were run:\n    cal_f.meta.cal_step.instance\n\n\n\nCheck which reference files were used to calibrate the dataset:\n\nif doimage2:\n    cal_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#verify-which-pipeline-steps-were-run","position":27},{"hierarchy":{"lvl1":"Purpose:","lvl2":"7. Image3 Pipeline"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-7-image3-pipeline","position":28},{"hierarchy":{"lvl1":"Purpose:","lvl2":"7. Image3 Pipeline"},"content":"In the \n\nImage3 stage of the pipeline,\nthe individual *_cal.fits files for each of the dither positions are combined to one single\ndistortion corrected image. First, an \n\nAssociation\nneeds to be created to inform the pipeline that these individual exposures are linked together.\n\nBy default, the Image3 stage of the pipeline performs the following steps on NIRISS data:\n\ntweakreg -\ncreates source catalogs of pointlike sources for each input image. The source catalog for each input image is compared to each other to derive coordinate transforms to align the images relative to each other.\n\nAs of CRDS context jwst_1156.pmap and later, the pars-tweakreg parameter reference file for NIRISS performs an absolute astrometric correction to GAIA data release 3 by default (i.e., the abs_refcat parameter is set to GAIADR3). Though this default correction generally improves results compared with not doing this alignment, it could potentially result in poor performance in crowded or sparse fields, so users are encouraged to check astrometric accuracy and revisit this step if necessary.\n\nAs of pipeline version 1.14.0, the default source finding algorithm for NIRISS is IRAFStarFinder which testing shows returns good accuracy for undersampled NIRISS PSFs at short wavelengths \n\n(Goudfrooij 2022).\n\nskymatch - measures the background level from the sky to use as input into the subsequent outlier detection and resample steps.\n\noutlier detection - flags any remaining cosmic rays, bad pixels, or other artifacts not already flagged during the DETECTOR1 stage of the pipeline, using all input images to create a median image so that outliers in individual images can be identified.\n\nresample - resamples each input image based on its WCS and distortion information and creates a single undistorted image.\n\nsource catalog - creates a catalog of detected sources along with measured photometries and morphologies (i.e., point-like vs extended). Useful for quicklooks, but optimization is likely needed for specific science cases, which is an on-going investigation for the NIRISS team. Users may wish to experiment with changing the snr_threshold and deblend options. Modifications to the following parameters will not significantly improve data quality and it is advised to keep them at their default values: aperture_ee1, aperture_ee2, aperture_ee3, ci1_star_threshold, ci2_star_threshold.\n\ntime_image3 = time.perf_counter()\n\n\n\n# Set up a dictionary to define how the Image3 pipeline should be configured\n# Boilerplate dictionary setup\nimage3dict = {}\nimage3dict['assign_mtwcs'], image3dict['tweakreg'], image3dict['skymatch'] = {}, {}, {}\nimage3dict['outlier_detection'], image3dict['resample'], image3dict['source_catalog'] = {}, {}, {}\n\n# Overrides for whether or not certain steps should be skipped (example)\n#image3dict['outlier_detection']['skip'] = True\n\n# Overrides for various reference files\n# Files should be in the base local directory or provide full path\n#image3dict['source_catalog']['override_apcorr'] = 'myfile.fits'  # Aperture correction parameters\n#image3dict['source_catalog']['override_abvegaoffset'] = 'myfile.asdf'  # Data to convert from AB to Vega magnitudes (ASDF file)\n\n\n\nFind and sort all of the input files, ensuring use of absolute paths\n\n# Science Files need the cal.fits files\nsstring = os.path.join(image2_dir, 'jw*cal.fits')\ncal_files = sorted(glob.glob(sstring))\nfor ii in range(0, len(cal_files)):\n    cal_files[ii] = os.path.abspath(cal_files[ii])\ncalfiles = np.array(cal_files)\n\nprint(f'Found {str(len(cal_files))} science files to process')\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-7-image3-pipeline","position":29},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Create Association File","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#create-association-file","position":30},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Create Association File","lvl2":"7. Image3 Pipeline"},"content":"An association file lists the exposures to calibrated together in Stage 3\nof the pipeline. Note that an association file is available for download\nfrom MAST, with a filename of *_asn.json. Here we show how to create an\nassociation file to point to the data products created when processing data\nthrough the pipeline. Note that the output products will have a rootname\nthat is specified by the product_name in the association file. For\nthis tutorial, the rootname of the output products will be\nimage3_association.\n\n# Create a Level 3 Association\nif doimage3:\n    associations = asn_from_list.asn_from_list(cal_files,\n                                               rule=DMS_Level3_Base,\n                                               product_name='image3_association')\n    \n    associations.data['asn_type'] = 'image3'\n    program = datamodels.open(cal_files[0]).meta.observation.program_number\n    associations.data['program'] = program\n    \n    # Format association as .json file\n    asn_filename, serialized = associations.dump(format=\"json\")\n\n    # Write out association file\n    association_im3 = os.path.join(sci_dir, asn_filename)\n    with open(association_im3, \"w\") as fd:\n        fd.write(serialized)\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#create-association-file","position":31},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#run-image3-stage-of-the-pipeline","position":32},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Run Image3 stage of the pipeline","lvl2":"7. Image3 Pipeline"},"content":"Given the grouped exposures in the association file, the\nImage3 stage of the pipeline will produce:\n\na *_cr.fits file produced by the outlier_detection step, where the DQ array marks the pixels flagged as outliers.\n\na final combined, rectified image with name *_i2d.fits,\n\na source catalog with name *_cat.ecsv,\n\na segmentation map file (*_segm.fits) which has integer values at the pixel locations where a source is detected where the pixel values match the source ID number in the catalog.\n\n# Run Stage 3\nif doimage3:\n    i2d_result = Image3Pipeline.call(association_im3, output_dir=image3_dir, steps=image3dict, save_results=True)\nelse:\n    print('Skipping Spec3 processing')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\nprint(f\"Runtime for Image3: {time1 - time_image3:0.0f} seconds\")\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#run-image3-stage-of-the-pipeline","position":33},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Verify which pipeline steps were run","lvl2":"7. Image3 Pipeline"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#verify-which-pipeline-steps-were-run-1","position":34},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Verify which pipeline steps were run","lvl2":"7. Image3 Pipeline"},"content":"\n\nif doimage3:\n    # Identify *_i2d file and open as datamodel\n    i2d = glob.glob(os.path.join(image3_dir, \"*_i2d.fits\"))[0]\n    i2d_f = datamodels.open(i2d)\n\n    # Check which steps were run\n    i2d_f.meta.cal_step.instance\n\n\n\nCheck which reference files were used to calibrate the dataset\n\nif doimage3:\n    i2d_f.meta.ref_file.instance\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#verify-which-pipeline-steps-were-run-1","position":35},{"hierarchy":{"lvl1":"Purpose:","lvl2":"8. Visualize the drizzle-combined image"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-8-visualize-the-drizzle-combined-image","position":36},{"hierarchy":{"lvl1":"Purpose:","lvl2":"8. Visualize the drizzle-combined image"},"content":"We are using the \n\nImviz tool\nwithin the jdaviz package to visualize the NIRISS image.\n\nif doviz:\n    # Identify *_i2d file and open as datamodel\n    i2d = glob.glob(os.path.join(image3_dir, \"*_i2d.fits\"))[0]\n    i2d_f = datamodels.open(i2d)\n    \n    # Create an Imviz instance and set up default viewer\n    imviz_i2d = Imviz()\n    viewer_i2d = imviz_i2d.default_viewer\n\n    # Read in the science array for our visualization dataset:\n    i2d_science = i2d_f.data\n\n    # Load the dataset into Imviz\n    imviz_i2d.load_data(i2d_science)\n\n    # Visualize the dataset:\n    imviz_i2d.show()\n    \n    viewer_i2d.stretch = 'sqrt'\n    viewer_i2d.set_colormap('Viridis')\n    viewer_i2d.cuts = '95%'\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#id-8-visualize-the-drizzle-combined-image","position":37},{"hierarchy":{"lvl1":"Purpose:","lvl2":"Visualize Detected Sources"},"type":"lvl2","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#visualize-detected-sources","position":38},{"hierarchy":{"lvl1":"Purpose:","lvl2":"Visualize Detected Sources"},"content":"Using the source catalog created by the IMAGE3 stage of the pipeline,\nmark the detected sources, using different markers for point sources\nand extended sources. The source catalog is saved in\nimage3/image3_association_cat.ecsv file. We will need to\nread in the i2d file again to make sure the world\ncoordinate system (WCS) info is read in.\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#visualize-detected-sources","position":39},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Read in catalog file and identify point/extended sources","lvl2":"Visualize Detected Sources"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#read-in-catalog-file-and-identify-point-extended-sources","position":40},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Read in catalog file and identify point/extended sources","lvl2":"Visualize Detected Sources"},"content":"\n\nif doviz:\n    catalog_file = glob.glob(os.path.join(image3_dir, \"*_cat.ecsv\"))[0]\n    catalog = Table.read(catalog_file)\n\n    # To identify point/extended sources, use the 'is_extended' column in the source catalog\n    pt_src, = np.where(~catalog['is_extended'])\n    ext_src, = np.where(catalog['is_extended'])\n\n    # Define coordinates of point and extended sources\n    pt_coord = Table({'coord': [SkyCoord(ra=catalog['sky_centroid'][pt_src].ra,\n                                         dec=catalog['sky_centroid'][pt_src].dec)]})\n    ext_coord = Table({'coord': [SkyCoord(ra=catalog['sky_centroid'][ext_src].ra,\n                                          dec=catalog['sky_centroid'][ext_src].dec)]})\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#read-in-catalog-file-and-identify-point-extended-sources","position":41},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Mark the extended and point sources on the image","lvl2":"Visualize Detected Sources"},"type":"lvl3","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#mark-the-extended-and-point-sources-on-the-image","position":42},{"hierarchy":{"lvl1":"Purpose:","lvl3":"Mark the extended and point sources on the image","lvl2":"Visualize Detected Sources"},"content":"Display combined image; point sources will be marked by small pink circles and extended sources will be marked by larger white circles.\n\nif doviz:\n    # Read in i2d file to Imviz\n    imviz_cat = Imviz()\n    viewer_cat = imviz_cat.default_viewer\n    imviz_cat.load_data(i2d)\n\n    # Adjust settings for viewer\n    viewer_cat.stretch = 'sqrt'\n    viewer_cat.set_colormap('Viridis')\n    viewer_cat.cuts = '95%'\n\n    # Show the plot\n    imviz_cat.show()\n    \n    # Add marker for point sources:\n    viewer_cat.marker = {'color': 'pink', 'markersize': 50, 'fill': False}\n    viewer_cat.add_markers(pt_coord, use_skycoord=True, marker_name='point_sources')\n\n    # Add marker for extended sources:\n    viewer_cat.marker = {'color': 'white', 'markersize': 100, 'fill': False}\n    viewer_cat.add_markers(ext_coord, use_skycoord=True, marker_name='extended_sources')\n\n\n\n\n\n","type":"content","url":"/notebooks/niriss/imaging/jwpipenb-niriss-imaging#mark-the-extended-and-point-sources-on-the-image","position":43},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots","position":0},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook"},"content":"\n\nAuthors: Nikolay Nikolov (AURA Associate Scientist, \n\nnnikolov@stsci.edu); Kayli Glidic (\n\nkglidic@stsci.edu); NIRSpec branch\nLast Updated: July 16, 2025\nPipeline Version: 1.19.1 (Build 12.0, Context jwst_1413.pmap)\n\nPurpose:\nEnd-to-end calibration with the James Webb Space Telescope (JWST) pipeline is divided into three main processing stages. This notebook provides a framework for processing generic Near-Infrared Spectrograph (NIRSpec) Bright Object Time-Series (BOTS) data through \n\nstages 1-3 of the JWST pipeline, including how to use associations for multi-exposure observations and how to interact and work with JWST datamodels. In most cases, editing cells outside the \n\nConfiguration section is unnecessary unless the standard pipeline processing options or plot parameters need to be modified.\n\nData:\nThis notebook is set up to use transit observations of WASP-39b with the G395H grism, obtained by Proposal ID (PID) 1366, Observation 3. The demo data will automatically download unless disabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements. Any \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated to incorporate the latest pipeline improvements. Find the most up-to-date version of this notebook \n\nhere.\n\nRecent Changes:\n\nOctober 15, 2024: Converted notebook to follow standard template (\n\noriginal).\n\nNovember 6, 2024: Notebook updated to JWST pipeline version 1.16.0 (Build 11.1).\n\nFebruary 3, 2025: Notebook updated to JWST pipeline version 1.17.1 (Build 11.2)\n\nApril 18, 2025: Notebook updated to JWST pipeline version 1.18.0 (Build 11.3) added curved trace extraction.\n\nJuly 16, 2025: Updated to JWST pipeline version 1.19.1 (update plotting to work with new spectral data table format)\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots","position":1},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#table-of-contents","position":2},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"Table of Contents"},"content":"1. Configuration\n\n2. Package Imports\n\n3. Demo Mode Setup\n\n4. Directory Setup\n\n5. Stage 1: Detector1Pipeline (calwebb_detector1)\n\n5.1 Configure Detector1Pipeline\n\n5.2 Run Detector1Pipeline\n\n6. Stage 2: Spec2Pipeline (calwebb_spec2)\n\n6.1 Configure Spec2Pipeline\n\n6.2 Create Spec2Pipeline ASN Files\n\n6.3 Run Spec2Pipeline\n\n7. Stage 3: Tso3Pipeline (calwebb_tso3)\n\n7.1 Configure Tso3Pipeline\n\n7.2 Create Tso3Pipeline ASN Files\n\n7.3 Run Tso3Pipeline\n\n8. Visualizing the Data\n\n8.1 Display Detector1Pipeline Products\n\n8.2 Display Spec2Pipeline Products\n\n8.3 Display Tso3Pipeline Products\n\n9. Modifying the EXTRACT1D Reference File (as needed)\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#table-of-contents","position":3},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-1-configuration","position":4},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"1. Configuration"},"content":"","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-1-configuration","position":5},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#install-dependencies-and-parameters","position":6},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"To make sure that the pipeline version is compatible with the steps discussed below and that the required dependencies and packages get installed, you can create a fresh Conda environment and install the provided requirements.txt file before starting this notebook:conda create -n nirspec_bots_pipeline python=3.12\nconda activate nirspec_bots_pipeline\npip install -r requirements.txt\n\nSet the basic parameters to configure the notebook. These parameters determine what data gets used and where the data is located (if already on disk). The list of parameters includes:\n\ndemo_mode:\n\nTrue: Downloads example data from the \n\nBarbara A. Mikulski Archive for Space Telescopes (MAST) and processes it through the pipeline. All processing will occur in a local directory unless modified in \n\nSection 3 below.\n\nFalse: Process your own downloaded data; provide its location.\n\nDirectories with data:\n\nsci_dir: Directory where science observation data is stored.\n\n# Basic import necessary for configuration.\n# Uncomment logging to hide log information.\n\nimport os\nimport warnings\n#import logging\n\n# Control logging level: INFO, WARNING, ERROR\n# Run command logging.disable if want to hide logging\n# ERROR messages.\n#logging.disable(logging.ERROR)\nwarnings.simplefilter(\"ignore\", RuntimeWarning)\n\n\n\nNote that demo_mode must be set appropriately below.\n\n# Set parameters for demo_mode, data mode directories, and processing steps.\n\n# -------------------------------DEMO MODE-----------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# ----------------------------User Mode Directories--------------------------\nelse:  # If demo_mode = False, look for user data in these paths.\n\n    # Set directory paths for processing specific data; adjust to your local\n    # directory setup (examples provided below).\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n\n    # Directory to science observation data; expects uncalibrated data in\n    # sci_dir/uncal/ and results in stage1, stage2, and stage3 directories.\n    sci_dir = os.path.join(basedir, 'bots_data_01366/Obs003', '')\n\n# ---------------------------Set Processing Steps----------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing.\ndodet1 = True  # calwebb_detector1\ndospec2 = True  # calwebb_spec2\ndotso3 = True  # calwebb_tso3\ndoviz = True  # Visualize calwebb outputs\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#install-dependencies-and-parameters","position":7},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#set-crds-context-and-server","position":8},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline. If the local CRDS cache directory has not been set, it will automatically be created in the home directory.\n\nBuild Context Table\n\n# ------------------------Set CRDS context and paths------------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#os.environ['CRDS_CONTEXT'] = 'jwst_1364.pmap'  # CRDS context for 1.18.0\n\n# Set CRDS cache directory to user home if not already set.\nif os.getenv('CRDS_PATH') is None:\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds_cache')\n\n# Check whether the CRDS server URL has been set. If not, set it.\nif os.getenv('CRDS_SERVER_URL') is None:\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Output the current CRDS path and server URL in use.\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#set-crds-context-and-server","position":9},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-2-package-imports","position":10},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook.\nfrom IPython.display import display, HTML, JSON\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# ----------------------General Imports----------------------\nimport time\nimport glob\nimport json\nimport itertools\nimport numpy as np\n\n# -------------------- Astroquery Imports ----------------------\nfrom astroquery.mast import Observations\n\n# ----------------------Astropy Imports----------------------\n# Astropy utilities for opening FITS files, downloading demo files, etc.\nfrom astropy.io import fits\nfrom astropy.table import Table\nfrom astropy.stats import sigma_clip\nfrom astropy.visualization import ImageNormalize, ManualInterval, LogStretch\nfrom astropy.visualization import LinearStretch, AsinhStretch, simple_norm\n\n# ----------------------Plotting Imports---------------------\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.collections import PatchCollection\nfrom jwst.extract_1d.extract import location_from_wcs\n\n\n\nInstallation instructions for the JWST pipeline found here: \n\nJDox • \n\nReadtheDocs • \n\nGithub\n\n# ----------------------JWST Calibration Pipeline Imports----------------------\nimport jwst  # Import the base JWST and CRDS packages.\nimport crds\nfrom crds.client import api\nfrom stpipe import crds_client\n\n# JWST pipelines (each encompassing many steps).\nfrom jwst.pipeline import Detector1Pipeline  # calwebb_detector1\nfrom jwst.pipeline import Spec2Pipeline  # calwebb_spec2\nfrom jwst.pipeline import Tso3Pipeline  # calwebb_tso3\nfrom jwst.extract_1d import Extract1dStep  # Extract1D Step\n\n# JWST pipeline utilities\nfrom jwst import datamodels  # JWST pipeline utilities: datamodels.\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files.\nfrom jwst.associations.lib.rules_level2b import Asn_Lv2SpecTSO\nfrom jwst.associations.lib.rules_level3 import DMS_Level3_Base\n\n# Check the default context for the Pipeline version\ndefault_context = crds.get_default_context('jwst', state='build')\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(f\"Default CRDS Context for JWST Version {jwst.__version__}: {default_context}\")\nprint(f\"Using CRDS Context: {os.environ.get('CRDS_CONTEXT', default_context)}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-2-package-imports","position":11},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"Define Convenience Functions","lvl2":"2. Package Imports"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#define-convenience-functions","position":12},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"Define Convenience Functions","lvl2":"2. Package Imports"},"content":"Define a function that filters files based on detector, filter, grating, etc.\n\ndef get_matching(files, detector, filt, grating, fxd_slit, exp_type):\n    \"\"\"\n    Filters a list of FITS files to find those with matching \n    detector, filter, and grating for a specified exposure type.\n\n    Parameters\n    ----------\n    files : list of str\n        Paths to FITS files to check.\n    detector : str\n        Expected value of the DETECTOR keyword.\n    filt : str\n        Expected value of the FILTER keyword.\n    grating : str\n        Expected value of the GRATING keyword.\n    fxd_slit : str\n        Fixed slit name.\n    exp_type : str, optional\n        The exposure type to match.\n\n    Returns\n    -------\n    files_regular : list of str\n        Files with matching configuration and IS_IMPRT == False or missing.\n    files_imprint : list of str)\n        Files with matching configuration and IS_IMPRT == True.\n    \"\"\"\n    files_regular, files_imprint = [], []\n    for file in files:\n        # Skip if EXP_TYPE doesn't match the provided one.\n        if fits.getval(file, 'EXP_TYPE') != exp_type:\n            files_regular.append(file)\n            continue\n        # Check if DETECTOR, FILTER, GRATING, and SLIT match\n        detector_match = fits.getval(file, 'DETECTOR') == detector\n        filter_match = fits.getval(file, 'FILTER') == filt\n        grating_match = fits.getval(file, 'GRATING') == grating\n        slit_match = fits.getval(file, 'FXD_SLIT') == fxd_slit\n        if detector_match and filter_match and grating_match and slit_match:\n            # Only IFU and MOS observations have imprint exposures.\n            try:\n                is_imprt = fits.getval(file, 'IS_IMPRT')\n            except KeyError:\n                is_imprt = None\n            (files_imprint if is_imprt else files_regular).append(file)\n    return files_regular, files_imprint\n\n\n\n# Start a timer to keep track of runtime.\ntime0 = time.perf_counter()\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#define-convenience-functions","position":13},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":14},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"The data in this notebook is public and does not require a token. For other data sets, you may need to provide a token. For more infomation visit the \n\nastroquery documentation.\n\nIf running in demonstration mode, set up the program information to retrieve the uncalibrated data (_uncal.fits) automatically from MAST using astroquery. MAST provides flexibility by allowing searches based on proposal ID and observation ID, rather than relying solely on filenames. More information about the JWST file naming conventions can be found \n\nhere.\n\nThe BOTS demo data in this notebook is from the \n\nJWST Early Release Science (ERS) program 1366 and features transit observations of WASP-39b using the G395H grism. The program setup is briefly summarized in the table below.\n\nDemo Target: WASP-39b\n\n\n\n\n\nPROGRAM\n\n01366\n\nProgram number\n\nOBSERVTN\n\n003\n\nObservation number\n\nGRATING/FILTER\n\nG395H/F290LP\n\nλ: 2.87–5.14 μm (a high resolution, R ~ 2700)\n\nSUBARRAY\n\nSUB2048\n\nSubarray used (2048x32 pixels per integration, per group)\n\nNINTS\n\n465\n\nNumber of integrations in exposure\n\nNGROUPS\n\n70\n\nNumber of groups in integration\n\nDURATION\n\n29789.053 [s]\n\nTotal duration of one exposure\n\nREADPATT\n\nNRSRAPID\n\nReadout pattern\n\nPATTTYPE\n\nNONE\n\nPrimary dither pattern type\n\nNUMDTHPT\n\n1\n\nTotal number of points in pattern\n\nSRCTYAPT\n\nUNKNOWN\n\nSource type selected in APT\n\nNote: The presence of a physical gap between detectors affects high-resolution BOTS observations because the spectra are long enough to span both NIRSpec detectors. \n\nMore Info ...\n\nMany TSO exposures may contain a sufficiently large number of integrations (NINTS) so as to make their individual exposure products too large (in terms of file size on disk) to be able to handle conveniently. In these cases, the uncalibrated raw data for a given exposure are split into multiple “segmented” products, each of which is identified with a segment number (see segmented products).\n\nInformation about existing and planned JWST TSO programs for transiting exoplanets, including with the NIRSpec BOTS mode, can be obtained from \n\nTrExoLiSTS\n\n# Set up the program information for demo mode.\n\nif demo_mode:\n    print('Running in demonstration mode. '\n          'Example data will be downloaded from MAST!')\n\n    # NOTE:\n    # The data in this notebook is public and does not require a token.\n    # For other data sets, you may need to provide a token.\n    # Observations.login(token=None)\n\n    # --------------Program and observation information--------------\n    program = \"01366\"\n    sci_observtn = \"003\"\n    bg_observtn = None\n    filters = [\"F290LP;G395H\"]\n\n    # ----------Define the base and observation directories----------\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n    sci_dir = os.path.join(basedir, f'Obs{sci_observtn}')\n    uncal_dir = os.path.join(sci_dir, 'uncal/')\n\n    os.makedirs(uncal_dir, exist_ok=True)\nelse:\n    print('Running with user provided data.')\n\n\n\nClick on the following links to learn more about querying and downloading data:\n• \n\nDownloading data\n• \n\nObservations Class\n• \n\nProducts Field Descriptions\n\nCompile a table of files from MAST associated with the science (SCI) observation.\n\n# Obtain a list of observation IDs for the specified demo program.\n\nif demo_mode:\n    # --------------------SCIENCE Observation--------------------\n    sci_obs_id_table = Observations.query_criteria(instrument_name=['NIRSPEC/SLIT'],\n                                                   provenance_name=[\"CALJWST\"],\n                                                   obs_id=[f'*{program}*{sci_observtn}*'])\n\n\n\nFilter these tables to identify uncalibrated data and their association files for download from MAST.\n\nThe demo dataset consists of six segments of _uncal.fits files, each approximately 1.42 GB in size.\n\n# Convert visits into a list of uncalibrated data and ASN files.\n\nif demo_mode:\n    file_criteria = {'filters': filters, 'calib_level': [1],\n                     'productSubGroupDescription': 'UNCAL'}\n\n    # Initialize lists for science, background, and ASN files.\n    sci_downloads = []\n\n    pfilter = Observations.filter_products  # Alias for filter_products method.\n\n    # ----------Identify uncalibrated SCIENCE files associated with each visit----------\n    for exposure in sci_obs_id_table:\n        sci_products = Observations.get_product_list(exposure)\n\n        # Filter for full-size science files (exclude smaller confirmation images).\n        avg_sci_size = np.nanmean(sci_products['size'])\n        sci_products = sci_products[sci_products['size'] > avg_sci_size]\n        sci_downloads.extend(pfilter(sci_products, **file_criteria)['dataURI'])\n\n    # Filter out other observations and remove duplicates.\n    sci_downloads = {f for f in sci_downloads if f\"jw{program}{sci_observtn}\" in f}\n\n    print(f\"Science files selected for downloading: {len(sci_downloads)}\")\n\n\n\nDownoload the data\n\nWarning: If this notebook is halted during this step, the downloaded file may be incomplete, and cause crashes later on!\n\n# Download data and place them into the appropriate directories.\nif demo_mode:\n    for file in sci_downloads:\n        sci_manifest = Observations.download_file(file, local_path=uncal_dir)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":15},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-4-directory-setup","position":16},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"Set up detailed paths to input/output stages here.\n\n# Define/create output subdirectories to keep data products organized.\n\n# -----------------------------Science Directories------------------------------\nuncal_dir = os.path.join(sci_dir, 'uncal/')  # Uncalibrated pipeline inputs.\ndet1_dir = os.path.join(sci_dir, 'stage1/')  # calwebb_detector1 pipeline outputs.\nspec2_dir = os.path.join(sci_dir, 'stage2/')  # calwebb_spec2 pipeline outputs.\ntso3_dir = os.path.join(sci_dir, 'stage3/')  # calwebb_tso3 pipeline outputs.\nasn_dir = os.path.join(sci_dir, 'asn/')  # Association directory.\n\nos.makedirs(det1_dir, exist_ok=True)\nos.makedirs(spec2_dir, exist_ok=True)\nos.makedirs(tso3_dir, exist_ok=True)\nos.makedirs(asn_dir, exist_ok=True)\n\n\n\n# Print out the time benchmark.\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {round((time1 - time0) / 60.0, 1):0.4f} min\")\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-4-directory-setup","position":17},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-5-stage-1-detector1pipeline-calwebb-detector1","position":18},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"In this section, we process the data through the calwebb_detector1 pipeline to create Stage 1 \n\ndata products.\n\nInput: Raw exposure (_uncal.fits) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n\nOutput: Uncalibrated countrate (slope) image in units of DN/s:\n\n_rate.fits: A single countrate image averaged over multiple integrations (if available).\n\n_rateints.fits: Countrate images for each integration, saved in multiple extensions.\n\nThe Detector1Pipeline applies basic detector-level corrections on a group-by-group basis, followed by ramp fitting for all exposure types, commonly referred to as “ramps-to-slopes” processing.\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-5-stage-1-detector1pipeline-calwebb-detector1","position":19},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-5-1-configure-detector1pipeline","position":20},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"The Detector1Pipeline has the following steps available for NIRSpec BOTS:\n\ngroup_scale : Rescales pixel values to correct for improper onboard frame averaging.\n\ndq_init : Initializes the data quality (DQ) flags for the input data.\n\nsaturation : Flags pixels at or below the A/D floor or above the saturation threshold.\n\nsuperbias : Subtracts the superbias reference file from the input data.\n\nrefpix : Use reference pixels to correct bias drifts.\n\nlinearity : Applies a correction for non-linear detector response.\n\ndark_current : Subtracts the dark current reference file from the input data.\n\njump : Performs CR/jump detection on each ramp integration within an exposure.\n\nramp_fit : Determines the mean count rate (counts per second) for each pixel by performing a linear fit to the input data.\n\ngain_scale : Corrects pixel values for non-standard gain settings, primarily in NIRSpec subarray data.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox •\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Detector1Pipeline should be configured for BOTS data.\n\nTo override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\ndet1dict['superbias'], det1dict['refpix'], det1dict['linearity'] = {}, {}, {}\ndet1dict['dark_current'], det1dict['jump'], det1dict['clean_flicker_noise'] = {}, {}, {}\ndet1dict['ramp_fit'], det1dict['gain_scale'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['superbias']['override_superbias'] = 'myfile.fits' # Bias subtraction\n#det1dict['dark_current']['override_dark'] = 'myfile.fits' # Dark current subtraction\n\n# -----------------------------Set step parameters------------------------------\n# Overrides for whether or not certain steps should be skipped (example).\n#det1dict['linearity']['skip'] = True  # This is the default.\n\n# Turn on multi-core processing (off by default).\n# Choose what fraction of cores to use (quarter, half, or all).\ndet1dict['jump']['maximum_cores'] = 'quarter'\n#det1dict['ramp_fit']['maximum_cores'] = 'half'\n\n\n\nMany exposures are affected by artifacts known as \n\nsnowballs caused by large cosmic ray events. These artifacts are particularly significant in deep exposures with long integration times, with an estimated rate of one snowball per detector (FULL FRAME) per 20 seconds. To expand the number of pixels flagged as jumps around large cosmic ray events, set expand_large_events to True. An expand_factor of 3 works well for NIRSpec observations to cover most snowballs.\n\n# Turn on detection of cosmic ray snowballs (on by default).\ndet1dict['jump']['expand_large_events'] = True\ndet1dict['jump']['expand_factor'] = 3  # (default 2)\n\n\n\nJWST detector readout electronics (a.k.a. SIDECAR ASICs) generate significant 1/f noise during detector operations and signal digitization. This noise manifests as faint banding along the detector’s slow axis and varies from column to column. If not handled properly, the 1/f noise can introduce systematic errors and extra scatter in BOTS light curves. For more information, please visit \n\nJWST Time-Series Observations Noise Sources.\n\nFor NIRSpec data, the primary pipeline algorithm to address 1/f noise is nsclean in the Spec2Pipeline (Rauscher 2023) and is off by default. However, we turned on in Stage 2. An additional 1/f noise-cleaning algorithm, clean_flicker_noise, has been implemented at the group stage in the Detector1Pipeline. This step is also off by default.\n\n# Turn on 1/f noise correction in Stage 1? (off by default).\n#det1dict['clean_flicker_noise']['skip'] = False\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-5-1-configure-detector1pipeline","position":21},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-5-2-run-detector1pipeline","position":22},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Run the science files through the calwebb_detector1 pipeline using the .call() method.\n\nWe use .call() instead of .run() to ensure that the latest default parameters from CRDS are applied (\n\nReadtheDocs).\n\n# Final list of UNCAL files ready for Stage 1 processing.\nuncal_sci = sorted(glob.glob(uncal_dir + '*uncal.fits'))\n\nprint(f\"Science UNCAL Files:\\n{'-' * 20}\\n\" + \"\\n\".join(uncal_sci))\n\n\n\n# Run Stage 1 pipeline using the custom det1dict dictionary.\n\nif dodet1:\n    # ---------------------Science UNCAL files---------------------\n    for uncal_file in sorted(glob.glob(uncal_dir + '*uncal.fits')):\n        print(f\"Applying Stage 1 Corrections & Calibrations to: \"\n              f\"{os.path.basename(uncal_file)}\")\n\n        det1_result = Detector1Pipeline.call(uncal_file,\n                                             save_results=True,\n                                             steps=det1dict,\n                                             output_dir=det1_dir)\n\n        print(\"... Stage 1 has been completed!\\n\")\nelse:\n    print('Skipping Detector1 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Final list of RATE[INTS] files ready for Stage 2 processing.\nrate_sci = sorted(glob.glob(det1_dir + '*_rateints*.fits'))\nprint(f\"SCIENCE | RATE[INTS] Files:\\n{'-' * 20}\\n\" + \"\\n\".join(rate_sci))\n\n\n\n# Print out the time benchmark.\ntime2 = time.perf_counter()\nprint(f\"Runtime so far: {round((time2 - time0) / 60.0, 1):0.4f} min\")\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-5-2-run-detector1pipeline","position":23},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-stage-2-spec2pipeline-calwebb-spec2","position":24},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"In this section, we process our countrate (slope) image products from Stage 1 (calwebb_detector1) through the Spec2 (calwebb_spec2) pipeline to create Stage 2 \n\ndata products.\n\nInput: A single countrate (slope) image (_rate[ints].fits) or an association file listing multiple inputs.\n\nOutput: Calibrated products (rectified and unrectified) and 1D spectra.\n\n_cal[ints].fits: Calibrated 2D (unrectified) spectra (ncols x nrows).\n\n_x1d[ints].fits: Extracted 1D spectroscopic data (wavelength vs. flux).\n\nThe Spec2Pipeline applies additional instrumental corrections and calibrations (e.g., slit loss, path loss, etc.,) to countrate products that result in a fully calibrated individual exposure (per segment). The Spec2Pipeline also converts countrate products from units of DN/s to flux (Jy) for point sources and surface brightness (MJy/sr) for extended sources.\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-stage-2-spec2pipeline-calwebb-spec2","position":25},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-1-configure-spec2pipeline","position":26},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"The Spec2Pipeline has the following steps available for NIRSpec BOTS:\n\nassign_wcs: Assigns wavelength solution for spectra.\n\nbadpix_selfcal: Flags bad pixels in the input data using a self-calibration technique based on median filtering along the spectral axis.\n\nnsclean: Cleans 1/f noise.\n\nextract_2d : Extracts 2D arrays from spectral images.\n\nsrctype: Determines whether a spectroscopic source should be classified as a point or extended object.\n\nflat_field: Applies flat-field corrections to the input science dataset.\n\nphotom: Applies photometric calibrations to convert data from countrate to surface brightness or flux density.\n\npixel_replace: Interpolates and estimates flux values for pixels flagged as DO_NOT_USE in 2D extracted spectra.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox •\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Spec2Pipeline should be configured for BOTS data.\n\nWe opt to skip the flat_field and photom steps, as they can introduce scatter in the final light curves. This scatter arises from uncertainties in the limited number of flat field frames used to generate the flat field reference file, as well as uncertainties in the throughput used for converting the extracted spectra from relative to absolute units.\n\nTo override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Spec2 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\nspec2dict = {}\nspec2dict['assign_wcs'], spec2dict['badpix_selfcal'] = {}, {}\nspec2dict['nsclean'] = {}\nspec2dict['extract_2d'], spec2dict['srctype'] = {}, {}\nspec2dict['flat_field'], spec2dict['photom'] = {}, {}\nspec2dict['pixel_replace'], spec2dict['extract_1d'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n# spec2dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# -----------------------------Set step parameters------------------------------\n# Overrides for whether or not certain steps should be skipped.\n# Skip this step, because it can increase the light curve scatter.\nspec2dict['flat_field']['skip'] = True\nspec2dict['photom']['skip'] = True  # Skip this; BOTS observations are relative.\n\n# For Brown dwarf observation uncomment the following.\n#spec2dict['flat_field']['skip'] = False\n#spec2dict['photom']['skip'] = False\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels.\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\nspec2dict['pixel_replace']['skip'] = False\nspec2dict['pixel_replace']['n_adjacent_cols'] = 5\nspec2dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n# Run nsclean for 1/f noise.\nspec2dict['nsclean']['skip'] = False\nspec2dict['nsclean']['n_sigma'] = 0.1\nspec2dict['nsclean']['save_mask'] = True\nspec2dict['nsclean']['save_results'] = True\n\n# Build a sigma-clipped mask not based on WCS.\nspec2dict['nsclean']['mask_spectral_regions'] = False\nspec2dict['nsclean']['save_noise'] = True  # Save the 1/f noise removed.\n\nspec2dict['extract_1d']['apply_apcorr'] = False  # Turn off aperture correction.\n\n# Turn on bad pixel self-calibration, where all exposures on a given detector \n# are used to find and flag bad pixels that may have been missed by the bad pixel mask.\n# This step is experimental, and works best when dedicated background observations are included.\n#spec2dict['badpix_selfcal']['skip'] = False\n#spec2dict['badpix_selfcal']['flagfrac_upper'] = 0.005  # Fraction of pixels to flag.\n\n\n\nTo correct for 1/f noise with nsclean in Stage 2, see the demo notebook for BOTS data \n\nhere.\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-1-configure-spec2pipeline","position":27},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline ASN Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-2-create-spec2pipeline-asn-files","position":28},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline ASN Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Association (ASN) files define the relationships between multiple exposures, allowing them to get processed as a set rather than individually. Processing an ASN file enables the exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than as individual objects.\n\nStage 2 ASN files for BOTS data will typically only include science (not background) asn selfacal exposure types.\n\nThis notebook creates the Stage 2 ASN files using the files created in Stage 1.\n\nDefine a function that creates a Level 2 ASN file.\n\ndef writel2asn(onescifile, allscifiles, asnfile, product_name, exp_type):\n    \"\"\"\n    Create a Level 2 association file for each science exposure.\n\n    Parameters\n    ----------\n    onescifile : str\n        Path to the primary science exposure file.\n    allscifiles : list of str\n        List of all science exposure files.\n    asnfile : str\n        Path to write the output association file.\n    product_name : str\n        Name of the product for the association.\n    exp_type : str, optional\n        Exposure type to match against.\n\n    Returns\n    -------\n    True if the association was written successfully, and False otherwise \n    \"\"\"\n    # Define a basic association with the science file.\n    # Wrap in array since input was single exposure.\n    asn = afl.asn_from_list([onescifile], rule=Asn_Lv2SpecTSO, product_name=product_name)\n    asn.data['program'] = program if 'program' in globals() else \"9999\"\n\n    # Grab header information from the science file.\n    exp_type = fits.getval(onescifile, 'EXP_TYPE')\n    if (exp_type == exp_type):\n        detector = fits.getval(onescifile, 'DETECTOR')\n        grating = fits.getval(onescifile, 'GRATING')\n        filt = fits.getval(onescifile, 'FILTER')\n        fxd_slit = fits.getval(onescifile, 'FXD_SLIT')\n\n    # If the exposure type does not match, fail out \n    # to ensure TA images don't get processed by accident.\n    else:\n        return False\n\n    # Find all files matching the input configuration and split into regular/imprint.\n    use_sci, _ = get_matching(allscifiles, detector, filt, grating, fxd_slit, exp_type)\n\n    # Assign selfcal exposures.\n    for file in use_sci:\n        asn['products'][0]['members'].append({'expname': file, 'exptype': 'selfcal'})\n\n    # Write the association to a json file.\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n        \n    return True\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-2-create-spec2pipeline-asn-files","position":29},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-3-run-spec2pipeline","position":30},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Run the science files through the calwebb_spec2 pipeline using the .call() method.\n\n# Run Stage 2 pipeline using the custom spec2dict dictionary.\nstart = time.time()\n\nif dospec2:\n\n    # --------------------------Science ASN files--------------------------\n    for file in rate_sci:\n        try:  # Create ASN files.\n            asnfile = os.path.join(asn_dir, os.path.basename(file).replace('rateints.fits', 'l2asn.json'))\n            if writel2asn(file, rate_sci, asnfile, 'Level2', 'NRS_SLIT'):\n                print(f\"Applying Stage 2 Corrections & Calibrations to: {file}\")\n                spec2sci_result = Spec2Pipeline.call(asnfile,\n                                                     save_results=True,\n                                                     steps=spec2dict,\n                                                     output_dir=spec2_dir)\n        except Exception as e:\n            # A handle for when no slits fall on NRS1/2.\n            print(f\"Skipped processing {os.path.basename(asnfile)}: {e}\")\n    print(\"Stage 2 has been completed!\\n\")\nelse:\n    print('Skipping Spec2 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor “cal” or “calints” products that have not been resampled, the extraction region will be curved to follow the calculated trace.\n\n# Print out the time benchmark.\ntime3 = time.perf_counter()\nprint(f\"Runtime so far: {round((time3 - time0) / 60.0, 1):0.4f} min\")\n\n\n\n# List the Stage 2 products.\n\n# ------------------------1/f noise cleaned files-------------------------\nmasks = sorted(glob.glob(spec2_dir + '*mask.fits'))\nrate_sci_cl = sorted(glob.glob(spec2_dir + '*nsclean.fits'))\nflicker_noise = sorted(glob.glob(spec2_dir + '*flicker_noise.fits'))\n\nprint(f\"NSCLEAN | Masks :\\n{'-' * 20}\\n\" + \"\\n\".join(masks))\nprint(f\"NSCLEAN | 1/F NOISE:\\n{'-' * 20}\\n\" + \"\\n\".join(flicker_noise))\nprint(f\"NSCLEAN | RATE:\\n{'-' * 20}\\n\" + \"\\n\".join(rate_sci_cl))\n\n\n\n# List the Stage 2 products.\n\n# -----------------------------Science files-----------------------------\nsci_cal = sorted(glob.glob(spec2_dir + '*_calints.fits'))\nsci_x1d = sorted(glob.glob(spec2_dir + '*_x1dints.fits'))\n\nprint(f\"SCIENCE | Stage 2 CAL Products:\\n{'-' * 20}\\n\" + \"\\n\".join(sci_cal))\nprint(f\"SCIENCE | Stage 2 X1D Products:\\n{'-' * 20}\\n\" + \"\\n\".join(sci_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-6-3-run-spec2pipeline","position":31},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-stage-3-tso3pipeline-calwebb-tso3","position":32},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"content":"In this section, we process our calibrated spectra from Stage 2 (calwebb_spec2) through the Tso3 (calwebb_tso3) pipeline to create Stage 3 \n\ndata products.\n\nInput: An ASN file that lists multiple exposures or exposure segments of a science target (_calints.fits).\n\nOutput: Calibrated time-series spectra and white-light curve.\n\n_x1dints.fits: Extracted 1D spectroscopic data for all integrations contained in the input exposures.\n\n_whtlt.ecsv: An ASCII catalog in ecsv format containing the wavelength-integrated white-light photometry of the source.\n\nThe TSO3Pipeline performs additional corrections (e.g., outlier detection) and produces calibrated time-series spectra and white-light curve of the source object.\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-stage-3-tso3pipeline-calwebb-tso3","position":33},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"7.1 Configure Tso3Pipeline","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-1-configure-tso3pipeline","position":34},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"7.1 Configure Tso3Pipeline","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"content":"The Tso3Pipeline has the following steps available for NIRSpec BOTS:\n\noutlier_detection : Identification of bad pixels or cosmic-rays that remain in each of the input images.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets.\n\nwhite_light: Sums the spectroscopic flux over all wavelengths in each integration of a multi-integration extracted spectrum product to produce an integrated (“white”) flux as a function of time for the target.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox •\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the TSO3Pipeline should be configured for BOTS data.\n\nTo override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Tso3 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\ntso3dict = {}\ntso3dict['outlier_detection'], tso3dict['pixel_replace'] = {}, {}\ntso3dict['white_light'], tso3dict['extract_1d'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n# Overrides for various reference files.\n# Files should be in the base local directory or provide full path.\n#tso3dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels.\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\ntso3dict['pixel_replace']['skip'] = False\ntso3dict['pixel_replace']['n_adjacent_cols'] = 5\ntso3dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n\n\nBy default, the calwebb_tso3 pipeline will perform an outlier_detection and repeat spectral extraction. This workflow has been envisioned for spectral data from all JWST instruments. While the outlier_detection step could provide adequate corrections for non-TSO spectra, this is not the case for BOTS. We, therefore, opt to skip this step and repeat spectral extraction. It should be noted that in this case, the user can simply copy the extracted spectra from Spec2Pipeline and proceed with the white_light step instead.\n\n# -----------------------------Set step parameters------------------------------\n# Overrides for whether or not certain steps should be skipped (example).\ntso3dict['outlier_detection']['skip'] = True\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-1-configure-tso3pipeline","position":35},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"7.2 Create Tso3Pipeline ASN Files","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-2-create-tso3pipeline-asn-files","position":36},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"7.2 Create Tso3Pipeline ASN Files","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"content":"Stage 3 ASN files for BOTS data includes science exposure types. A Stage 3 ASN file requires at least one science file, although there is usually more than one. Note that the science exposures should be in the _calints.fits format.\n\nIn practice, Stage 3 ASN files can be downloaded directly from MAST, however, here we provide an example of manually creating Stage 3 ASN files. Below we create an ASN files for each GRATING/FILTER combination.\n\ndef writel3asn(scifiles, detector=None):\n    \"\"\"\n    Create a Level 3 association file.\n\n    Parameters\n    ----------\n    scifiles : list of str\n        List of all science exposure files.\n    detector : str, optional\n        Detector names to include. If None, include all.\n    \n    Returns\n    -------\n    None.\n    \"\"\"\n    # Filter based on GRATING/FILTER.\n    from collections import defaultdict\n    grouped = defaultdict(lambda: {'sci': [], 'bg': []})\n\n    for f in scifiles:\n        if detector:\n            det = fits.getval(f, 'DETECTOR')\n            if det != detector:\n                continue  # Skip if detector does not match.\n\n        filt = fits.getval(f, 'FILTER')\n        grat = fits.getval(f, 'GRATING')\n        grouped[(filt, grat)]['sci'].append(f)\n\n    # Make ASN for each FILTER/GRATING.\n    for (filt, grat), files in grouped.items():\n        name = f\"{filt}_{grat}\".lower()\n        asnfile = os.path.join(asn_dir, f\"{name}_l3asn.json\")\n        asn = afl.asn_from_list(files['sci'], rule=DMS_Level3_Base, product_name=name)\n        asn.data['asn_type'] = 'tso3'\n        asn.data['program'] = program if 'program' in globals() else \"9999\"\n\n        with open(asnfile, 'w') as f:\n            f.write(asn.dump()[1])\n    print(\"Level 3 ASN creation complete!\")\n\n\n\nif dotso3:\n    # Restrict to one detector for the demo.\n    writel3asn(sci_cal, detector='NRS1' if demo_mode else None)\n\n\n\nCheck that the association files for Stage 3\n\n# Open an ASN file as an example.\n# Check that file paths have been correctly updated.\nif dotso3:\n    spec3_asn = glob.glob(asn_dir + '*l3asn.json')[0]\n    with open(spec3_asn, 'r') as f_obj:\n        asnfile_data = json.load(f_obj)\n    display(JSON(asnfile_data, expanded=True))\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-2-create-tso3pipeline-asn-files","position":37},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"7.3 Run Tso3Pipeline","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-3-run-tso3pipeline","position":38},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"7.3 Run Tso3Pipeline","lvl2":"7. Stage 3: Tso3Pipeline (calwebb_tso3)"},"content":"Run the science files through the calwebb_tso3 pipeline using the .call() method.\n\n# Run Stage 3 pipeline using the custom tso33dict dictionary.\nif dotso3:\n    for tso3_asn in glob.glob(asn_dir + '*l3asn.json'):\n        print(f\"Applying Stage 3 to: {os.path.basename(tso3_asn)}\")\n        tso3_result = Tso3Pipeline.call(tso3_asn,\n                                        save_results=True,\n                                        steps=tso3dict,\n                                        output_dir=tso3_dir)\n    print(\"Stage 3 has been completed!\\n\")\nelse:\n    print(\"Skipping Stage 3. \\n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmark.\ntime4 = time.perf_counter()\nprint(f\"Runtime so far: {round((time4 - time0) / 60.0, 1):0.4f} min\")\n\n\n\n# List the Stage 3 products.\n\nstage3_whtlt = sorted(glob.glob(tso3_dir + '*_whtlt.ecsv'))\nstage3_x1d = sorted(glob.glob(tso3_dir + '*_x1dints.fits'))\n\nprint(f\"Stage 3 White Light Products:\\n{'-' * 20}\\n\" + \"\\n\".join(stage3_whtlt))\nprint(f\"Stage 3 X1D Products:\\n{'-' * 20}\\n\" + \"\\n\".join(stage3_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-7-3-run-tso3pipeline","position":39},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"8. Visualizing the Data"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-visualizing-the-data","position":40},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"8. Visualizing the Data"},"content":"Define convenience funcitons for visualization.\n\nFunction to consolidate all extracted spectra (from each segment) and their corresponding timestamps into single large arrays using the helper function compile_segments. This structure simplifies the analysis and plotting.\n\nWith the consolidated arrays, we plot three one-dimensional spectra from the spectral time series using the display_spectra helper function. We also offset two spectra by a constant amount to make them easier to distinguish since nearly all TSO spectra have the same flux (except reduced flux during transit or secondary eclipse).\n\ndef compile_segments(data_products):\n    \"\"\"\n    Compiles extracted 1D spectra, corresponding timestamps,\n    and wavelengths from a list of X1D data products.\n\n    Parameters\n    ----------\n    data_products : list of str\n        A list of data products (X1DINT files).\n\n    Returns\n    -------\n    all_spec_1D : numpy.ndarray\n        A 2D array where each row corresponds to a spectrum from a single\n        integration, and columns represent flux values at each wavelength.\n    all_times : numpy.ndarray\n        A 1D array containing the mid-integration times (e.g., BJD_TDB) for\n        each spectrum in `all_spec_1D`.\n    \"\"\"\n\n    data_products = [data_products] if isinstance(data_products, str) else data_products\n\n    # Return empty arrays if the input list is empty.\n    if not data_products:\n        return None, None\n\n    for i, product in enumerate(data_products):\n\n        x1d = datamodels.open(product)\n        \n        n_spec, n_pix = x1d.spec[0].spec_table.WAVELENGTH.shape\n        seg_spec_1D = np.zeros([n_spec, n_pix])\n        wave_um = x1d.spec[0].spec_table.WAVELENGTH[0, :]\n\n        for j in range(n_spec):\n            seg_spec_1D[j, :] = x1d.spec[0].spec_table.FLUX[j, :]\n\n        if i == 0:\n            all_spec_1D = seg_spec_1D\n            all_times = x1d.int_times.int_mid_BJD_TDB\n        if i > 0:\n            all_spec_1D = np.concatenate((all_spec_1D, seg_spec_1D), axis=0)\n            all_times = np.concatenate((all_times,\n                                        x1d.int_times.int_mid_BJD_TDB),\n                                       axis=0)\n\n    # We also trim several columns at the start and end of the spectra.\n    # These belong to the reference pixels and are marked 'nan'.\n    print(\"Trimming first/last 5 reference pixels with nan-values ...\")\n    all_spec_1D = all_spec_1D[:, 5:-5]\n    wave_um = wave_um[5:-5]\n\n    return all_spec_1D, all_times, wave_um\n\n\n\nFunction to display Stage 1 products.\n\ndef display_rate(rates,\n                 slits_models=[],\n                 integration=0,\n                 extname='data',\n                 cmap='viridis',\n                 bad_color=(1, 0.7, 0.7),\n                 vmin=None,\n                 vmax=None,\n                 scale='asinh',\n                 aspect='auto',\n                 title_prefix=None,\n                 title_path=False,\n                 save_plot=False):\n    \"\"\"\n    Display countrate images.\n\n    Parameters\n    ----------\n    rates : list of str\n        A list of RATE[INTS] files to be displayed.\n    slits_models : list of str, optional\n        A list of CAL[INTS] or S2D files containing the slit models.\n        If provided, slit cutouts will be overlaid on the countrate images.\n    integration : {None, 'min', int}, optional\n        Specifies the integration to use for multi-integration data.\n        If 'min', the minimum value across all integrations is used.\n        If an integer, the specific integration index is used (default 0).\n    extname : str, optional\n        The name of the data extension to extract from ('data', 'dq', etc.).\n    cmap : str, optional\n        Colormap to use for displaying the image. Default is 'viridis'.\n    bad_color : tuple of float, optional\n        Color to use for NaN pixels. Default is light red (1, 0.7, 0.7).\n    vmin : float, optional\n        Minimum value for color scaling. If None, determined from the data.\n    vmax : float, optional\n        Maximum value for color scaling. If None, determined from the data.\n    scale : {'linear', 'log', 'asinh'}, optional\n        Scale to use for the image normalization. Default is 'asinh'.\n    aspect : str, optional\n        Aspect ratio of the plot. Default is 'auto'.\n    title_prefix : str, optional\n        Optional prefix for the plot title.\n    title_path : bool, optional\n        If True, uses the full file path for the title;\n        otherwise, uses the basename. Default is False.\n    save_plot : bool, optional\n        If True, saves the plot as a PNG file. Default is False.\n    \"\"\"\n\n    # -------------------------------Check Inputs-------------------------------\n    rates = [rates] if isinstance(rates, str) else rates\n    slits_models = [slits_models] if isinstance(slits_models, str) else slits_models\n    nrates = len(rates)\n\n    # ------------------------------Set up figures------------------------------\n    fig, axes = plt.subplots(nrates, 1, figsize=(12, 12 * nrates),\n                             sharex=True, height_ratios=[1] * nrates)\n    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n    axes = [axes] if nrates == 1 else axes\n\n    cmap = plt.get_cmap(cmap)  # Set up colormap and bad pixel color.\n    cmap.set_bad(bad_color, 1.0)\n\n    # ---------------------------Plot countrate image---------------------------\n    for i, (rate, cal) in enumerate(itertools.zip_longest(rates,\n                                                          slits_models,\n                                                          fillvalue=None)):\n\n        # -------------------Open files as JWST datamodels-------------------\n        model = datamodels.open(rate)\n        slits_model = datamodels.open(cal) if cal else None\n\n        # -----------------------Extract the 2D/3D data----------------------\n        data_2d = getattr(model, extname)\n        if data_2d.ndim == 3:  # Handle multi-integration data.\n            if integration == 'min':\n                data_2d = np.nanmin(data_2d, axis=0)\n            elif isinstance(integration, int) and 0 <= integration < data_2d.shape[0]:\n                data_2d = data_2d[integration]\n            else:\n                raise ValueError(f\"Invalid integration '{integration}' for 3D data.\")\n\n        # ---------------------------Scale the data-------------------------\n        sigma_clipped_data = sigma_clip(data_2d, sigma=5, maxiters=3)\n        vmin = np.nanmin(sigma_clipped_data) if vmin is None else vmin\n        vmax = np.nanmax(sigma_clipped_data) if vmax is None else vmax\n        stretch_map = {'log': LogStretch(), 'linear': LinearStretch(),\n                       'asinh': AsinhStretch()}\n        if scale in stretch_map:\n            norm = ImageNormalize(sigma_clipped_data,\n                                  interval=ManualInterval(vmin=vmin, vmax=vmax),\n                                  stretch=stretch_map[scale])\n        else:\n            norm = simple_norm(sigma_clipped_data, vmin=vmin, vmax=vmax)\n\n        # ----------------Plot the countrate image & colorbar---------------\n        plt.subplots_adjust(left=0.05, right=0.85)\n        im = axes[i].imshow(data_2d, origin='lower', cmap=cmap,\n                            norm=norm, aspect=aspect, interpolation='nearest')\n        units = model.meta.bunit_data\n        cbar_ax = fig.add_axes([axes[i].get_position().x1 + 0.02,\n                                axes[i].get_position().y0, 0.02,\n                                axes[i].get_position().height])\n        cbar = fig.colorbar(im, cax=cbar_ax)\n        cbar.set_label(units, fontsize=12)\n\n        # -----------------Draw slits and label source ids------------------\n        # slits_model can be s2d/cal from spec2 - contains slit models for all sources.\n        if slits_model:\n            slit_patches = []\n            for slit in slits_model.slits:\n                slit_patch = Rectangle((slit.xstart, slit.ystart),\n                                       slit.xsize, slit.ysize)\n                slit_patches.append(slit_patch)\n                y = slit.ystart + slit.ysize / 2\n                x = slit.xstart if 'nrs1' in rate else slit.xstart + slit.xsize\n                ha = 'right' if 'nrs1' in rate else 'left'\n                plt.text(x, y, slit.source_id, color='w', ha=ha, va='center',\n                         fontsize=7, path_effects=[], weight='bold')\n            axes[i].add_collection(PatchCollection(slit_patches, ec='r', fc='None'))\n\n        # -----------------Construct title and axis labels------------------\n        filename = model.meta.filename\n        title = (f\"{title_prefix + ' ' if title_prefix else ''}\"\n                 f\"{filename if title_path else os.path.basename(filename)}\")\n        if integration is not None:\n            title = title.replace('rateints', f'rateints[{integration}]')\n        axes[i].set_title(title, fontsize=14)\n        axes[i].set_xlabel(\"Pixel Column\", fontsize=12)\n        axes[i].set_ylabel(\"Pixel Row\", fontsize=12)\n\n        # -------------------------Save the figure?-------------------------\n        if save_plot:\n            save_plot = rate.replace('fits', 'png')\n            if integration:\n                save_plot = save_plot.replace('.png', '%s.png' % integration)\n            fig.savefig(save_plot, dpi=200)\n\n        fig.show()\n\n\n\nFunction to display the calibrated BOTS spectra from Stage 2.\n\ndef display_spectra(data_products,\n                    integrations=0,\n                    offsets=0):\n    \"\"\"\n    Displays the calibrated BOTS spectra from Stage 2.\n\n    Parameters\n    ----------\n    data_products : str or list of str\n        File path or list of file paths to X1D data products.\n    integrations : int or list of int, optional\n        Indices of integrations to plot (default is 0).\n    offset : int or list of int, optional\n        Offsets to apply between spectra (default is 0).\n\n    Returns\n    -------\n    None.\n    \"\"\"\n\n    # -----------------------Check and sort input lists-----------------------\n    data_products = [data_products] if isinstance(data_products, str) else data_products\n    integrations = [integrations] if isinstance(integrations, int) else integrations\n    offsets = [offsets] * len(integrations) if isinstance(offsets, (int)) else offsets\n\n    # Sort NRS1 and NRS2 products.\n    products = {\n        \"NRS1\": [f for f in sorted(data_products) if 'nrs1' in f],\n        \"NRS2\": [f for f in sorted(data_products) if 'nrs2' in f]\n    }\n\n    # ----------Load extracted spectra and time stamps into one array---------\n    for key, product_list in products.items():\n        if not product_list:\n            continue\n\n        # Load all spectra from list of segments.\n        # This makes plotting and analysis easier.\n        all_spec1D, all_times, wave_um = compile_segments(product_list)\n\n        # Print summary.\n        print(f\"\\n{key} Summary:\")\n        print(f\"  Total number of time stamps: {len(all_spec1D)}\")\n        print(f\"  Total number of 1D spectra:  {all_spec1D.shape[0]}\")\n        print(f\"  Total number of columns:     {all_spec1D.shape[1]}\")\n        print(f\"  Total length of wavemap:     {len(wave_um)}\\n\")\n\n        # --------------------------Set up figures--------------------------\n        fig, axes = plt.subplots(2, 1, figsize=(15, 10), height_ratios=[1, 2])\n        fig.subplots_adjust(hspace=0.2, wspace=0.2)\n        ax2d, ax1d = axes\n\n        for idx, i in enumerate(integrations):\n            ax1d.plot(wave_um, all_spec1D[i, :] - offsets[idx],\n                      label=f'Spectrum {i}')\n\n        ax1d.set_xlabel(\"Wavelength (microns)\")\n        ax1d.set_ylabel(\"Flux (Jy) + Constant offset\")\n        ax1d.grid(True)\n        ax1d.legend()\n\n        # ------------------------Plot CAL FITS file------------------------\n        x1d = datamodels.open(product_list[0]).spec[0]\n        # Handle both cases dynamically\n        if 'x1dints_mod' in product_list[0]:\n            cal = datamodels.open(product_list[0].replace('x1dints_mod', 'calints'))\n        else:\n            cal = datamodels.open(product_list[0].replace('x1dints', 'calints'))\n\n        ax2d.imshow(cal.data[0], aspect='auto', vmin=np.nanpercentile(cal.data[0], 10),\n                    vmax=np.nanpercentile(cal.data[0], 90), origin='lower')\n        ystart, ystop = (x1d.extraction_ystart - 1,\n                         x1d.extraction_ystop - 1\n                         )\n        extract_width = ystop - ystart + 1\n        slit = cal\n        _, _, _, trace = location_from_wcs(cal, slit)\n        ax2d.plot(np.arange(len(trace)), trace + extract_width, color='r')\n        ax2d.plot(np.arange(len(trace)), trace - extract_width, color='r')\n        ax2d.set_title(cal.meta.filename)\n        ax2d.set_xlabel(\"Pixel Column\")\n        ax2d.set_ylabel(\"Pixel Row\")\n\n    fig.show()\n\n    # If no products were found, display a message\n    if not any(products.values()):\n        print(\"No NRS1 or NRS2 products found. Exiting.\")\n\n\n\nFunction to display the white light curve.\n\ndef display_light_curve(all_spec_1D,\n                        all_times,\n                        wave_um,\n                        total_flux_cols=(120, -20),\n                        correct_tilt_event=False,\n                        before_transit=(0, 170),\n                        tilt_event=270,\n                        after_transit=(330, 460)):\n    \"\"\"\n    Create and display white light curve.\n\n    Parameters\n    ----------\n    all_spec_1D : ndarray\n        2D array of spectra (integrations x columns).\n    all_times : ndarray\n        Array of time stamps for integrations.\n    wave_um : ndarray\n        Array of wavelengths corresponding to columns.\n    total_flux_cols : tuple of int\n        Tuple specifying the start and end column indices\n        for summing flux to calculate the white light curve.\n    correct_tilt_event : bool, optional\n        If True, applies a correction to address tilt events\n        by normalizing affected regions.\n    before_transit : tuple of int, optional\n        Tuple specifying the range of indices (start, end)\n        defining the data before the transit.\n    tilt_event : int, optional\n        Index specifying the start of the tilt event for applying corrections.\n    after_transit : tuple of int, optional\n        Tuple specifying the range of indices (start, end)\n        defining the data after the transit.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n\n    # --------------------------Set up figures--------------------------\n    fig, axes = plt.subplots(2, 1, figsize=(15, 10), height_ratios=[1, 2])\n    fig.subplots_adjust(hspace=0.3, wspace=0.2)\n    axlc, axslc = axes\n\n    # ---------------------Obtain white light curve---------------------\n    n_spec = len(all_times)  # Number of spectra (integrations).\n    wlc_flux = np.zeros(n_spec)\n\n    # Sum all flux (total flux) in a given range.\n    for i in range(n_spec):\n        col_start, col_end = total_flux_cols[0], total_flux_cols[1]\n        wlc_flux[i] = np.nansum(all_spec_1D[i, col_start:col_end])\n\n    # Normalize by the median flux of the first twenty points.\n    wlc_flux /= np.nanmedian(wlc_flux[0:20])\n    if correct_tilt_event:\n        # Normalize the post-tilt region using the after_transit median.\n        wlc_flux[tilt_event:] /= np.nanmedian(wlc_flux[after_transit[0]:after_transit[1]])\n\n    # Calculate light curve scatter from first ~100 points.\n    wlc_flux_s = sigma_clip(wlc_flux, sigma=2, maxiters=2, masked=False)\n    sigma_wlc = np.sqrt(np.nanvar(wlc_flux_s[2:100]))\n    sigma_wlc_ppm = round(sigma_wlc * 1e6, 0)\n    print(f\"White Light Curve scatter (ppm):  {sigma_wlc_ppm}\")\n\n    # Plot white light curve\n    time_axis = (all_times - np.nanmean(all_times)) * 24.0\n    axlc.plot(time_axis,\n              wlc_flux, color='r', marker='o', markersize=2,\n              label=f\"White light curve, (r.m.s.={round(sigma_wlc * 1e6, 0)} ppm)\")\n    wavestart = round(wave_um[col_start], 4)\n    waveend = round(wave_um[col_end], 4)\n    axlc.set_title(f\"White Light Curve (λ = {wavestart} - {waveend} μm)\", fontsize=15)\n    axlc.legend(loc=\"lower right\")\n    axlc.set_xlabel(\"Time since mid-exposure, hr\", fontsize=15)\n    axlc.set_ylabel(\"Normalized flux\", fontsize=15)\n\n    # Add secondary x-axis for integration indices\n    integration_indices = np.arange(n_spec)\n    tick_positions = np.linspace(time_axis.min(),\n                                 time_axis.max(),\n                                 len(integration_indices))\n    axlc_secondary = axlc.secondary_xaxis('top')\n    axlc_secondary.set_xlabel(\"Integration Index\", fontsize=12)\n    axlc_secondary.set_xticks(tick_positions[::len(tick_positions) // 10])\n    axlc_secondary.set_xticklabels([f\"{int(idx)}\" for idx in\n                                    integration_indices[::len(integration_indices) // 10]])\n\n    # -----------------Obtain spectroscopic light curve-----------------\n    lc_map = np.copy(all_spec_1D)\n    spec_xlen = len(lc_map[0, :])\n    for j in range(spec_xlen):\n        # Normalize each spectrum by the mean.\n        lc_map[:, j] /= np.nanmean(lc_map[before_transit[0]:before_transit[1], j])\n        if correct_tilt_event:\n            # Correct for tilt event.\n            lc_map[tilt_event:, j] /= np.nanmean(lc_map[after_transit[0]:after_transit[1], j])\n    axslc.set_title(\"Spectroscopic Light Curves\", fontsize=15)\n    slc = axslc.imshow(lc_map,\n                       interpolation=\"bilinear\",\n                       aspect=\"auto\",\n                       cmap=\"inferno_r\",\n                       origin=\"lower\",\n                       clim=(0.977, 1.005),\n                       )\n\n    axslc.set_xlabel(r\"x-column, pixel\", fontsize=15)\n    axslc.set_ylabel(\"Integration \", fontsize=15)\n    plt.colorbar(slc, ax=axslc, label=r\"Normalized Flux\")\n\n    fig.show()\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-visualizing-the-data","position":41},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualizing the Data"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-1-display-detector1pipeline-products","position":42},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualizing the Data"},"content":"Inspect the Stage 1 slope products.\n\nrate_file = rate_sci[-1]  # Show a rate file, as an example.\ndisplay_rate(rate_file, integration=100, vmin=-0.1, vmax=1, scale='asinh',\n             aspect=10, title_prefix='REPROCESSED')  # , extname='dq')\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-1-display-detector1pipeline-products","position":43},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"8.2 Display Spec2Pipeline Products","lvl2":"8. Visualizing the Data"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-2-display-spec2pipeline-products","position":44},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"8.2 Display Spec2Pipeline Products","lvl2":"8. Visualizing the Data"},"content":"First, let’s visually inspect that the 1/f noise was removed from the data.\n\nrate_file_cl = rate_sci_cl[0]  # Show a rate file, as an example.\nnoise = flicker_noise[0]\nmask = masks[0]\n\ndisplay_rate(mask, integration=100, vmin=0, vmax=1,\n             aspect=10, title_prefix='MASK ')\ndisplay_rate(rate_file_cl, integration=100, vmin=-0.1, vmax=1,\n             aspect=10, scale='asinh', title_prefix='CLEANED ')\ndisplay_rate(noise, integration=100, vmin=-0.1, vmax=1,\n             aspect=10, title_prefix='1/F NOISE ')\n\n\n\n\n\n\n\nNow inspect the Stage 2 calibrated spectra.\n\ndisplay_spectra(sci_x1d, integrations=[0, 10, 100], offsets=[0, 70, 140])\n\n\n\n\n\n\n\n\n\n\n\nNext, we derive white light curves and a spectroscopic light curves from the large arrays we made and plot them.\n\nTo produce a white light curve, we sum the flux from the full wavelength range of each extracted one-dimensional spectrum. Then we normalize the light curve by dividing the light curve flux to the median flux of the first twenty data points out-of-the-transit. We calculate and report the scatter using the first ~100 data points.\n\nWhile the white light curve provides information regarding the overall quality of the data, the light curves from each pixel (wavelength) contain information about the atmosphere of a transiting exoplanet. The second figure in the plot shows chromatic light curves (also known as wavelength maps). To produce them, we obtain a copy of all spectra and normalize each spectrum by its mean value.\n\nYou may find that a light curve also exhibits the morphology of a transit event along with a step-function flux jump near the mid-transit. This flux jump (a decrease of flux in this case) is attributed to a ‘tilt’ event associated with one of the segments of the JWST mirror. A ‘tilt’ event is considered any uncommanded change in the tip-tilt orientation of a mirror segment and can be caused by a micrometeorite impact. For further details, please consult the following page: \n\nJWST TSO noise sources.\n\nIn our plots below, we also correct for the tilt event by renormalizing the post-tilt event light curves. To do that, we divide these light curves by the mean out-of-transit post-tilt event flux\n\n# Sort NRS1 from NRS2 files.\nsci_x1d_nrs1 = [f for f in sci_x1d if \"nrs1\" in f]\nsci_x1d_nrs2 = [f for f in sci_x1d if \"nrs2\" in f]\n\n# Compile the NRS1 and NRS2 spectra into one array.\nall_spec1D_nrs1, all_times_nrs1, wave_um_nrs1 = compile_segments(sci_x1d_nrs1)\nall_spec1D_nrs2, all_times_nrs2, wave_um_nrs2 = compile_segments(sci_x1d_nrs2)\n\n# Plot the light curves for each detector.\ndisplay_light_curve(all_spec1D_nrs1, all_times_nrs1, wave_um_nrs1,\n                    total_flux_cols=(20, -20),  # Sum flux over integration range.\n                    # Tilt event correction parameters:\n                    correct_tilt_event=True,\n                    before_transit=(0, 170),  # Before transit integration range.\n                    tilt_event=270,  # Tilt event integration.\n                    after_transit=(330, 460))  # After transit integration range.\n\ndisplay_light_curve(all_spec1D_nrs2, all_times_nrs2, wave_um_nrs2,\n                    total_flux_cols=(5, -5),  # Sum flux over integration range.\n                    # Tilt event correction parameters:\n                    correct_tilt_event=True,\n                    before_transit=(0, 170),  # Before transit integration range.\n                    tilt_event=270,  # Tilt event integration.\n                    after_transit=(330, 460))  # After transit integration range.\n\n\n\n\n\n\n\n\n\nThe white light curve shows a relatively low scatter (230 ppm) for NRS1 and a slightly higher scatter (800 ppm) for NRS2.\n\nThe 2D plots above show all extracted 1D spectra covering the transit event. The horizontal axis is the spectral direction (wavelength), and the vertical - each integration (time). The dark pixels correspond to the out-of-transit data (pre/post transit), the orange horizontal stripes indicate the ingress and egress portions, and the yellow stripe shows the in-transit part of the light curve. We have corrected the tilt event data by normalizing all spectra after integration 330 using the post-transit flux. The cells above can be rerun without correction for the tilt event. In this case, all light curves after the tilt event will look offset by a constant amount owing to the redistributed wavefront.\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-2-display-spec2pipeline-products","position":45},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"8.3 Display Tso3Pipeline Products","lvl2":"8. Visualizing the Data"},"type":"lvl3","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-3-display-tso3pipeline-products","position":46},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl3":"8.3 Display Tso3Pipeline Products","lvl2":"8. Visualizing the Data"},"content":"Inspect the Stage 3 combined calibrated spectra. The white light curve produced from Stage 3 is not corrected like above for any tilt events.\n\n# Read the white light curve.\ndata = Table.read(stage3_whtlt[0], format=\"ascii.ecsv\")\nxx = data[\"MJD_UTC_NRS1\"]\nyy = data[\"whitelight_flux_NRS1\"] / np.median(data[\"whitelight_flux_NRS1\"][:100])\n\n# Calculate scatter.\nsigma_wlc = np.sqrt(np.nanvar(yy[2:100]))\nprint(f\"White Light Curve scatter (ppm): {round(sigma_wlc * 1e6, 0)}\")\n\n# Plot white light curve\nplt.figure(figsize=(12, 5))\nplt.plot(\n    (xx - np.nanmean(xx)) * 24.0,\n    yy,\n    color=\"blue\",\n    marker=\"o\",\n    markersize=2,\n    label=f\"White light curve, (r.m.s.={round(sigma_wlc * 1e6, 0)} ppm)\")\nplt.legend(loc=\"lower right\")\nplt.title(\"White Light Curve\", fontsize=15)\nplt.xlabel(\"Time since mid-exposure, hr\", fontsize=15)\nplt.ylabel(\"Normalized flux\", fontsize=15)\n\n# Set plot limits\n#plt.ylim([0.965, 1.015])\nplt.show()\n\n\n\n\n\nWe now have white and spectroscopic light curves ready for fitting (not covered in this notebook). For additional analysis and features, please consult the following notebook, presented on a JWebbinar in December 2023: \n\nPart2-Spec2.ipynb.\n\nIt should be pointed out that the workaround solutions lead to a lower white light curve scatter for this particular data set (approximately 70 ppm lower, or 160 ppm for NRS1). Two factors determine the difference:\n\nThe pixel replacement step in the workaround uses a nominal PSF profile constructed from adjacent columns (of a column that needs to be corrected) to identify high and low pixels in addition to the data quality flags.\n\nAt the time of writing, the spectral resampling step is unavailable in the STScI pipeline. Instead, in the workaround notebook, we fit for the star’s centroid to locate and trace the spectra (without resampling) and perform aperture extraction using the trace.\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-8-3-display-tso3pipeline-products","position":47},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-9-modifying-the-extract1d-reference-file-as-needed","position":48},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"content":"extract_1d •\n\n\nEditing JSON reference file\n\nAs of Build 11.3, the extract_1d step now uses a curved trace to extract the 1D spectra by default for un-resampled 2D spectra (resampling is skipped for BOTS data). As an example, we still provide a way to modify the extraction region if needed.\n\nThe EXTRACT1D reference file, along with several other parameter files, can be found in the CRDS_PATH directory. While some files, like .json files, can be manually edited, we modify them using Python.\n\n# Modify the EXTRACT1D reference file.\n\n# If you don't know the reference file name this should work.\n# extract_1d_ref = Spec2Pipeline().get_reference_file(sci_cal, 'extract1d')\n\nrefs = api.dump_references(crds_client.get_context_used('jwst'),\n                           ['jwst_nirspec_extract1d_0006.json'])\nextract_1d_ref = refs['jwst_nirspec_extract1d_0006.json']\n\n# Open EXTRACT1D reference file in read-mode.\nwith open(extract_1d_ref, \"r\") as ref_file:\n    params = json.load(ref_file)\n\n    # S1600A1 full slit\n    params[\"apertures\"][0][\"extract_width\"] = 27\n    params[\"apertures\"][0].pop(\"nod2_offset\")  # remove\n    params[\"apertures\"][0].pop(\"nod3_offset\")  # remove\n    params[\"apertures\"][0].pop(\"nod5_offset\")  # remove\n    # params[\"apertures\"][0][\"xstart\"] = 100  # lower x-index\n\n# Write changes to a new file.\nnewData = json.dumps(params, indent=4)\n\n# Add the suffix '_bots' to distinguish the file from the default version.\nbasename = os.path.basename(extract_1d_ref)[:-5]\nextract_1d_ref_mod = os.path.join(basedir, f'{basename}_bots.json')\nwith open(extract_1d_ref_mod, \"w\") as file:\n    file.write(newData)\n\n\n\n# Inspect the EXTRACT1D reference file.\nwith open(extract_1d_ref_mod, 'r') as f_obj:\n    extract_1d_ref_mod_data = json.load(f_obj)\n\nJSON(extract_1d_ref_mod_data, expanded=True)\n\n\n\nNow, we re-extract the 1D spectrum by running the Extract1dStep and overriding the reference file.\n\n# Re-extract the NRS2 1D spectra.\nsci_cal_nrs2 = [f for f in sci_cal if \"nrs2\" in f]\n\nfor cal in sci_cal_nrs2:\n    Extract1dStep.call(cal,\n                       save_results=True,\n                       output_dir=spec2_dir,\n                       output_use_model=True,\n                       suffix='x1dints_mod',  # Default suffix is `_extract1dstep.fits`\n                       use_source_posn=False,\n                       override_extract1d=extract_1d_ref_mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsci_x1d_mod = sorted(glob.glob(spec2_dir + '*nrs2_x1dints_mod.fits'))\ndisplay_spectra(sci_x1d_mod, integrations=[0, 10, 100], offsets=[0, 70, 140])\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#id-9-modifying-the-extract1d-reference-file-as-needed","position":49},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"Concluding Remarks"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#concluding-remarks","position":50},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"Concluding Remarks"},"content":"In this notebook, we demonstrated how to obtain white and spectroscopic light curves by (re-) running the three stages of the JWST pipeline. The saved data producs can now be provided to light curve fitting codes for measurements of the physical properties of the exoplanet (or other source with temporal variability) and obtaining a transmission spectrum. It should be pointed out that the analyses performed here are only a subset of the possible analyses one can perform, and are in no way the final word on how JWST data should be analyzed. This will be solidified more and more as data comes and best practices are established in the current and future cycles.\n\nIn conclusion, I would like to express my gratitude to the entire JWST team that has supported the creation of this notebook through discussions and testing, which have improved the notebook. In particular, special thanks to the Time-Series Observations Working Group at STScI, including Néstor Espinoza, Leonardo Ubeda, Sarah Kendrew, Elena Manjavacas, Brian Brooks, Mike Reagan, Loïc Albert, Everett Schlawin, Stephan Birkmann among others. To the NIRCam IDT team for multiple fruitful discussions, including Everett Schlawin, Thomas Beatty, Tom Greene and Jarron Leisenring. To the ERS Transiting Exoplanet team who have provided several venues for discussion and community input. To the several JWST team members, including behind the pipeline and the mission itself, including and in no particular order Bryan Hilbert, Armin Rest, Anton Koekemoer, Alicia Canipe, Melanie Clarke, James Muzerolle, Kayli Glidic, Jeff Valenti and Karl Gordon.\n\n","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#concluding-remarks","position":51},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"Related Notebooks"},"type":"lvl2","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#related-notebooks","position":52},{"hierarchy":{"lvl1":"NIRSpec BOTS Pipeline Notebook","lvl2":"Related Notebooks"},"content":"JWebbinar in December 2023\n\nNIRSpec Workaround Notebooks\n\nJDAT: JWST Data Analysis Example Notebooks\n\n\n\nTop of Page","type":"content","url":"/notebooks/nirspec/bots/jwpipenb-nirspec-bots#related-notebooks","position":53},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs","position":0},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs","position":1},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#nirspec-fs-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook"},"content":"\n\nAuthors: Elena Manjavacas (\n\nemanjavacas@stsci​.edu), building on the work of Peter Zeidler (\n\nzeidler@stsci.edu), Kayli Glidic (\n\nkglidic@stsci.edu), and James Muzerolle (\n\nmuzerol@stsci.edu); NIRSpec branch \nLast Updated: August 5, 2025 \nPipeline Version: 1.19.1 (Build 12.0, Context jwst_1413.pmap)\n\nPurpose:\nThis notebook provides a framework for processing generic Near-Infrared Spectrograph (NIRSpec) fixed slit (FS) data through the three stages of the JWST pipeline. It includes how to use associations for multi-exposure observations and how to interact and work with JWST datamodels. Data is assumed to be organized into two folders: science and background, as specified in the paths set up below. In most cases, editing cells outside the \n\nConfiguration section is unnecessary unless the standard pipeline processing options or plot parameters need to be modified.\n\nData: \nThis notebook is set up to use observations of HD1808347 A3V standard star (point source) with the G235M grism obtained by Proposal ID (PID) 1128, Observation 6. The demo data will be automatically downloaded in the demo_mode unless disabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context: \nThis notebook was written for the calibration pipeline version given above and uses the context associated with this version of the JWST Calibration Pipeline. Information about this an other contexts can be found in the JWST Calibration Reference Data System (CRDS)\n\n\nserver. If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements.\nAny \n\nknown issues for this build are noted in the notebook.\n\nUpdates: \nThis notebook is regularly updated to incorporate the latest pipeline improvements. Find the most up-to-date version of this notebook \n\nhere.\n\nRecent Changes:\n\nOctober 15, 2024: Converted notebook to follow standard template (\n\nkglidic@stsci.edu). \n\nNovember 4, 2024: Notebook updated to JWST pipeline version 1.16.0 (Build 11.1).\n\nJanuary 6, 2025: Updated formatting and added examples for creating association files.\n\nJanuary 27, 2025: Notebook updated to JWST pipeline version 1.17.1 (Build 11.2) and added more association file information.\n\nApril 16, 2025: Updated JWST pipeline version 1.18.0 (Build 11.3) and added Jdaviz plotting options.\n\nJuly 16, 2025: Updated to JWST pipeline version 1.19.1 (no significant changes)\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#nirspec-fs-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#table-of-contents","position":4},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"Table of Contents"},"content":"1. Configuration\n\n2. Package Imports\n\n3. Demo Mode Setup\n\n4. Directory Setup\n\n5. Stage 1: Detector1Pipeline (calwebb_detector1)\n\n5.1 Configure Detector1Pipeline\n\n5.2 Run Detector1Pipeline\n\n5.2.1 Calibrating Science Files\n\n5.2.2 Calibrating Background Files\n\n6. Stage 2: Spec2Pipeline (calwebb_spec2)\n\n6.1 Configure Spec2Pipeline\n\n6.2 Create Spec2Pipeline Association Files\n\n6.3 Run Spec2Pipeline\n\n6.3.1 Calibrating Science Files\n\n6.3.2 Calibrating Background Files\n\n7. Stage 3: Spec3Pipeline (calwebb_spec3)\n\n7.1 Configure Spec3Pipeline\n\n7.2 Create Spec3Pipeline Association Files\n\n7.3 Run Spec3Pipeline\n\n8. Visualize the Data\n\n8.1 Display Detector1Pipeline Products\n\n8.2 Display Spec2Pipeline Products\n\n8.3 Display Spec3Pipeline Products\n\n9. Modifying the EXTRACT1D Reference File (as needed)\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#table-of-contents","position":5},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-1-configuration","position":6},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"1. Configuration"},"content":"","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-1-configuration","position":7},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#install-dependencies-and-parameters","position":8},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"To make sure that the pipeline version is compatible with the steps discussed below and that the required dependencies and packages get installed, you can create a fresh conda environment and install the provided requirements.txt file before starting this notebook:conda create -n nirspec_fs_pipeline python=3.12\nconda activate nirspec_fs_pipeline\npip install -r requirements.txt","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#install-dependencies-and-parameters","position":9},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Set the basic parameters to configure the notebook","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#set-the-basic-parameters-to-configure-the-notebook","position":10},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Set the basic parameters to configure the notebook","lvl2":"1. Configuration"},"content":"These parameters determine what data gets used, where data is located (if already on disk), and the type of background subtraction (if any). The list of parameters includes:\n\ndemo_mode:\n\nTrue: Downloads example data from the \n\nBarbara A. Mikulski Archive for Space Telescopes (MAST) and processes it through the pipeline. All processing will occur in a local directory unless modified in \n\nSection 3 below.\n\nFalse: Process your own downloaded data; provide its location.\n\nDirectories with data:\n\nsci_dir: Directory where science observation data is stored.\n\nbg_dir: Directory where dedicated background observation data is stored.\n\nBackgroud subtraction methods: \n\nmaster_bg = True: Apply master-background subtraction in calwebb_spec3. For dedicated background observations.\n\npixel_bg = True: Apply pixel-to-pixel background subtraction in calwebb_spec2.  This is the default pipeline setting. Typically uses noded observations.\n\n# Basic import necessary for configuration.\n# Uncomment logging to hide log information.\n\nimport os\nimport warnings\n#import logging\n\n# Control logging level: INFO, WARNING, ERROR\n# Run command logging.disable if want to hide logging\n# ERROR messages.\n#logging.disable(logging.ERROR)\nwarnings.simplefilter(\"ignore\", RuntimeWarning)\n\n\n\nNote that demo_mode must be set appropriately below.\n\n# Set parameters for demo_mode, data mode directories, and processing steps.\n\n# -------------------------------DEMO MODE-----------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# ----------------------------User Mode Directories--------------------------\nelse:  # If demo_mode = False, look for user data in these paths.\n\n    # Set directory paths for processing specific data; adjust to your local\n    # directory setup (examples provided below).\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n\n    # Directory to science observation data; expects uncalibrated data in\n    # sci_dir/uncal/ and results in stage1, stage2, and stage3 directories.\n    sci_dir = os.path.join(basedir, 'fs_data_01128/Obs006', '')\n\n    # Directory to background observation data; expects uncalibrated data in\n    # bg_dir/uncal/ and results in stage1, stage2, and stage3 directories.\n    #bg_dir = os.path.join(basedir, 'fs_data_02288/Obs002', '')\n    bg_dir = ''  # If no background observation, use an empty string.\n\n# ---------------------------Set Processing Steps----------------------------\n# Individual pipeline stages can be turned on/off here.  Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing.\ndodet1 = True  # calwebb_detector1\ndospec2 = True  # calwebb_spec2\ndospec3 = True  # calwebb_spec3\ndoviz = True  # Visualize calwebb outputs\n\n# Background Processing.\ndodet1bg = False  # calwebb_detector1\ndospec2bg = False  # calwebb_spec2 (needed for Master Background subtraction)\n\n# How should background subtraction be done?\n# Set one or None of the flags below.\n# If none are selected, data will not be background subtracted.\n# If background subtraction is done in Spec2 it will be skipped in Spec3.\n# Note: Master-background subtraction is for dedicated background observations.\n# Dedicated backgrounds must be processed through spec2 first.\nmaster_bg = False  # Master-background subtraction in spec3.\npixel_bg = True  # Pixel-based background subtraction in spec2.\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#set-the-basic-parameters-to-configure-the-notebook","position":11},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#set-crds-context-and-server","position":12},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline. If the local CRDS cache directory has not been set, it will automatically be created in the home directory.\n\nBuild Context Table\n\n# ------------------------Set CRDS context and paths------------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here, we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#os.environ['CRDS_CONTEXT'] = 'jwst_1364.pmap'  # CRDS context for 1.18.0\n\n# Set CRDS cache directory to user home if not already set.\nif os.getenv('CRDS_PATH') is None:\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds_cache')\n\n# Check whether the CRDS server URL has been set. If not, set it.\nif os.getenv('CRDS_SERVER_URL') is None:\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Output the current CRDS path and server URL in use.\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#set-crds-context-and-server","position":13},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-2-package-imports","position":14},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook.\nfrom IPython.display import display, HTML, JSON\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# ----------------------General Imports----------------------\nimport time\nimport glob\nimport json\nimport itertools\nimport numpy as np\n\n# ----------------------Astropy Imports----------------------\n# Astropy utilities for opening FITS files, downloading demo files, etc.\nfrom astropy.io import fits\nfrom astropy.stats import sigma_clip\nfrom astropy.visualization import ImageNormalize, ManualInterval, LogStretch\nfrom astropy.visualization import LinearStretch, AsinhStretch, simple_norm\n\n# ----------------------Astroquery Import----------------------\nfrom astroquery.mast import Observations\n\n# ----------------------Plotting Imports---------------------\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.collections import PatchCollection\nfrom jdaviz import Specviz2d\n\n\n\nInstallation instructions for the JWST pipeline found in \n\nJWST User Documentation and \n\nReadtheDocs • \n\nGithub\n\n# ----------------------JWST Calibration Pipeline Imports----------------------\nimport jwst  # Import the base JWST and CRDS packages.\nimport crds\nfrom crds.client import api\nfrom stpipe import crds_client\n\n# JWST pipelines (each encompassing many steps).\nfrom jwst.pipeline import Detector1Pipeline  # calwebb_detector1\nfrom jwst.pipeline import Spec2Pipeline  # calwebb_spec2\nfrom jwst.pipeline import Spec3Pipeline  # calwebb_spec3\nfrom jwst.extract_1d import Extract1dStep  # Extract1D Step\n\n# JWST pipeline utilities.\nfrom jwst import datamodels  # JWST datamodels.\nfrom jwst.associations import asn_from_list as afl  # Tools for creating ASN files.\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Lvl2 ASN file.\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Lvl3 ASN file.\n\ndefault_context = crds.get_default_context('jwst', state='build')\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(f\"Default CRDS Context for JWST Version {jwst.__version__}: {default_context}\")\nprint(f\"Using CRDS Context: {os.environ.get('CRDS_CONTEXT', default_context)}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-2-package-imports","position":15},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Define Convenience Functions","lvl2":"2. Package Imports"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#define-convenience-functions","position":16},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"Define Convenience Functions","lvl2":"2. Package Imports"},"content":"\n\nDefine a function that filters a list of files based on a specific FITS header key-value condition.\n\ndef filter_list(files, key, value):\n    \"\"\"\n    Filter a list of files based on a specific FITS header key-value condition.\n\n    Parameters\n    ----------\n    files : list\n        List of file paths to FITS files.\n    key : str\n        The FITS header key to check.\n    value : Any\n        The value to match for the specified header key.\n\n    Returns\n    -------\n    list : A list of file paths that satisfy the key-value condition.\n    \"\"\"\n    return [file for file in files if fits.getheader(file).get(key) == value]\n\n\n\nDefine a function that filters files based on detector, filter, and grating.\n\ndef get_matching(files, detector, filt, grating, fxd_slit, exp_type):\n    \"\"\"\n    Filters a list of FITS files to find those with matching \n    detector, filter, and grating for a specified exposure type.\n\n    Parameters\n    ----------\n    files : list of str\n        Paths to FITS files to check.\n    detector : str\n        Expected value of the DETECTOR keyword.\n    filt : str\n        Expected value of the FILTER keyword.\n    grating : str\n        Expected value of the GRATING keyword.\n    fxd_slit : str\n        Fixed slit name.\n    exp_type : str, optional\n        The exposure type to match.\n\n    Returns\n    -------\n    files_regular : list of str\n        Files with matching configuration and IS_IMPRT == False or missing.\n    files_imprint : list of str)\n        Files with matching configuration and IS_IMPRT == True.\n    \"\"\"\n    files_regular, files_imprint = [], []\n    for file in files:\n        # Skip if EXP_TYPE doesn't match the provided one.\n        if fits.getval(file, 'EXP_TYPE') != exp_type:\n            files_regular.append(file)\n            continue\n        # Check if DETECTOR, FILTER, and GRATING match\n        detector_match = fits.getval(file, 'DETECTOR') == detector\n        filter_match = fits.getval(file, 'FILTER') == filt\n        grating_match = fits.getval(file, 'GRATING') == grating\n        slit_match = fits.getval(file, 'FXD_SLIT') == fxd_slit\n        if detector_match and filter_match and grating_match and slit_match:\n            # Only IFU and MOS observations have imprint exposures.\n            try:\n                is_imprt = fits.getval(file, 'IS_IMPRT')\n            except KeyError:\n                is_imprt = None\n            (files_imprint if is_imprt else files_regular).append(file)\n    return files_regular, files_imprint\n\n\n\nDefine a function that checks the grating wheel tilt value between two files.\n\ndef match_gwa(file1, file2):\n    \"\"\"\n    Check if GWA tilt values match closely enough to be associated.\n    \n    Parameters\n    ----------\n    file1, file2 : str \n        Input exposures FITS file paths.\n\n    Returns\n    -------\n    True if both GWA tilt values match within tolerance, else False.\n    \"\"\"\n    hdr1, hdr2 = fits.getheader(file1), fits.getheader(file2)\n    return np.allclose(\n        (hdr1['GWA_XTIL'], hdr1['GWA_YTIL']),\n        (hdr2['GWA_XTIL'], hdr2['GWA_YTIL']),\n        atol=1e-8, rtol=0\n    )\n\n\n\n# Start a timer to keep track of runtime.\ntime0 = time.perf_counter()\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#define-convenience-functions","position":17},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":18},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"The data in this notebook is public and does not require a token. For other data sets, you may need to provide a token. For more infomation visit \n\nastroquery documentation.\n\nIf running in demonstration mode, set up the program information to retrieve the uncalibrated data (_uncal.fits) automatically from MAST using astroquery. MAST provides flexibility by allowing searches based on proposal ID and observation ID, rather than relying solely on filenames. More information about the JWST file naming conventions can be found \n\nhere.\n\nThe FS demo data in this notebook is from the \n\nNIRSpec calibration program 1128 and features observations of HD1808347 (point source) using the G235M grism. The program setup is briefly summarized in the table below.\n\nDemo Target: HD1808347 A3V Standard Star\n\n\n\n\n\nPROGRAM\n\n01128\n\nProgram number\n\nOBSERVTN\n\n006\n\nObservation number\n\nGRATING/FILTER\n\nG235M/F170LP\n\nλ: 1.66–3.17 μm (a medium resolution, R ~ 1000)\n\nSUBARRAY\n\nSUBS200A1\n\nSubarray used\n\nNINTS\n\n2\n\nNumber of integrations in exposure\n\nNGROUPS\n\n30\n\nNumber of groups in integration\n\nDURATION\n\n96.637 [s]\n\nTotal duration of one exposure\n\nREADPATT\n\nNRSRAPID\n\nReadout pattern\n\nPATTTYPE\n\n3-POINT-NOD\n\nPrimary dither pattern type\n\nNUMDTHPT\n\n3\n\nTotal number of points in pattern\n\nSRCTYAPT\n\nPOINT\n\nSource type selected in APT\n\nNote: The presence of a physical gap between detectors affects high-resolution FS observations because the spectra are long enough to span both NIRSpec detectors. \n\nMore Info ...\n\n# Set up the program information and directories to collect\n# the data in demo_mode.\nif demo_mode:\n    \n    print('Running in demonstration mode. '\n          'Example data will be downloaded from MAST!')\n\n    # For non public data sets, you may need to provide a token.\n    # However, for security it is not recommended to enter tokens into\n    # a terminal or Jupyter notebook.\n    #Observations.login(token=\"your-token\")\n\n    # --------------Program and observation information--------------\n    program = \"01128\"\n    sci_observtn = \"006\"\n    bg_observtn = None\n    filters = [\"F170LP;G235M\"]\n\n    # ----------Define the base and observation directories----------\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n    sci_dir = os.path.join(basedir, f'fs_data_{program}')\n    sci_dir = os.path.join(sci_dir, f'Obs{sci_observtn}')\n    uncal_dir = os.path.join(sci_dir, 'uncal/')\n\n    # If no background observation, leave blank.\n    bg_dir = os.path.join(basedir, f'fs_data_{program}')\n    bg_dir = os.path.join(bg_dir, f'Obs{bg_observtn}') if bg_observtn else ''\n    uncal_bgdir = os.path.join(bg_dir, 'uncal/') if bg_observtn else ''\n\n    # ------Ensure directories for downloading MAST data exists------\n    os.makedirs(uncal_dir, exist_ok=True)\n    # Makes directory only when a background observation is provided.\n    if bg_observtn:\n        os.makedirs(uncal_bgdir, exist_ok=True)\nelse:\n    print('Running with user provided data.')\n\n\n\nClick on the following links to learn more about querying and downloading data:\n• \n\nDownloading data\n• \n\nObservations Class\n• \n\nProducts Field Descriptions\n\nCompile tables of files from MAST associated with the science (SCI) and, if applicable, background (BG) observations. Note that the demo data does not have BG observations.\n\n# Obtain a list of observation IDs for the specified demo program.\nif demo_mode:\n    \n    # --------------------SCIENCE Observation--------------------\n    sci_obs_id_table = Observations.query_criteria(instrument_name=['NIRSPEC/SLIT'],\n                                                   provenance_name=[\"CALJWST\"],\n                                                   obs_id=[f'*{program}*{sci_observtn}*'])\n\n    if bg_dir:\n        # ------------------BACKGROUND Observation-------------------\n        bg_obs_id_table = Observations.query_criteria(instrument_name=['NIRSPEC/SLIT'],\n                                                      provenance_name=[\"CALJWST\"],\n                                                      obs_id=[f'*{program}*{bg_observtn}*'])\n\n\n\nThe demo dataset consists of six _uncal.fits files, each approximately 15 MB in size.\n\n# Convert visits into a list of uncalibrated data and ASN files.\nif demo_mode:\n    \n    file_criteria = {'filters': filters, 'calib_level': [1],\n                     'productSubGroupDescription': 'UNCAL'}\n\n    # Initialize lists for science and background files.\n    sci_downloads, bg_downloads = [], []\n\n    pfilter = Observations.filter_products  # Alias for filter_products method.\n\n    # ----------Identify uncalibrated SCIENCE files associated with each visit----------\n    for exposure in sci_obs_id_table:\n        sci_products = Observations.get_product_list(exposure)\n\n        # Filter for full-size science files (exclude smaller confirmation images).\n        avg_sci_size = np.nanmean(sci_products['size'])\n        sci_products = sci_products[sci_products['size'] > avg_sci_size]\n        sci_downloads.extend(pfilter(sci_products, **file_criteria)['dataURI'])\n\n    # --------Identify uncalibrated BACKGROUND files associated with each visit---------\n    if bg_dir:\n        for exposure in bg_obs_id_table:\n            bg_products = Observations.get_product_list(exposure)\n\n            # Filter for full-size background files (exclude smaller confirmation images).\n            avg_bg_size = np.nanmean(bg_products['size'])\n            bg_products = sci_products[bg_products['size'] > avg_bg_size]\n            bg_downloads.extend(pfilter(bg_products, **file_criteria)['dataURI'])\n\n    # Filter out other observations and remove duplicates.\n    sci_downloads = {f for f in sci_downloads if f\"jw{program}{sci_observtn}\" in f}\n    print(f\"Science files selected for downloading: {len(sci_downloads)}\")\n\n    if bg_dir:\n        bg_downloads = {f for f in bg_downloads if f\"jw{program}{bg_observtn}\" in f}\n        print(f\"Background files selected for downloading: {len(bg_downloads)}\")\n    else:\n        print(\"Background files selected for downloading: 0\")\n\n\n\nDownload the data.\n\nWarning: If this notebook is halted during this step, the downloaded file may be incomplete, and cause crashes later on!\n\n# Download data and place them into the appropriate directories.\nif demo_mode:\n    for file in sci_downloads:\n        sci_manifest = Observations.download_file(file, local_path=uncal_dir)\n    for file in bg_downloads:\n        bg_manifest = Observations.download_file(file, local_path=uncal_bgdir)\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":19},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-4-directory-setup","position":20},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"Set up detailed paths to input/output stages here.\n\n# Define/create output subdirectories to keep data products organized.\n\n# -----------------------------Science Directories------------------------------\nuncal_dir = os.path.join(sci_dir, 'uncal/')  # Uncalibrated pipeline inputs.\nasn_dir = os.path.join(sci_dir, 'asn/')  # Association files.\ndet1_dir = os.path.join(sci_dir, 'stage1/')  # calwebb_detector1 pipeline outputs.\nspec2_dir = os.path.join(sci_dir, 'stage2/')  # calwebb_spec2 pipeline outputs.\nspec3_dir = os.path.join(sci_dir, 'stage3/')  # calwebb_spec3 pipeline outputs.\n\n# Creates the directories if target directory does not exist.\nos.makedirs(det1_dir, exist_ok=True)\nos.makedirs(asn_dir, exist_ok=True)\nos.makedirs(spec2_dir, exist_ok=True)\nos.makedirs(spec3_dir, exist_ok=True)\n\n# ---------------------------Background Directories-----------------------------\nif bg_dir:\n    uncal_bgdir = os.path.join(bg_dir, 'uncal/')  # Uncalibrated pipeline inputs.\n    asn_bgdir = os.path.join(bg_dir, 'asn/')  # Association files.\n    det1_bgdir = os.path.join(bg_dir, 'stage1/')  # calwebb_detector1 pipeline outputs.\n    spec2_bgdir = os.path.join(bg_dir, 'stage2/')  # calwebb_spec2 pipeline outputs.\n\n    # Creates directories if background observations are provided and do not already exist.\n    os.makedirs(det1_bgdir, exist_ok=True)\n    os.makedirs(asn_bgdir, exist_ok=True)\n    os.makedirs(spec2_bgdir, exist_ok=True)\n\n\n\n# Print out the time benchmark.\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {round((time1-time0)/60.0, 1):0.4f} min\")\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-4-directory-setup","position":21},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-stage-1-detector1pipeline-calwebb-detector1","position":22},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"In this section, we process the data through the calwebb_detector1 pipeline to create Stage 1 \n\ndata products.\n\nInput: Raw exposure (_uncal.fits) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n\nOutput: Uncalibrated countrate (slope) image in units of DN/s:\n\n_rate.fits: A single countrate image averaged over multiple integrations (if available).\n\n_rateints.fits: Countrate images for each integration, saved in multiple extensions.\n\nThe Detector1Pipeline applies basic detector-level corrections on a group-by-group basis, followed by ramp fitting for all exposure types, commonly referred to as “ramps-to-slopes” processing.\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-stage-1-detector1pipeline-calwebb-detector1","position":23},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-1-configure-detector1pipeline","position":24},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"The Detector1Pipeline has the following steps available for NIRSpec FS:\n\ngroup_scale : Rescales pixel values to correct for improper onboard frame averaging.\n\ndq_init : Initializes the data quality (DQ) flags for the input data.\n\nsaturation : Flags pixels at or below the A/D floor or above the saturation threshold.\n\nsuperbias : Subtracts the superbias reference file from the input data.\n\nrefpix : Use reference pixels to correct bias drifts.\n\nlinearity : Applies a correction for non-linear detector response.\n\ndark_current : Subtracts the dark current reference file from the input data.\n\njump : Performs CR/jump detection on each ramp integration within an exposure.\n\nclean_flicker_noise: Removes flicker (1/f) noise from calibrated ramp images (similar to nsclean in spec2).\n\nramp_fit : Determines the mean count rate (counts per second) for each pixel by performing a linear fit to the input data.\n\ngain_scale : Corrects pixel values for non-standard gain settings, primarily in NIRSpec subarray data.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox and\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Detector1Pipeline should be configured for FS data.\n\nTo override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\ndet1dict['superbias'], det1dict['refpix'] = {}, {}\ndet1dict['linearity'], det1dict['dark_current'], det1dict['jump'] = {}, {}, {}\ndet1dict['clean_flicker_noise'], det1dict['ramp_fit'] = {}, {}\ndet1dict['gain_scale'] = {}\n\n# ---------------------------Override reference files---------------------------\n\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n#det1dict['dq_init']['override_mask'] = 'myfile.fits'  # Bad pixel mask\n#det1dict['superbias']['override_superbias'] = 'myfile.fits'  # Bias subtraction\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\n#det1dict['linearity']['skip'] = True  # This is the default.\n\n# Suppress computations for saturated ramps with\n# only one good (unsaturated) sample (default True).\n# The demo data has some saturation.\ndet1dict['ramp_fit']['suppress_one_group'] = False\n\n# Turn on multi-core processing (off by default).\n# Choose what fraction of cores to use (quarter, half, or all).\ndet1dict['jump']['maximum_cores'] = 'half'\n\n\n\nThe refpix_algorithm parameter in the refpix step is applicable only to NIR data. For NIRSpec full-frame data using traditional readout modes (NRS, NRSRAPID), the default algorithm—set in the parameter reference file as of Build 12.0—is ‘sirs’ (Simple Improved Reference Subtraction), which uses reference pixels from the left and right sides. For subarray data or non-traditional readouts, the algorithm automatically defaults to ‘median’.\n\n#det1dict['refpix']['refpix_algorithm'] = 'sirs'  # default\n\n\n\nMany exposures are affected by artifacts known as \n\nsnowballs caused by large cosmic ray events. These artifacts are particularly significant in deep exposures with long integration times, with an estimated rate of one snowball per detector (FULL FRAME) per 20 seconds. To expand the number of pixels flagged as jumps around large cosmic ray events, set expand_large_events to True. An expand_factor of 3 works well for NIRSpec observations to cover most snowballs.\n\n# Turn on detection of cosmic ray snowballs (on by default).\ndet1dict['jump']['expand_large_events'] = True\ndet1dict['jump']['expand_factor'] = 3  # (default 2)\n\n\n\nJWST detector readout electronics (a.k.a. SIDECAR ASICs) generate significant 1/f noise during detector operations and signal digitization. This noise manifests as faint banding along the detector’s slow axis and varies from column to column. For NIRSpec data, the primary pipeline algorithm to address 1/f noise is nsclean in the Spec2Pipeline (Rauscher 2023) but is off by default.\n\nAn additional 1/f noise-cleaning algorithm, clean_flicker_noise, has been implemented at the group stage in the Detector1Pipeline. This step is also off by default.\n\n# Turn on 1/f noise correction in Stage 1? (off by default).\n#det1dict['clean_flicker_noise']['skip'] = False\n#det1dict['clean_flicker_noise']['fit_method'] = 'fft'\n#det1dict['clean_flicker_noise']['background_method'] = None\n#det1dict['clean_flicker_noise']['mask_science_regions'] = False\n#det1dict['clean_flicker_noise']['n_sigma'] = False\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-1-configure-detector1pipeline","position":25},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-2-run-detector1pipeline","position":26},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Run the science files, nods, and, if available, any dedicated background files through the calwebb_detector1 pipeline using the .call() method.\n\nWe use .call() instead of .run() to ensure that the latest default parameters defined via reference files in CRDS, are applied (\n\nReadtheDocs).\n\nThis stage takes approximately 2 minutes to process six _uncal.fits files from the demo data.\n\n# Final list of UNCAL files ready for Stage 1 processing.\nuncal_sci = sorted(glob.glob(uncal_dir + '*uncal.fits'))\nprint(f\"Science UNCAL Files:\\n{'-'*20}\\n\" + \"\\n\".join(uncal_sci))\n\nif bg_dir:\n    uncal_bg = sorted(glob.glob(uncal_bgdir + '*uncal.fits'))\n    print(f\"Background UNCAL Files:\\n{'-'*20}\\n\" + \"\\n\".join(uncal_bg))\n\n\n\ntime_det1 = time.perf_counter()  # Tracks runtime for Stage 1.\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-2-run-detector1pipeline","position":27},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"5.2.1 Calibrating Science Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl4","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-2-1-calibrating-science-files","position":28},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"5.2.1 Calibrating Science Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Identify the input science files and execute the calwebb_detector1 pipeline using the call method.\n\n# Run Stage 1 pipeline on the science using the custom det1dict dictionary.\nif dodet1:\n\n    #--------------------------Science UNCAL files--------------------------\n    for uncal_file in uncal_sci:\n\n        print(f\"Applying Stage 1 Corrections & Calibrations to: \"\n              f\"{os.path.basename(uncal_file)}\")\n\n        det1_result = Detector1Pipeline.call(uncal_file,\n                                             save_results=True,\n                                             steps=det1dict,\n                                             output_dir=det1_dir)\n    print(\"Detector1 has been completed for SCI data! \\n\")\nelse:\n    print('Skipping Detector1 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-2-1-calibrating-science-files","position":29},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"5.2.2 Calibrating Background Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl4","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-2-2-calibrating-background-files","position":30},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"5.2.2 Calibrating Background Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Identify the input background files and execute the calwebb_detector1 pipeline using the call method.\n\n# Run Stage 1 pipeline on any background using the custom det1dict dictionary.\nif dodet1bg:\n\n    #------------------------Background UNCAL files-------------------------\n    for uncal_file in sorted(glob.glob(uncal_bgdir + '*uncal.fits')):\n\n        print(f\"Applying Stage 1 Corrections & Calibrations to: \"\n              f\"{os.path.basename(uncal_file)}\")\n\n        det1bg_result = Detector1Pipeline.call(uncal_file,\n                                               save_results=True,\n                                               steps=det1dict,\n                                               output_dir=det1_bgdir)\n    print(\"Detector1 has been completed for BKG data! \\n\")\nelse:\n    print('Skipping Detector1 processing for BKG data.')\n\n\n\n\n\n# Print out the time benchmark.\ntime2 = time.perf_counter()\nprint(f\"Runtime so far: {round((time2-time0)/60.0, 1):0.4f} min\")\nprint(f\"Runtime for Stage 1: {round((time2-time_det1)/60.0, 1):0.4f} min\")\n\n\n\n# Final list of RATE[INTS] files ready for Stage 2 processing.\nrate_sci = sorted(glob.glob(det1_dir + '*_rate.fits'))\nrateints_sci = sorted(glob.glob(det1_dir + '*_rateints.fits'))\nprint(f\"SCIENCE | RATE[INTS] Files:\\n{'-'*20}\\n\" + \"\\n\".join(rate_sci + rateints_sci))\n\nif bg_dir:\n    rate_bg = sorted(glob.glob(det1_bgdir + '*_rate.fits'))\n    rateints_bg = sorted(glob.glob(det1_bgdir + '*_rateints.fits'))\n    print(f\"BACKGROUND | RATE[INTS] Files:\\n{'-' * 20}\\n\" + \"\\n\".join(rate_bg + rateints_bg))\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-5-2-2-calibrating-background-files","position":31},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-stage-2-spec2pipeline-calwebb-spec2","position":32},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"In this section, we process our countrate (slope) image products from Stage 1 (calwebb_detector1) through the Spec2 (calwebb_spec2) pipeline to create Stage 2 \n\ndata products.\n\nInput: A single countrate (slope) image (_rate[ints].fits) or an association file listing multiple inputs.\n\nOutput: Calibrated products (rectified and unrectified) and 1D spectra.\n\n_cal[ints].fits: Calibrated 2D (unrectified) spectra (ncols x nrows).\n\n_s2d.fits: Resampled (rectified) 2D spectra (ncols x nrows).\n\n_x1d[ints].fits: Extracted 1D spectroscopic data (wavelength vs. flux).\n\nThe Spec2Pipeline applies additional instrumental corrections and calibrations (e.g., slit loss, path loss, etc.,) to countrate products that result in a fully calibrated individual exposure (per nod/dither position). The Spec2Pipeline also converts countrate products from units of DN/s to flux (Jy) for point sources and surface brightness (MJy/sr) for extended sources.\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-stage-2-spec2pipeline-calwebb-spec2","position":33},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-1-configure-spec2pipeline","position":34},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"The Spec2Pipeline has the following steps available for NIRSpec FS:\n\nassign_wcs: Assigns wavelength solution for spectra.\n\nbadpix_selfcal: Flags bad pixels in the input data using a self-calibration technique based on median filtering along the spectral axis.\n\nnsclean: Cleans 1/f noise.\n\nbkg_subtract: Performs image subtraction for background removal.\n\nextract_2d : Extracts 2D arrays from spectral images.\n\nsrctype: Determines whether a spectroscopic source should be classified as a point or extended object.\n\nwavecorr : Updates wavelengths for FS and MOS point sources that are offset in the dispersion direction within their slit.\n\nflat_field: Applies flat-field corrections to the input science dataset.\n\npathloss: Calculates and applies corrections for signal loss in spectroscopic data.\n\nphotom: Applies photometric calibrations to convert data from countrate to surface brightness or flux density.\n\npixel_replace: Interpolates and estimates flux values for pixels flagged as DO_NOT_USE in 2D extracted spectra.\n\nresample_spec: Resamples each input 2D spectral image using WCS and distortion information.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox and\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Spec2Pipeline should be configured for FS data.\n\nIf pixel-to-pixel background subtraction was chosen above, it will be applied during this stage. To override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Spec2 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\nspec2dict = {}\nspec2dict['assign_wcs'], spec2dict['badpix_selfcal'] = {}, {}\nspec2dict['nsclean'] = {}\nspec2dict['extract_2d'], spec2dict['bkg_subtract'] = {}, {}\nspec2dict['srctype'], spec2dict['wavecorr'] = {}, {}\nspec2dict['flat_field'], spec2dict['pathloss'] = {}, {}\nspec2dict['photom'], spec2dict['pixel_replace'] = {}, {}\nspec2dict['resample_spec'], spec2dict['extract_1d'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n#spec2dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\nspec2dict['bkg_subtract']['skip'] = not pixel_bg  # Runs if pixel-to-pixel bkg selected.\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels.\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\n#spec2dict['pixel_replace']['skip'] = False\n#spec2dict['pixel_replace']['n_adjacent_cols'] = 5\n#spec2dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n# Turn on bad pixel self-calibration, where all exposures on a given detector \n# are used to find and flag bad pixels that may have been missed by the bad pixel mask.\n# This step is experimental, and works best when dedicated background observations are included.\n#spec2dict['badpix_selfcal']['skip'] = False\n#spec2dict['badpix_selfcal']['flagfrac_upper'] = 0.005  # Fraction of pixels to flag.\n\n\n\nResampling 2D spectra can sometimes introduce artificial noise and reduce the signal-to-noise ratio (SNR) in the resulting 1D spectra when using weight_type='ivm' (\n\nsee known issues). The default is now set to set weight type to ‘exptime’. Consider the following when selecting a weight_type parameter:\n\n‘ivm’: Inverse variant scaling based on read noise (VAR_RNOISE), ideal for rejecting outliers and better suited for faint sources.\n\n‘exptime’: Uses exposure time for scaling, improving SNR for bright sources.\n\n# Resample weight_type.\n#spec2dict['resample_spec']['weight_type'] = 'exptime'\n\n\n\nTo correct for 1/f noise with nsclean in Stage 2, see the FS_NSClean_example demo notebook for FS data \n\nhere.\n\n# Run nsclean for 1/f noise.\n#spec2dict['nsclean']['skip'] = False\n#spec2dict['nsclean']['n_sigma'] = 2\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-1-configure-spec2pipeline","position":35},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline Association Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-2-create-spec2pipeline-association-files","position":36},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline Association Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Association (ASN) files define the relationships between multiple exposures, allowing them to get processed as a set rather than individually. Processing an ASN file enables the exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than as individual objects.\n\nStage 2 ASN files for FS data can include science, background, and selfcal exposure types. A Stage 2 ASN file requires at least one science file but can contain multiple background and selfcal files that enable pixel-to-pixel background subtraction and bad pixel self-calibration in calwebb_spec2.\n\nHere, we provide an example of manually creating Stage 2 ASN files.\n\nBackground subtraction may not be correctly applied in Stage 2 if more than one science file is included in the association.\n\nAdditionally, pixel-to-pixel background subtraction will only be performed if the grating wheel has not moved between the target and off-scene associated background exposures. If the grating wheel moved between the target and background exposures (as would be the case if they were in different visits), pipeline processing will require a more involved “master background” subtraction done in Stage 3.\n\nAssociation for nodded observations\n\ndef asn_nod(asn, onescifile, sci, sci_imprint, nod_num):\n    \"\"\"\n    Associate background, imprint, and selfcal exposures for nodded observations.\n\n    Parameters\n    ----------\n    asn : dict\n        The association dictionary to update.\n    onescifile : str \n        Path to the primary science file.\n    sci : list of str\n        List of science exposure file paths.\n    sci_imprint : list of str\n        List of science imprint exposure file paths.\n    nod_num : int\n        Position in dither pattern.\n\n    Returns\n    -------\n    asn : dict \n        Updated association dictionary with members for applicable background, imprint, and selfcal.\n    \"\"\"\n    members = asn['products'][0]['members']\n\n    # Assign background exposures.\n    for file in sci:\n        # If dither position is different from the input position, use it as a background.\n        if ((fits.getval(file, 'PATT_NUM') - 1) // (fits.getval(file, 'SUBPXPTS'))) != nod_num:\n            members.append({'expname': file, 'exptype': 'background'})\n    \n    # Assign imprint exposures (pipeline handles figuring out which one is best).\n    for file in sci_imprint:\n        # Only IFU and MOS observations have imprint exposures.\n        if fits.getval(file, 'EXP_TYPE') == 'NRS_IFU' or 'NRS_MSASPEC':\n            if match_gwa(onescifile, file):\n                members.append({'expname': file, 'exptype': 'imprint'})\n\n    # Assign selfcal exposures.\n    for file in sci + sci_imprint:\n        members.append({'expname': file, 'exptype': 'selfcal'})\n\n    return asn\n\n\n\nDefine a function that associates background and selfcal exposures for dithered observations.\n\ndef asn_dither(asn, onescifile, sci, sci_imprint, bg, bg_imprint):\n    \"\"\"\n    Associate background, imprint, and selfcal exposures for dithered observations.\n\n    Parameters\n    ----------\n    asn : dict\n        The association dictionary to update.\n    onescifile : str \n        Path to the primary science file.\n    sci : list of str\n        List of science exposure file paths.\n    sci_imprint : list of str\n        List of science imprint exposure file paths.\n    bg : list of str\n        List of background exposure file paths.\n    bg_imprint : list of str\n        List of background imprint exposure file paths.\n\n    Returns\n    -------\n    asn : dict \n        Updated association dictionary with members for applicable background, imprint, and selfcal.\n    \"\"\"\n    members = asn['products'][0]['members']\n    \n    # Assign background exposures.\n    for file in bg:\n        members.append({'expname': file, 'exptype': 'background'})\n\n    # Assign imprint exposures (pipeline handles figuring out which one is best).\n    for file in sci_imprint:\n        # Only IFU and MOS observations have imprint exposures.\n        if fits.getval(file, 'EXP_TYPE') == 'NRS_IFU' or 'NRS_MSASPEC':\n            if match_gwa(onescifile, file):\n                members.append({'expname': file, 'exptype': 'imprint'})\n    for file in bg_imprint:\n        # Only IFU and MOS observations have imprint exposures.\n        if fits.getval(file, 'EXP_TYPE') == 'NRS_IFU' or 'NRS_MSASPEC':\n            if match_gwa(bg[0], file):\n                members.append({'expname': file, 'exptype': 'imprint'})\n\n    # Assign selfcal exposures.\n    for file in sci + sci_imprint + bg + bg_imprint:\n        members.append({'expname': file, 'exptype': 'selfcal'})\n    \n    return asn\n\n\n\nFunction to write the association file\n\ndef writel2asn(onescifile, allscifiles, bgfiles, asnfile, product_name, exp_type):\n    \"\"\"\n    Create a Level 2 association file for each science exposure.\n\n    Parameters\n    ----------\n    onescifile : str\n        Path to the primary science exposure file.\n    allscifiles : list of str\n        List of all science exposure files.\n    bgfiles : list of str\n        List of background exposure files.\n    asnfile : str\n        Path to write the output association file.\n    product_name : str\n        Name of the product for the association.\n    exp_type : str, optional\n        Exposure type to match against.\n\n    Returns\n    -------\n    True if the association was written successfully, and False otherwise \n    \"\"\"\n    # Define a basic association with the science file.\n    # Wrap in array since input was single exposure.\n    asn = afl.asn_from_list([onescifile], rule=DMSLevel2bBase, product_name=product_name)\n    program = fits.getval(onescifile, 'PROGRAM')\n    asn.data['program'] = program\n\n    # Grab header information from the science file.\n    exp_type = fits.getval(onescifile, 'EXP_TYPE')\n    if (exp_type == exp_type):\n        detector = fits.getval(onescifile, 'DETECTOR')\n        grating = fits.getval(onescifile, 'GRATING')\n        filt = fits.getval(onescifile, 'FILTER')\n        fxd_slit = fits.getval(onescifile, 'FXD_SLIT')\n        patttype = fits.getval(onescifile, 'PATTTYPE')  # Dither pattern type.\n        pattnum = fits.getval(onescifile, 'PATT_NUM')  # Dither pattern number.\n        # primary_dithpts = fits.getval(onescifile, 'PRIDTPTS')  # Points in primary dither pattern.\n        subpxpts = fits.getval(onescifile, 'SUBPXPTS')  # Points in subpixel dither pattern.\n        # Position number within primary dither pattern.\n        nod_num = (pattnum - 1) // (subpxpts)\n\n    # If the exposure type does not match, fail out \n    # to ensure TA images don't get processed by accident.\n    else:\n        return False\n\n    # Find all files matching the input configuration and split into regular/imprint.\n    use_sci, _ = get_matching(allscifiles, detector, filt, grating, fxd_slit, exp_type)\n    use_bg, _ = get_matching(bgfiles, detector, filt, grating, fxd_slit, exp_type) if bgfiles else ([], [])\n\n    # If this uses nodded exposures set up pixel-based background subtraction accordingly.\n    is_nod = 'NOD' in patttype.split('-')\n    if is_nod:\n        asn = asn_nod(asn, onescifile, use_sci, [], nod_num)\n    else:  # Otherwise handle as dithered exposures.\n        asn = asn_dither(asn, onescifile, use_sci, [], use_bg, [])\n\n    # Write the association to a json file.\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n        \n    return True\n\n\n\n# ---------------------Sort science and background files---------------------\n# 'rate_sci' includes files marked as science targets.\n# 'rate_bg' includes files marked as backgrounds in the science observation\n# or dedicated background observations.\nrate_sci = filter_list(rate_sci, 'BKGDTARG', False) or []\nrate_bg = filter_list(rate_sci, 'BKGDTARG', True) or (rate_bg if bg_dir else [])\n\n# Special case for FS S1600A1 with a 5-POINT-NOD.\n# Exclude the top and bottom dithers [1, 5] that are close to slit edges.\nexcluded_files = [\n    file for file in rate_sci + rate_bg\n    # Considering number of points in primary dither pattern and\n    # Position number within primary dither pattern.\n    if (\n        (header := fits.getheader(file)).get('FXD_SLIT') == 'S1600A1' and header.get('PRIDTPTS') == 5 and (header.get('PATT_NUM') - 1) // header.get('SUBPXPTS') in [1, 5]\n    )\n]\n\n# Filter excluded files from both lists.\nrate_sci = [file for file in rate_sci if file not in excluded_files]\nrate_bg = [file for file in rate_bg if file not in excluded_files]\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-2-create-spec2pipeline-association-files","position":37},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-3-run-spec2pipeline","position":38},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Run the science files, associated nods and, if available, any background files through the calwebb_spec2 pipeline using the .call() method.\n\nPerform pixel-to-pixel background subtraction (if desired) here in Stage 2. Otherwise, reduce the backgrounds individually for master background subtraction in Stage 3 (if desired).\n\ntime_spec2 = time.perf_counter()\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-3-run-spec2pipeline","position":39},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"6.3.1 Calibrating Science Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl4","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-3-1-calibrating-science-files","position":40},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"6.3.1 Calibrating Science Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Identify the Stage 2 ASN files and execute the calwebb_spec2 pipeline using the call method.\n\n# To save on runtime turns off creation of quicklook 2d/1d spectra for science data.\n# Any master background subtraction in spec3 will require the 1d spectra from spec2.\n#spec2dict['resample_spec']['skip'] = True  # S2D products.\n#spec2dict['extract_1d']['skip'] = True  # X1D products.\n\n\n\n# Run Stage 2 pipeline using the custom spec2dict dictionary.\nif dospec2:\n\n    # --------------------------Science files--------------------------\n    for file in rate_sci:\n        try:  # Create ASN files.\n            asnfile = os.path.join(asn_dir, os.path.basename(file).replace('rate.fits', 'l2asn.json'))\n            if writel2asn(file, rate_sci, rate_bg, asnfile, 'Level2', 'NRS_FIXEDSLIT'):\n                print(f\"Applying Stage 2 Corrections & Calibrations to: {file}\")\n                spec2sci_result = Spec2Pipeline.call(asnfile,\n                                                     save_results=True,\n                                                     steps=spec2dict,\n                                                     output_dir=spec2_dir)\n        except Exception as e:\n            # A handle for when no slits fall on NRS2.\n            print(f\"Skipped processing {os.path.basename(asnfile)}: {e}\")\n    print(\"Spec2 has been completed for SCI data! \\n\")\nelse:\n    print('Skipping Spec2 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-3-1-calibrating-science-files","position":41},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"6.3.2 Calibrating Background Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl4","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-3-2-calibrating-background-files","position":42},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl4":"6.3.2 Calibrating Background Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Prepare background files for master background subtraction in Stage 3.\n\n# Run Stage 2 pipeline using the custom spec2dict dictionary.\n# Process dedicated background data to use in the master background step.\nif dospec2bg and master_bg:\n\n    # ------------------------Background RATE files------------------------\n    for file in rate_bg:\n        try:  # Create ASN files.\n            asnfile = os.path.join(asn_dir, os.path.basename(file).replace('rate.fits', 'l2asn.json'))\n            if writel2asn(file, rate_bg, [], asnfile, 'Level2', 'NRS_FIXEDSLIT'):\n                print(f\"Applying Stage 2 Corrections & Calibrations to: {file}\")\n                spec2sci_result = Spec2Pipeline.call(asnfile,\n                                                     save_results=True,\n                                                     steps=spec2dict,\n                                                     output_dir=spec2_dir)\n        except Exception as e:\n            # A handle for when no slices fall on NRS2.\n            print(f\"Skipped processing {os.path.basename(asnfile)}: {e}\")\n    print(\"Spec2 has been completed for BKG data! \\n\")\nelse:\n    print(\"Skipping Spec2 for BKG data. \\n\")\n\n\n\n\n\n# Print out the time benchmarks.\ntime3 = time.perf_counter()\nprint(f\"Runtime so far: {round((time3-time0)/60.0, 1):0.4f} min\")\nprint(f\"Runtime for Spec2: {round((time3-time_spec2)/60.0, 1):0.4f} min\")\n\n\n\n# List the Stage 2 products.\n\n# -----------------------------Science files-----------------------------\nsci_cal = sorted(glob.glob(spec2_dir + '*_cal.fits'))\nsci_s2d = sorted(glob.glob(spec2_dir + '*_s2d.fits'))\nsci_x1d = sorted(glob.glob(spec2_dir + '*_x1d.fits'))\n\nprint(f\"SCIENCE | Stage 2 CAL Products:\\n{'-'*20}\\n\" + \"\\n\".join(sci_cal))\nprint(f\"SCIENCE | Stage 2 S2D Products:\\n{'-'*20}\\n\" + \"\\n\".join(sci_s2d))\nprint(f\"SCIENCE | Stage 2 X1D Products:\\n{'-'*20}\\n\" + \"\\n\".join(sci_x1d))\n\nif dospec2bg:\n    # ----------------------------Background files---------------------------\n    bg_cal = sorted(glob.glob(spec2_bgdir + '*_cal.fits'))\n    bg_s2d = sorted(glob.glob(spec2_bgdir + '*_s2d.fits'))\n    bg_x1d = sorted(glob.glob(spec2_bgdir + '*_x1d.fits'))\n\n    print(f\"BACKGROUND | Stage 2 CAL Products:\\n{'-'*20}\\n\" + \"\\n\".join(bg_cal))\n    print(f\"BACKGROUND | Stage 2 S2D Products:\\n{'-'*20}\\n\" + \"\\n\".join(bg_s2d))\n    print(f\"BACKGROUND | Stage 2 X1D Products:\\n{'-'*20}\\n\" + \"\\n\".join(bg_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-6-3-2-calibrating-background-files","position":43},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-stage-3-spec3pipeline-calwebb-spec3","position":44},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"In this section, we process our calibrated spectra from Stage 2 (calwebb_spec2) through the Spec3 (calwebb_spec3) pipeline to create Stage 3 \n\ndata products.\n\nInput: An ASN file that lists multiple calibrated exposures (_cal.fits) in addition to any background exposures (_x1d.fits).\n\nOutput: A single calibrated product (rectified and unrectified) and 1D spectrum. These data products have units of MJy/sr (or Jy for extracted point-source spectra).\n\n_cal.fits: Calibrated 2D (unrectified) spectra (ncols x nrows).\n\n_crf.fits: Calibrated 2D (unrectified) spectra whose DQ array has been updated to flag pixels detected as outliers (ncols x nrows).\n\n_s2d.fits: Resampled (rectified) 2D spectra (ncols x nrows).\n\n_x1d.fits: Extracted 1D spectroscopic data.\n\nThe Spec3Pipeline performs additional corrections (e.g., outlier detection, background subtraction) and combines calibrated data from multiple exposures (e.g. a dither/nod pattern) into a single 2D spectral product, as well as a combined 1D spectrum.\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-stage-3-spec3pipeline-calwebb-spec3","position":45},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"7.1 Configure Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-1-configure-spec3pipeline","position":46},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"7.1 Configure Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"The Spec3Pipeline has the following steps available for NIRSpec FS:\n\nassign_mtwcs: Modifies the WCS output frame in each exposure of a Moving Target (MT) observation association.\n\nmaster_background: Master background subtraction.\n\noutlier_detection : Identification of bad pixels or cosmic-rays that remain in each of the input images.\n\npixel_replace: Interpolates and estimates flux values for pixels flagged as DO_NOT_USE in 2D extracted spectra.\n\nresample_spec: Resamples each input 2D spectral image using WCS and distortion information.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox and\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Spec3Pipeline should be configured for FS data.\n\nIf master background subtraction was chosen above, it will be applied during this stage. To override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Spec3 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\nspec3dict = {}\nspec3dict['assign_mtwcs'], spec3dict['master_background'] = {}, {}\nspec3dict['outlier_detection'], spec3dict['pixel_replace'] = {}, {}\nspec3dict['resample_spec'], spec3dict['extract_1d'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n# Overrides for various reference files.\n# Files should be in the base local directory or provide full path.\n#spec3dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# -----------------------------Set step parameters------------------------------\n# Overrides for whether or not certain steps should be skipped (example).\n#spec3dict['outlier_detection']['skip'] = True\n\n# Master background usage was set up above, propagate that here.\nspec3dict['master_background']['skip'] = not master_bg\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels.\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\n#spec3dict['pixel_replace']['skip'] = False\n#spec3dict['pixel_replace']['n_adjacent_cols'] = 5\n#spec3dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n# Resample weight_type.\n#spec3dict['resample_spec']['weight_type'] = 'exptime'\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-1-configure-spec3pipeline","position":47},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"7.2 Create Spec3Pipeline Association Files","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-2-create-spec3pipeline-association-files","position":48},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"7.2 Create Spec3Pipeline Association Files","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"Stage 3 ASN files for FS data can include science and background exposure types. A Stage 3 ASN file requires at least one science file (there is usually more than one) but can contain multiple background files that enable master background subtraction in calwebb_spec3. Note that the science exposures should be in the _cal.fits format, while the background exposures must be in the _x1d.fits format.\n\nIn practice, Stage 3 ASN files can be downloaded directly from MAST, however, here we provide an example of manually creating Stage 3 ASN files. Below we create an ASN files for each GRATING/FILTER combination.\n\ndef writel3asn(scifiles, bgfiles):\n    \"\"\"\n    Create a Level 3 association file.\n\n    Parameters\n    ----------\n    scifiles : list of str\n        List of all science exposure files.\n    bgfiles : list of str\n        List of background exposure files.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n    # Filter based on GRATING/FILTER.\n    from collections import defaultdict\n    grouped = defaultdict(lambda: {'sci': [], 'bg': []})\n\n    for f in scifiles:\n        k = (fits.getval(f, 'FILTER'), fits.getval(f, 'GRATING'), fits.getval(f, 'FXD_SLIT'))\n        grouped[k]['sci'].append(f)\n    for f in bgfiles:\n        k = (fits.getval(f, 'FILTER'), fits.getval(f, 'GRATING'), fits.getval(f, 'FXD_SLIT'))\n        grouped[k]['bg'].append(f)\n\n    # Make ASN for each FILTER/GRATING.\n    for (filt, grat, slit), files in grouped.items():\n        name = f\"{slit}_{filt}_{grat}\".lower()\n        asnfile = os.path.join(asn_dir, f\"{name}_l3asn.json\")\n        asn = afl.asn_from_list(files['sci'], rule=DMS_Level3_Base, product_name=name)\n        for bg in files['bg']:\n            asn['products'][0]['members'].append({'expname': bg, 'exptype': 'background'})\n        with open(asnfile, 'w') as f:\n            f.write(asn.dump()[1])\n    print(\"Level 3 ASN creation complete!\")\n\n\n\nif dospec3:\n    writel3asn(sci_cal, bg_x1d if bg_dir else [])\n\n# Get list of all spec3 ASN files.\nspec3_asn = glob.glob(f\"{asn_dir}*l3asn.json\")\nprint(f\"Stage 3 ASN Files:\\n{'-'*20}\\n\" + \"\\n\".join(spec3_asn))\n\n\n\n# Open an ASN file as an example.\n# Check that file paths have been correctly updated.\nif dospec3:\n    with open(spec3_asn[0], 'r') as f_obj:\n        asnfile_data = json.load(f_obj)\n    display(JSON(asnfile_data, expanded=True))\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-2-create-spec3pipeline-association-files","position":49},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"7.3 Run Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-3-run-spec3pipeline","position":50},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"7.3 Run Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"Run the science files and, if available, any background files through the calwebb_spec3 pipeline using the .call() method.\n\ntime_spec3 = time.perf_counter()\n\n\n\n# Run Stage 3 pipeline using the custom spec3dict dictionary.\nif dospec3:\n\n    # --------------------------Spec3 ASN files--------------------------\n    for s3_asn in spec3_asn:\n        print(f\"Applying Stage 3 Corrections & Calibrations to: \"\n              f\"{os.path.basename(s3_asn)}\")\n\n        spec3_result = Spec3Pipeline.call(s3_asn,\n                                          save_results=True,\n                                          steps=spec3dict,\n                                          output_dir=spec3_dir)\n    print(\"Spec3 has been completed! \\n\")\nelse:\n    print(\"Skipping Spec3. \\n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmarks.\ntime4 = time.perf_counter()\nprint(f\"Runtime so far: {round((time4-time0)/60.0, 1):0.4f} min\")\nprint(f\"Runtime for Spec3: {round((time4-time_spec3)/60.0, 1):0.4f} min\")\n\n\n\n# List the Stage 3 products.\nstage3_cal = sorted(glob.glob(spec3_dir + '*_cal.fits'))\nstage3_s2d = sorted(glob.glob(spec3_dir + '*_s2d.fits'))\nstage3_x1d = sorted(glob.glob(spec3_dir + '*_x1d.fits'))\n\nprint(f\"Stage 3 CAL Products:\\n{'-'*20}\\n\" + \"\\n\".join(stage3_cal))\nprint(f\"Stage 3 S3D Products:\\n{'-'*20}\\n\" + \"\\n\".join(stage3_s2d))\nprint(f\"Stage 3 X1D Products:\\n{'-'*20}\\n\" + \"\\n\".join(stage3_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-7-3-run-spec3pipeline","position":51},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"8. Visualize the Data"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-visualize-the-data","position":52},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"8. Visualize the Data"},"content":"Define convenience funcitons for visualization. For some plots we utilize \n\njdaviz, a package of astronomical data analysis visualization tools designed to work in Jupyter notebooks.\n\nDefine a function to display Stage 1 products.\n\n# Function to display the rate files produced by Stage 1 in the\n# JWST Calibration Pipeline.\ndef display_rate(rates,\n                 slits_models=[],\n                 integration=0,\n                 extname='data',\n                 cmap='viridis',\n                 bad_color=(1, 0.7, 0.7),\n                 vmin=None,\n                 vmax=None,\n                 scale='asinh',\n                 aspect='auto',\n                 title_prefix=None,\n                 title_path=False,\n                 save_plot=False):\n    \"\"\"\n    Display countrate images.\n\n    Parameters\n    ----------\n    rates : list of str\n        A list of RATE[INTS] files to be displayed.\n    slits_models : list of str, optional\n        A list of CAL[INTS] or S2D files containing the slit models.\n        If provided, slit cutouts will be overlaid on the countrate images.\n    integration : {None, 'min', int}, optional\n        Specifies the integration to use for multi-integration data.\n        If 'min', the minimum value across all integrations is used.\n        If an integer, the specific integration index is used (default 0).\n    extname : str, optional\n        The name of the data extension to extract from ('data', 'dq', etc.).\n    cmap : str, optional\n        Colormap to use for displaying the image. Default is 'viridis'.\n    bad_color : tuple of float, optional\n        Color to use for NaN pixels. Default is light red (1, 0.7, 0.7).\n    vmin : float, optional\n        Minimum value for color scaling. If None, determined from the data.\n    vmax : float, optional\n        Maximum value for color scaling. If None, determined from the data.\n    scale : {'linear', 'log', 'asinh'}, optional\n        Scale to use for the image normalization. Default is 'asinh'.\n    aspect : str, optional\n        Aspect ratio of the plot. Default is 'auto'.\n    title_prefix : str, optional\n        Optional prefix for the plot title.\n    title_path : bool, optional\n        If True, uses the full file path for the title;\n        otherwise, uses the basename. Default is False.\n    save_plot : bool, optional\n        If True, saves the plot as a PNG file. Default is False.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n\n    # -------------------------------Check Inputs-------------------------------\n    rates = [rates] if isinstance(rates, str) else rates\n    slits_models = [slits_models] if isinstance(slits_models, str) else slits_models\n    nrates = len(rates)\n\n    # ------------------------------Set up figures------------------------------\n    fig, axes = plt.subplots(nrates, 1, figsize=(12, 12 * nrates),\n                             sharex=True, height_ratios=[1] * nrates)\n    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n    axes = [axes] if nrates == 1 else axes\n\n    cmap = plt.get_cmap(cmap)  # Set up colormap and bad pixel color.\n    cmap.set_bad(bad_color, 1.0)\n\n    # ---------------------------Plot countrate image---------------------------\n    for i, (rate, cal) in enumerate(itertools.zip_longest(rates,\n                                                          slits_models,\n                                                          fillvalue=None)):\n\n        # -------------------Open files as JWST datamodels-------------------\n        model = datamodels.open(rate)\n        slits_model = datamodels.open(cal) if cal else None\n\n        # -----------------------Extract the 2D/3D data----------------------\n        data_2d = getattr(model, extname)\n        if data_2d.ndim == 3:  # Handle multi-integration data.\n            if integration == 'min':\n                data_2d = np.nanmin(data_2d, axis=0)\n            elif isinstance(integration, int) and 0 <= integration < data_2d.shape[0]:\n                data_2d = data_2d[integration]\n            else:\n                raise ValueError(f\"Invalid integration '{integration}' for 3D data.\")\n\n        # ---------------------------Scale the data-------------------------\n        sigma_clipped_data = sigma_clip(data_2d, sigma=5, maxiters=3)\n        vmin = np.nanmin(sigma_clipped_data) if vmin is None else vmin\n        vmax = np.nanmax(sigma_clipped_data) if vmax is None else vmax\n        stretch_map = {'log': LogStretch(), 'linear': LinearStretch(),\n                       'asinh': AsinhStretch()}\n        if scale in stretch_map:\n            norm = ImageNormalize(sigma_clipped_data,\n                                  interval=ManualInterval(vmin=vmin, vmax=vmax),\n                                  stretch=stretch_map[scale])\n        else:\n            norm = simple_norm(sigma_clipped_data, vmin=vmin, vmax=vmax)\n\n        # ----------------Plot the countrate image & colorbar---------------\n        plt.subplots_adjust(left=0.05, right=0.85)\n        im = axes[i].imshow(data_2d, origin='lower', cmap=cmap,\n                            norm=norm, aspect=aspect, interpolation='nearest')\n        units = model.meta.bunit_data\n        cbar_ax = fig.add_axes([axes[i].get_position().x1 + 0.02,\n                                axes[i].get_position().y0, 0.02,\n                                axes[i].get_position().height])\n        cbar = fig.colorbar(im, cax=cbar_ax)\n        cbar.set_label(units, fontsize=12)\n\n        # -----------------Draw slits and label source ids------------------\n        # slits_model can be s2d/cal from spec2 - contains slit models for all sources.\n        if slits_model:\n            slit_patches = []\n            for slit in slits_model.slits:\n                slit_patch = Rectangle((slit.xstart, slit.ystart),\n                                       slit.xsize, slit.ysize)\n                slit_patches.append(slit_patch)\n                y = slit.ystart + slit.ysize / 2\n                x = slit.xstart if 'nrs1' in rate else slit.xstart + slit.xsize\n                ha = 'right' if 'nrs1' in rate else 'left'\n                plt.text(x, y, slit.source_id, color='w', ha=ha, va='center',\n                         fontsize=7, path_effects=[], weight='bold')\n            axes[i].add_collection(PatchCollection(slit_patches, ec='r', fc='None'))\n\n        # -----------------Construct title and axis labels------------------\n        filename = model.meta.filename\n        title = (f\"{title_prefix + ' ' if title_prefix else ''}\"\n                 f\"{filename if title_path else os.path.basename(filename)}\")\n        if integration is not None:\n            title = title.replace('rateints', f'rateints[{integration}]')\n        axes[i].set_title(title, fontsize=14)\n        axes[i].set_xlabel(\"Pixel Column\", fontsize=12)\n        axes[i].set_ylabel(\"Pixel Row\", fontsize=12)\n\n        # -------------------------Save the figure?-------------------------\n        if save_plot:\n            save_plot = rate.replace('fits', 'png')\n            if integration:\n                save_plot = save_plot.replace('.png', '%s.png' % integration)\n            fig.savefig(save_plot, dpi=200)\n\n        fig.show()\n\n\n\n# Function to display the spectra generated in stage 2/3 of the\n# JWST Calibration Pipeline.\ndef display_spectra(spectra,\n                    compare_x1d=None,\n                    compare_mast=None,\n                    integration=None,\n                    extname='data',\n                    source_id=1,\n                    source_type=None,\n                    expand_wavelength_gap=True,\n                    plot_resample=True,\n                    plot_errors=False,\n                    cmap='viridis',\n                    bad_color=(1, 0.7, 0.7),\n                    aspect='auto',\n                    vmin=None,\n                    vmax=None,\n                    scale='asinh',\n                    title_prefix=None,\n                    title_path=False,\n                    y_limits=None,\n                    is_stage3=False):\n\n    \"\"\"\n    Display 2D and 1D spectra (Stage 2/3).\n\n    Parameters\n    ----------\n    spectra : list of str\n        A list of data products (e.g., CAL, S2D, X1D files).\n    compare_x1d : list of str, optional\n        A list of 1D spectra for comparison (X1D files).\n    compare_mast : list of str, optional\n        A list of 1D spectra from MAST for comparison (X1D files).\n    integration : {None, 'min', int}, optional\n        Specifies the integration to use for multi-integration data.\n        If 'min', the minimum value across all integrations is used.\n        If an integer, the specific integration index is used (default 0).\n     extname : str, optional\n        The name of the data extension to extract ('data', 'dq', etc.).\n    source_id : int or str, optional\n        Identifier for the source/slit to be displayed. Default is 1.\n    source_type : str, optional\n        Override data source type ('POINT' or 'EXTENDED').\n    expand_wavelength_gap : bool, optional\n        If True, expands gaps in the wavelength data for better visualization.\n    plot_resample : bool, optional\n        If True, plots resampled (S2D) data products;\n        otherwise, plots calibrated (CAL) data. Default is True.\n    plot_errors : bool, optional\n        If True, plots the error bands for the 1D spectra. Default is False.\n    cmap : str, optional\n        Colormap to use for displaying the images. Default is 'viridis'.\n    bad_color : tuple of float, optional\n        Color to use for bad pixels. Default is light red (1, 0.7, 0.7).\n    aspect : str, optional\n        Aspect ratio of the plot. Default is 'auto'.\n    vmin : float, optional\n        Minimum value for color scaling. If None, determined from the data.\n    vmax : float, optional\n        Maximum value for color scaling. If None, determined from the data.\n    scale : {'linear', 'log', 'asinh'}, optional\n        Scale to use for the image normalization. Default is 'asinh'.\n    title_prefix : str, optional\n        Optional prefix for the plot title.\n    title_path : bool, optional\n        If True, uses the full file path for the title;\n        otherwise, uses the basename. Default is False.\n    y_limits : tuple of float, optional\n        Limits for the y-axis of the 1D spectrum plot.\n        If None, limits are determined from the data.\n    is_stage3 : bool, optional\n        Plot stage 3 products? Default is False.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n\n    # ---------------------------------Check Inputs---------------------------------\n    spectra = [spectra] if isinstance(spectra, str) else spectra\n    compare_x1d = [compare_x1d] if isinstance(compare_x1d, str) else compare_x1d\n    compare_mast = [compare_mast] if isinstance(compare_mast, str) else compare_mast\n\n    # Plot stage 3 products?\n    if is_stage3:\n\n        # Stage 3 products should include the source_id in the filename.\n        # Sort based on filename rather than open all.\n        def filter_prod(products, source_id):\n            \"\"\"Filter products based on the source_id.\"\"\"\n            return [f for f in products if source_id.lower() in f and ('FXD_SLIT' not in fits.getheader(f, ext=0) or fits.getheader(f, ext=0)['FXD_SLIT'].lower() == source_id.lower())]\n\n        spectra = filter_prod(spectra, source_id)\n        compare_x1d = filter_prod(compare_x1d, source_id) if compare_x1d else None\n        compare_mast = filter_prod(compare_mast, source_id) if compare_mast else None\n\n    ftypes = {ftype: [f for f in spectra\n                      if ftype in f] for ftype in [\"cal\", \"s2d\", \"x1d\"]}\n    products = sorted(ftypes['s2d']) if plot_resample else sorted(ftypes['cal'])\n    if not products:\n        raise ValueError(\"No valid data products found for plotting.\")\n\n    # --------------------------------Set up figures-------------------------------\n    total_plots = len(products) + bool(ftypes['x1d'])\n    height_ratios = [1] * len(products) + ([3] if bool(ftypes['x1d']) else [])\n    fig, axes = plt.subplots(total_plots, 1, figsize=(15, 5 * total_plots),\n                             sharex=False, height_ratios=height_ratios)\n    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n    ax2d, ax1d = (axes[:-1], axes[-1]) if bool(ftypes['x1d']) else (axes, None)\n\n    cmap = plt.get_cmap(cmap)  # Set up colormap and bad pixel color.\n    cmap.set_bad(bad_color, 1.0)\n    colors = plt.get_cmap('tab10').colors\n    color_cycle = itertools.cycle(colors)\n\n    # ---------------------------------Plot spectra--------------------------------\n    for i, product in enumerate(products):\n        model = datamodels.open(product)  # Open files as JWST datamodels.\n\n        # Extract the correct 2D source spectrum if there are multiple.\n        slit_m = model\n        if 'slits' in model:\n            slits = model.slits\n            slit_m = next((s for s in slits\n                           if getattr(s, 'name', None) == source_id), None)\n            slit_m = slit_m or next((s for s in model.slits\n                                     if s.source_id == source_id), None)\n            if not slit_m:\n                print(f\"'{source_id}' not found/invalid in {os.path.basename(product)}\")\n                print(f\"Available source_ids: {[s.source_id for s in slits][:5]}\")\n                continue\n\n        # Check if 'fixed_slit' exists, otherwise fall back to 'slitlet_id'\n        slit_name = (f\"SLIT: {getattr(slit_m, 'name', None) or slit_m.slitlet_id}, \"\n                     f\"SOURCE: {getattr(slit_m, 'source_id', '')}\")\n\n        # -----------------------Extract the 2D/3D data----------------------\n        data_2d = getattr(slit_m, extname)\n        if data_2d.ndim == 3:  # Handle multi-integration data.\n            if integration == 'min':\n                data_2d = np.nanmin(data_2d, axis=0)\n            elif isinstance(integration, int) and 0 <= integration < data_2d.shape[0]:\n                data_2d = data_2d[integration]\n            else:\n                raise ValueError(f\"Invalid integration '{integration}' for 3D data.\")\n\n        # -----------Convert from pixels to wavelength (x-axis)--------------\n        wcsobj = slit_m.meta.wcs  # Obtaining the WCS object from the meta data.\n        y, x = np.mgrid[:slit_m.data.shape[0], :slit_m.data.shape[1]]\n        # Coordinate transform from detector space (pixels) to sky (RA, DEC).\n        det2sky = wcsobj.get_transform('detector', 'world')\n        ra, dec, s2dwave = det2sky(x, y)  # RA/Dec, wavelength (microns) for each pixel.\n        s2dwaves = s2dwave[0, :]  # Single row since this is the rectified spectrum.\n        x_arr = np.arange(0, slit_m.data.shape[1], int(len(slit_m.data[1]) / 4))\n        wav = np.round(s2dwaves[x_arr], 2)  # Populating the wavelength array.\n        ax2d[i].set_xticks(x_arr, wav)\n\n        # xticks = np.arange(np.ceil(wave_1d[0]), wave_1d[-1], 0.2)\n        # xtick_pos = np.interp(xticks, wave_1d, np.arange(num_waves))\n        # ax1d.set_xticks(xtick_pos)\n        # ax1d.set_xticklabels([f'{xtick:.1f}' for xtick in xticks])\n\n        # ---------------------------Scale the data-------------------------\n        sigma_clipped_data = sigma_clip(data_2d, sigma=5, maxiters=3)\n        vmin = np.nanmin(sigma_clipped_data) if vmin is None else vmin\n        vmax = np.nanmax(sigma_clipped_data) if vmax is None else vmax\n        stretch_map = {'log': LogStretch(), 'linear': LinearStretch(),\n                       'asinh': AsinhStretch()}\n        if scale in stretch_map:\n            norm = ImageNormalize(sigma_clipped_data,\n                                  interval=ManualInterval(vmin=vmin, vmax=vmax),\n                                  stretch=stretch_map[scale])\n        else:\n            norm = simple_norm(sigma_clipped_data, vmin=vmin, vmax=vmax)\n\n        # -------------------------Plot 1D Spectra-------------------------\n        for prods_1d, prefix in [(sorted(ftypes['x1d']), f'{title_prefix} '),\n                                 (compare_x1d, 'RE-EXTRACTION '),\n                                 (compare_mast, 'MAST ')]:\n            if prods_1d:\n\n                model_1d = datamodels.open(prods_1d[i])\n                specs = model_1d.spec\n                spec = next((s for s in specs if\n                             getattr(s, 'name', None) == source_id), None)\n                spec = spec or next((s for s in specs\n                                     if s.source_id == source_id), None)\n\n                if spec:\n                    tab = spec.spec_table\n                    source_type = source_type if source_type else slit_m.source_type\n                    wave = tab.WAVELENGTH\n                    flux = tab.FLUX if source_type == 'POINT' else tab.SURF_BRIGHT\n                    errs = tab.FLUX_ERROR if source_type == 'POINT' else tab.SB_ERROR\n\n                    # Expand the array to visualize the wavelength gap.\n                    if expand_wavelength_gap:\n                        dx1d_wave = wave[1:] - wave[:-1]\n                        igap = np.argmax(dx1d_wave)\n                        dx_replace = (dx1d_wave[igap - 1] + dx1d_wave[igap + 1]) / 2.\n                        nfill = int(np.round(np.nanmax(dx1d_wave) / dx_replace))\n\n                        if nfill > 1:\n                            print(f\"Expanding wavelength gap {wave[igap]:.2f} \"\n                                  f\"-- {wave[igap + 1]:.2f} μm\")\n\n                            wave_fill = np.mgrid[wave[igap]:wave[igap + 1]:(nfill + 1) * 1j]\n                            wave = np.concatenate([wave[:igap + 1],\n                                                   wave_fill[1:-1],\n                                                   wave[igap + 1:]])\n\n                            if prefix != 'RE-EXTRACTION ':\n                                num_rows, num_waves = data_2d.shape\n                                fill_2d = np.zeros(shape=(num_rows, nfill - 1)) * np.nan\n                                data_2d = np.concatenate([data_2d[:, :igap + 1],\n                                                          fill_2d, data_2d[:, igap + 1:]],\n                                                         axis=1)\n\n                            fill = np.zeros(shape=(nfill - 1)) * np.nan\n                            flux = np.concatenate([flux[:igap + 1], fill, flux[igap + 1:]])\n                            errs = np.concatenate([errs[:igap + 1], fill, errs[igap + 1:]])\n                    else:\n                        nfill = 0\n\n                    # ----------------Construct legends and annotations-----------------\n                    detector = slit_m.meta.instrument.detector\n                    ffilter = slit_m.meta.instrument.filter\n                    grating = slit_m.meta.instrument.grating\n                    dither = model.meta.dither.position_number\n                    label_2d = f'{grating}/{ffilter}'\n                    label_1d = f'{detector} ({grating}/{ffilter})'\n                    if not is_stage3:\n                        label_2d = f'Dither/Nod {dither} ({label_2d})'\n                        label_1d = (f'{prefix} Dither/Nod {dither} {label_1d}')\n                    else:\n                        label_1d = f'{prefix}{label_1d}'\n                    ax2d[i].annotate(label_2d, xy=(1, 1), xycoords='axes fraction',\n                                     xytext=(-10, -10), textcoords='offset points',\n                                     bbox=dict(boxstyle=\"round,pad=0.3\",\n                                               edgecolor='white',\n                                               facecolor='white', alpha=0.8),\n                                     fontsize=12, ha='right', va='top')\n\n                    title_2d = (f\"{title_prefix + ' ' if title_prefix else ''}\"\n                                f\"{model.meta.filename} | {slit_name}\")\n                    if integration:\n                        title_2d = title_2d.replace('.fits', f'[{integration}].fits')\n                    ax2d[i].set_title(title_2d, fontsize=14)\n                    if not bool(ftypes['x1d']):\n                        ax2d[i].set_xlabel(\"Wavelength (μm)\", fontsize=12)\n                    ax2d[i].set_ylabel(\"Pixel Row\", fontsize=12)\n                    ax2d[i].legend(fontsize=12)\n\n                    # ------------------------------------------------------------------\n\n                    num_waves = len(wave)\n                    color = next(color_cycle)\n                    ax1d.step(wave, flux, lw=1, label=label_1d, color=color)\n                    if plot_errors:\n                        ax1d.fill_between(np.arange(num_waves), flux - errs,\n                                          flux + errs, color='grey', alpha=0.3)\n                    ax1d.legend(fontsize=12)\n                    ax1d.set_title(f\"{title_prefix + ' ' if title_prefix else ''}\"\n                                   f\"Extracted 1D Spectra | {slit_name}\", fontsize=14)\n                    ax1d.set_ylabel(\"Flux (Jy)\" if source_type == 'POINT'\n                                    else \"Surface Brightness (MJy/sr)\", fontsize=12)\n                    ax1d.set_xlabel(\"Wavelength (μm)\", fontsize=12)\n\n                    ax1d.set_ylim(y_limits or (np.nanpercentile(flux, 1),\n                                               np.nanpercentile(flux, 99.5)))\n\n                    # --------------------Plot the 2D spectra & colorbar---------------\n                    plt.subplots_adjust(left=0.05, right=0.85)\n                    im = ax2d[i].imshow(data_2d, origin='lower', cmap=cmap, norm=norm,\n                                        aspect=aspect, interpolation='nearest')\n                    units = slit_m.meta.bunit_data\n                    cbar_ax = fig.add_axes([ax2d[i].get_position().x1 + 0.02,\n                                            ax2d[i].get_position().y0, 0.02,\n                                            ax2d[i].get_position().height])\n                    cbar = fig.colorbar(im, cax=cbar_ax)\n                    cbar.set_label(units, fontsize=12)\n\n                    # ----------------------Add extraction region---------------------\n                    ystart, ystop, xstart, xstop = (spec.extraction_ystart - 1,\n                                                    spec.extraction_ystop - 1,\n                                                    spec.extraction_xstart - 1,\n                                                    spec.extraction_xstop - 1)\n                    extract_width = ystop - ystart + 1\n                    box = Rectangle((xstart, ystart), xstop - xstart + nfill,\n                                    extract_width, fc='None', ec=color,\n                                    lw=2, label=prefix)\n                    ax2d[i].add_patch(box)\n                    ax2d[i].legend()\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-visualize-the-data","position":53},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-1-display-detector1pipeline-products","position":54},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Inspect the Stage 1 slope products.\n\nif doviz:\n    rate_file = rate_sci[-1]  # Show the last rate file, as an example.\n    display_rate(rate_file, vmin=-0.1, vmax=1, scale='asinh',\n                 aspect=10, title_prefix='REPROCESSED')  # , extname='dq')\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-1-display-detector1pipeline-products","position":55},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"8.2 Display Spec2Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-2-display-spec2pipeline-products","position":56},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"8.2 Display Spec2Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Inspect the Stage 2 calibrated spectra. Use Jdaviz \n\nSpecviz2D to visualize and analyze the Stage 2 2D and 1D calibrated spectra. For more information on these visualization tools and plotting capabilities, refer to the official documentation linked.\n\n# Plot the Stage 2 FS spectra with Specviz2D.\nif doviz:\n    try:\n        specviz2d = Specviz2d()\n        spectrum_1d = sorted(glob.glob(spec2_dir + '*x1d.fits'))[1]\n        spectrum_2d = sorted(glob.glob(spec2_dir + '*s2d.fits'))[1]\n        specviz2d.load_data(spectrum_1d)\n        specviz2d.show()\n    except Exception as e:\n        print(f\"Unable to run Specviz2D, using matplotlib instead. {e}\")\n        display_spectra(sci_s2d + sci_x1d, source_id='S200A1', scale='log',\n                        vmin=-0.1e-9, vmax=3e-8, title_prefix='REPROCESSED')\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-2-display-spec2pipeline-products","position":57},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"8.3 Display Spec3Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-3-display-spec3pipeline-products","position":58},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl3":"8.3 Display Spec3Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Inspect the Stage 3 combined calibrated spectra.\n\n# Plot the Stage 3 FS spectra with Specviz2D.\nif doviz:\n    try:\n        specviz2d = Specviz2d()\n        spectrum_1d = sorted(glob.glob(spec3_dir + '*x1d.fits'))[0]\n        spectrum_2d = sorted(glob.glob(spec3_dir + '*s2d.fits'))[0]\n        specviz2d.load_data(spectrum_2d=spectrum_2d, spectrum_1d=spectrum_1d)\n        specviz2d.show()\n    except ValueError:\n        print(\"Unable to display spectra with Specviz2d\")\n        display_spectra(stage3_s2d + stage3_x1d, source_id='S200A1', scale='log',\n                        vmin=-0.1e-9, vmax=3e-8, title_prefix='REPROCESSED', is_stage3=True)\n\n\n\n","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-8-3-display-spec3pipeline-products","position":59},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"type":"lvl2","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-9-modifying-the-extract1d-reference-file-as-needed","position":60},{"hierarchy":{"lvl1":"NIRSpec FS Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"content":"The extract_1d step’s use_source_pos parameter in Stage 2 generally centers the 1D extraction box on the actual source location effectively and thus doesn’t usually require manual adjustment. However, in some cases, adjusting the position of the extraction box by modifying the EXTRACT1D reference file may be useful. The following section demonstrates how to do this.\n\nThe EXTRACT1D reference file, along with several other parameter files, can be found in the CRDS_PATH directory. While some files, like .json files, can be manually edited, we modify them using Python.\n\nWarning: Currently, there is no aperture correction in place for NIRSpec, so the extract_width parameter MUST remain unchanged (6 pixels wide; 5 for S1600A1) to ensure proper flux calibration! The extraction box limits (ystart and ystop) can be modified; however, if ystart and ystop do not match the extract_width, the extract_width takes precedence and is applied symmetrically around the midpoint between ystart and ystop.\n\n# Modify the EXTRACT1D reference file.\n\n# If you don't know the reference file name this should work.\n# extract_1d_ref = Spec3Pipeline().get_reference_file(stage3_s2d, 'extract1d')\n\nrefs = api.dump_references(crds_client.get_context_used('jwst'),\n                           ['jwst_nirspec_extract1d_0008.json'])\nextract_1d_ref = refs['jwst_nirspec_extract1d_0008.json']\n\n# Open EXTRACT1D reference file in read-mode.\nwith open(extract_1d_ref, \"r\") as ref_file:\n    params = json.load(ref_file)\n\n    yshift = -4  # Applied shift in pixels as example.\n\n    # S200A1\n    params[\"apertures\"][0][\"extract_width\"] = 6\n    params[\"apertures\"][0][\"ystart\"] += yshift\n    params[\"apertures\"][0][\"ystop\"] += yshift\n\n    # S200B1\n    params[\"apertures\"][1][\"extract_width\"] = 6\n    params[\"apertures\"][1][\"ystart\"] = 26.5\n    params[\"apertures\"][1][\"ystop\"] = 31.5\n\n    # S200A2\n    params[\"apertures\"][2][\"extract_width\"] = 6\n    params[\"apertures\"][2][\"ystart\"] = 26.5\n    params[\"apertures\"][2][\"ystop\"] = 31.5\n\n    # S400A1\n    params[\"apertures\"][3][\"extract_width\"] = 6\n    params[\"apertures\"][3][\"ystart\"] = 31\n    params[\"apertures\"][3][\"ystop\"] = 36\n\n    # S1600A1\n    params[\"apertures\"][4][\"extract_width\"] = 5\n    params[\"apertures\"][4][\"ystart\"] = 14\n    params[\"apertures\"][4][\"ystop\"] = 18\n\n# Write changes to a new file.\nnewData = json.dumps(params, indent=4)\n# Add the suffix '_fs' to distinguish the file from the default version.\nbasename = os.path.basename(extract_1d_ref)[:-5]\nextract_1d_ref_mod = os.path.join(basedir, basename + \"_fs.json\")\nwith open(extract_1d_ref_mod, \"w\") as file:\n    file.write(newData)\n\n\n\n# Inspect the EXTRACT1D reference file.\nwith open(extract_1d_ref_mod, 'r') as f_obj:\n    extract_1d_ref_mod_data = json.load(f_obj)\n\nJSON(extract_1d_ref_mod_data, expanded=True)\n\n\n\nNow, we re-extract the 1D spectrum by running the Extract1dStep and overriding the reference file.\n\nExtract1dStep.call(stage3_s2d,\n                   save_results=True,\n                   output_dir=spec3_dir,\n                   output_use_model=True,\n                   suffix='x1d_mod',  # Change suffix to easily find modified file.\n                   use_source_posn=False,\n                   override_extract1d=extract_1d_ref_mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstage3_x1ds_mod = sorted(glob.glob(spec3_dir + '*_x1d_mod.fits'))\ndisplay_spectra(stage3_s2d + stage3_x1d, compare_x1d=stage3_x1ds_mod, source_id='S200A1',\n                scale='log', vmin=-0.1e-9, vmax=3e-8,\n                title_prefix='REPROCESSED', is_stage3=True)\n\n\n\nAs expected, the demo spectrum extracted in the shifted location has lower flux that the spectrum extracted in the center of the 2D spectral trace.\n\n\n\nTop of Page","type":"content","url":"/notebooks/nirspec/fslit/jwpipenb-nirspec-fs#id-9-modifying-the-extract1d-reference-file-as-needed","position":61},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu","position":0},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu","position":1},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#nirspec-ifu-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook"},"content":"\n\nAuthors: Kayli Glidic (\n\nkglidic@stsci.edu), Maria Pena-Guerrero (\n\npena@stsci.edu), Leonardo Ubeda (\n\nlubeda@stsci.edu); NIRSpec branch\nLast Updated: July 16, 2025 \nPipeline Version: 1.19.1 (Build 12.0, Context jwst_1413.pmap)\n\nPurpose:\nEnd-to-end calibration with the James Webb Space Telescope (JWST) pipeline is divided into three main processing stages. This notebook provides a framework for processing generic Near-Infrared Spectrograph (NIRSpec) integral field unit (IFU) data through \n\nstages 1-3 of the JWST pipeline, including how to use associations for multi-exposure observations and how to interact and work with JWST datamodels. Data is assumed to be organized into two folders: science and background, as specified in the paths set up below. In most cases, editing cells outside the \n\nConfiguration section is unnecessary unless the standard pipeline processing options or plot parameters need to be modified.\n\nData:\nThis notebook is set up to use observations of Tarantula Nebula with the G140H, G235H, and G395H grisms obtained by Proposal ID (PID) 2729, Observation 5. This observation has a CYCLING dither pattern with 8 points. These observations do not include nods or background. The demo data will automatically download unless disabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements.\nAny \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated to incorporate the latest pipeline improvements. Find the most up-to-date version of this notebook \n\nhere.\n\nRecent Changes:\n\nOctober 15, 2024: Converted notebook to follow standard template. \n\nNovember 4, 2024: Notebook updated to JWST pipeline version 1.16.0 (Build 11.1).\n\nJanuary 7, 2025: Add handling for background and CRDS.\n\nFebruary 7, 2025: Always construct associations within this notebook, generalize plotting.\n\nApril 16, 2025: Notebook updated to JWST pipeline version 1.18.0 (Build 11.3) and added Jdaviz plotting options.\n\nJuly 16, 2025: Updated to JWST pipeline version 1.19.1 (no significant changes)\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#nirspec-ifu-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#table-of-contents","position":4},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"Table of Contents"},"content":"1. Configuration\n\n2. Package Imports\n\n3. Demo Mode Setup\n\n4. Directory Setup\n\n5. Stage 1: Detector1Pipeline (calwebb_detector1)\n\n5.1 Configure Detector1Pipeline\n\n5.2 Run Detector1Pipeline\n\n5.2.1 Calibrating Science Files\n\n5.2.2 Calibrating Background Files\n\n6. Stage 2: Spec2Pipeline (calwebb_spec2)\n\n6.1 Configure Spec2Pipeline\n\n6.2 Create Spec2Pipeline Association Files\n\n6.3 Run Spec2Pipeline\n\n6.3.1 Calibrating Science Files\n\n6.3.2 Calibrating Background Files\n\n7. Stage 3: Spec3Pipeline (calwebb_spec3)\n\n7.1 Configure Spec3Pipeline\n\n7.2 Create Spec3Pipeline Association Files\n\n7.3 Run Spec3Pipeline\n\n8. Visualize the Data\n\n8.1 Display Detector1Pipeline Products\n\n8.2 Display Spec3Pipeline Products\n\n9. Modifying the EXTRACT1D Reference File (as needed)\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#table-of-contents","position":5},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-1-configuration","position":6},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"1. Configuration"},"content":"","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-1-configuration","position":7},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl4","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#install-dependencies-and-parameters","position":8},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"To make sure that the pipeline version is compatible with the steps discussed below and that the required dependencies and packages get installed, you can create a fresh Conda environment and install the provided requirements.txt file before starting this notebook:conda create -n nirspec_ifu_pipeline python=3.12\nconda activate nirspec_ifu_pipeline\npip install -r requirements.txt\n\nSet the basic parameters to configure the notebook. These parameters determine what data gets used, where data is located (if already on disk), and the type of background subtraction (if any). The list of parameters includes:\n\ndemo_mode:\n\nTrue: Downloads example data from the \n\nBarbara A. Mikulski Archive for Space Telescopes (MAST) and processes it through the pipeline. All processing will occur in a local directory unless modified in \n\nSection 3 below.\n\nFalse: Process your own downloaded data; provide its location. \n\nDirectories with data:\n\nsci_dir: Directory where science observation data is stored.\n\nbg_dir: Directory where background observation data is stored. \n\nBackgroud subtraction methods (True = run, False = skip):\n\nmaster_bg: Apply master-background subtraction in calwebb_spec3? Uses dedicated background observations.\n\npixel_bg: Apply pixel-to-pixel background subtraction in calwebb_spec2? This is the default pipeline setting. Uses noded observations.\n\n# Basic import necessary for configuration.\n# Uncomment logging to hide log information.\n\nimport os\nimport warnings\n#import logging\n\n# Control logging level: INFO, WARNING, ERROR\n# Run command loging.disable if want to hide logging\n# ERROR messages.\n#logging.disable(logging.ERROR)\nwarnings.simplefilter(\"ignore\", RuntimeWarning)\n\n\n\nNote that demo_mode must be set appropriately below.\n\n# Set parameters for demo_mode, data mode directories, and processing steps.\n\n# -------------------------------DEMO MODE-----------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# ----------------------------User Mode Directories--------------------------\nelse:  # If demo_mode = False, look for user data in these paths.\n\n    # Set directory paths for processing specific data; adjust to your local\n    # directory setup (examples provided below).\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n\n    # Directory to science observation data; expects uncalibrated data in\n    # sci_dir/uncal/ and results in stage1, stage2, and stage3 directories.\n    sci_dir = os.path.join(basedir, 'ifu_data_02729/Obs005', '')\n\n    # Directory to dedicated background observation data; expects uncalibrated data in\n    # bg_dir/uncal/ and results in stage1, stage2, and stage3 directories.\n    # bg_dir = os.path.join(basedir, 'ifu_data_02729/Obs002', '')\n    bg_dir = ''  # If no dedicated background observation, use an empty string.\n\n# ---------------------------Set Processing Steps----------------------------\n# Individual pipeline stages can be turned on/off here. Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing.\ndodet1 = True  # calwebb_detector1\ndospec2 = True  # calwebb_spec2\ndospec3 = True  # calwebb_spec3\ndoviz = True  # Visualize calwebb outputs\n\n# Dedicated Background Processing\ndodet1bg = False  # calwebb_detector1\ndospec2bg = False  # calwebb_spec2 (needed for Master Background subtraction)\n\n# How should background subtraction be done?\n# Dedicated backgrounds can either use master or pixel-based subtraction\n# Nodded backgrounds can use only pixel-based subtraction\n# If none are selected, data will not be background subtracted.\nmaster_bg = False  # Master-background subtraction in spec3.\npixel_bg = False  # Pixel-based background subtraction in spec2.\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#install-dependencies-and-parameters","position":9},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#set-crds-context-and-server","position":10},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline. If the local CRDS cache directory has not been set, it will automatically be created in the home directory.\n\n\nBuild Context Table\n\n# ------------------------Set CRDS context and paths------------------------\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n# os.environ['CRDS_CONTEXT'] = 'jwst_1364.pmap'  # CRDS context for 1.18.0\n\n# Set CRDS cache directory to user home if not already set.\nif os.getenv('CRDS_PATH') is None:\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds_cache')\n\n# Check whether the CRDS server URL has been set. If not, set it.\nif os.getenv('CRDS_SERVER_URL') is None:\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Output the current CRDS path and server URL in use.\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#set-crds-context-and-server","position":11},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-2-package-imports","position":12},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook.\nfrom IPython.display import display, HTML, JSON\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# ----------------------General Imports----------------------\nimport time\nimport copy\nimport json\nimport glob\nimport asdf\nimport itertools\nimport numpy as np\nfrom pprint import pprint\n\n# ----------------------Astropy Imports----------------------\n# Astropy utilities for opening FITS files, downloading demo files, etc.\nfrom astropy.io import fits\nfrom astropy.stats import sigma_clip\nfrom astropy.visualization import ImageNormalize, ManualInterval, LogStretch\nfrom astropy.visualization import LinearStretch, AsinhStretch, simple_norm\n\n# -------------------- Astroquery Imports ----------------------\nfrom astroquery.mast import Observations\n\n# ----------------------Plotting Imports---------------------\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Circle\nfrom matplotlib.collections import PatchCollection\nfrom jdaviz import Cubeviz, Specviz\nfrom specutils import Spectrum1D\n\n\n\nInstallation instructions for the JWST pipeline found here: \n\nJDox • \n\nReadtheDocs • \n\nGithub\n\n# ----------------------JWST Calibration Pipeline Imports----------------------\nimport jwst  # Import the base JWST and CRDS packages.\nimport crds\nfrom crds.client import api\nfrom stpipe import crds_client\n\n# JWST pipelines (each encompassing many steps).\nfrom jwst.pipeline import Detector1Pipeline  # calwebb_detector1\nfrom jwst.pipeline import Spec2Pipeline  # calwebb_spec2\nfrom jwst.pipeline import Spec3Pipeline  # calwebb_spec3\nfrom jwst.extract_1d import Extract1dStep  # Extract1D Step\n\n# JWST pipeline utilities\nfrom jwst import datamodels  # JWST pipeline utilities: datamodels.\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files.\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Define Lvl2 ASN.\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Define Lvl3 ASN.\n\n# Check the default context for the Pipeline version\ndefault_context = crds.get_default_context('jwst', state='build')\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(f\"Default CRDS Context for JWST Version {jwst.__version__}: {default_context}\")\nprint(f\"Using CRDS Context: {os.environ.get('CRDS_CONTEXT', default_context)}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-2-package-imports","position":13},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"Define Convience Functions","lvl2":"2. Package Imports"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#define-convience-functions","position":14},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"Define Convience Functions","lvl2":"2. Package Imports"},"content":"\n\nDefine a function that filters files based on detector, filter, and grating.\n\ndef get_matching(files, detector, filt, grating, exp_type):\n    \"\"\"\n    Filters a list of FITS files to find those with matching \n    detector, filter, and grating for a specified exposure type.\n\n    Parameters\n    ----------\n    files : list of str\n        Paths to FITS files to check.\n    detector : str\n        Expected value of the DETECTOR keyword.\n    filt : str\n        Expected value of the FILTER keyword.\n    grating : str\n        Expected value of the GRATING keyword.\n    exp_type : str, optional\n        The exposure type to match.\n\n    Returns\n    -------\n    files_regular : list of str\n        Files with matching configuration and IS_IMPRT == False or missing.\n    files_imprint : list of str)\n        Files with matching configuration and IS_IMPRT == True.\n    \"\"\"\n    files_regular, files_imprint = [], []\n    for file in files:\n        # Skip if EXP_TYPE doesn't match the provided one.\n        if fits.getval(file, 'EXP_TYPE') != exp_type:\n            files_regular.append(file)\n            continue\n        # Check if DETECTOR, FILTER, and GRATING match\n        detector_match = fits.getval(file, 'DETECTOR') == detector\n        filter_match = fits.getval(file, 'FILTER') == filt\n        grating_match = fits.getval(file, 'GRATING') == grating\n        if detector_match and filter_match and grating_match:\n            # Only IFU and MOS observations have imprint exposures.\n            try:\n                is_imprt = fits.getval(file, 'IS_IMPRT')\n            except KeyError:\n                is_imprt = None\n            (files_imprint if is_imprt else files_regular).append(file)\n    return files_regular, files_imprint\n\n\n\nDefine a function that checks the grating wheel tilt value between two files.\n\ndef match_gwa(file1, file2):\n    \"\"\"\n    Check if GWA tilt values match closely enough to be associated.\n\n    Parameters\n    ----------\n    file1, file2 : str \n        Input exposures FITS file paths.\n\n    Returns\n    -------\n    True if both GWA tilt values match within tolerance, else False.\n    \"\"\"\n    hdr1, hdr2 = fits.getheader(file1), fits.getheader(file2)\n    return np.allclose(\n        (hdr1['GWA_XTIL'], hdr1['GWA_YTIL']),\n        (hdr2['GWA_XTIL'], hdr2['GWA_YTIL']),\n        atol=1e-8, rtol=0\n    )\n\n\n\n# Start a timer to keep track of runtime.\ntime0 = time.perf_counter()\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#define-convience-functions","position":15},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":16},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"The data in this notebook is public and does not require a token. For other data sets, you may need to provide a token. For more infomation visit the \n\nastroquery documentation.\n\nIf running in demonstration mode, set up the program information to retrieve the uncalibrated data (_uncal.fits) automatically from MAST using astroquery. MAST provides flexibility by allowing searches based on proposal ID and observation ID, rather than relying solely on filenames. More information about the JWST file naming conventions can be found \n\nhere.\n\nThe IFU demo data in this notebook is from the \n\nEarly Release Science (ERS) Proposal ID 2729 and features observations of the Tarantula Nebula (extended source) using multiple grisms. The program setup is briefly summarized in the table below.\n\nDemo Target: Tarantula Nebula\n\n\n\n\n\nProposal ID\n\n02729\n\nProgram number\n\nOBSERVTN\n\n005\n\nObservation number\n\nGRATING/FILTER\n\nG140H/F100LP\n\nλ: 0.97–1.89 μm (a medium resolution, R ~ 1000)\n\n\n\nG235H/F170LP\n\nλ: 1.66–3.17 μm (a high resolution, R ~ 2700)\n\n\n\nG395H/F290LP\n\nλ: 2.87–5.27 μm (a high resolution, R ~ 2700)\n\nSUBARRAY\n\nSUBS200A1\n\nSubarray used\n\nNINTS\n\n2\n\nNumber of integrations in exposure\n\nNGROUPS\n\n30\n\nNumber of groups in integration\n\nDURATION\n\n87.533 [s]\n\nTotal duration of one exposure\n\nREADPATT\n\nNRSIRS2RAPID\n\nReadout Pattern\n\nPATTTYPE\n\nCYCLING\n\nPrimary dither pattern type\n\nPATTSIZE\n\nLARGE\n\nPrimary dither pattern size (1.0\" extent)\n\nNUMDTHPT\n\n8\n\nTotal number of points in pattern\n\nSRCTYAPT\n\nUNKNOWN\n\nSource Type selected in APT\n\nNote: The presence of a physical gap between detectors affects high-resolution IFU observations because the spectra are long enough to span both NIRSpec detectors. When using the grating-filter combination G140H/F070LP (or PRISM/CLEAR) the resulting spectra do not have any gaps because the spectra do not extend beyond NRS1. \n\nMore Info ...\n\n# Set up the program information and directories to collect\n# the data in demo_mode.\n\nif demo_mode:\n\n    print('Running in demonstration mode. '\n          'Example data will be downloaded from MAST!')\n\n    # NOTE:\n    # For non public data sets, you may need to provide a token.\n    # However, for security it is not recommended to enter tokens into\n    # a terminal or Jupyter notebook.\n    #Observations.login(token=\"\")\n\n    # --------------Program and observation information--------------\n    program = \"02729\"\n    sci_observtn = \"005\"\n    bg_observtn = None\n    # Possible filter options [\"F100LP;G140H\",\"F170LP;G235H\",\"F290LP;G395H\"].\n    # Limiting selection to one.\n    filters = [\"F290LP;G395H\"]\n\n    # ----------Define the base and observation directories----------\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n    sci_dir = os.path.join(basedir, f'ifu_data_{program}')\n    sci_dir = os.path.join(sci_dir, f'Obs{sci_observtn}')\n    uncal_dir = os.path.join(sci_dir, 'uncal/')\n\n    # If no background observation, leave blank.\n    bg_dir = os.path.join(basedir, f'ifu_data_{program}')\n    bg_dir = os.path.join(bg_dir, f'Obs{bg_observtn}') if bg_observtn else ''\n    uncal_bgdir = os.path.join(bg_dir, 'uncal/') if bg_observtn else ''\n\n    # ------Ensure directories for downloading MAST data exists------\n    os.makedirs(uncal_dir, exist_ok=True)\n    if bg_observtn:  # only if background observation is provided.\n        os.makedirs(uncal_bgdir, exist_ok=True)\n\nelse:\n    print('Running with user provided data.')\n\n\n\nClick on the following links to learn more about querying and downloading data:\n• \n\nDownloading data\n• \n\nObservations Class\n• \n\nProducts Field Descriptions\n\nCompile tables of files from MAST associated with the science (SCI) and, if applicable, background (BG) observations.\n\n# Obtain a list of observation IDs for the specified demo program.\n\nif demo_mode:\n    # --------------------SCIENCE Observation--------------------\n    sci_obs_id_table = Observations.query_criteria(instrument_name=['NIRSPEC/IFU'],\n                                                   provenance_name=[\"CALJWST\"],\n                                                   obs_id=[f'*{program}*{sci_observtn}*'])\n\n    # ------------------BACKGROUND Observation-------------------\n    if bg_observtn:\n        bg_obs_id_table = Observations.query_criteria(instrument_name=['NIRSPEC/IFU'],\n                                                      provenance_name=[\"CALJWST\"],\n                                                      obs_id=[f'*{program}*{bg_observtn}*'])\n\n\n\nFilter these tables to identify uncalibrated data from MAST.\n\nThe demo dataset consists of eight _uncal.fits files (per detector), each approximately 63 MB in size.\n\n# Convert visits into a list of uncalibrated data and ASN files.\n\nif demo_mode:\n    file_criteria = {'filters': filters, 'calib_level': [1],\n                     'productSubGroupDescription': 'UNCAL'}\n\n    # Initialize lists for science, background, and ASN files.\n    sci_downloads, bg_downloads = [], []\n\n    pfilter = Observations.filter_products  # Alias for filter_products method.\n\n    # ----------Identify uncalibrated SCIENCE files associated with each visit----------\n    for exposure in sci_obs_id_table:\n        sci_products = Observations.get_product_list(exposure)\n\n        # Filter for full-size science files (exclude smaller confirmation images).\n        avg_sci_size = np.nanmean(sci_products['size'])\n        sci_products = sci_products[sci_products['size'] > avg_sci_size]\n        sci_downloads.extend(pfilter(sci_products, **file_criteria)['dataURI'])\n\n    # Filter for full-size background files (exclude smaller confirmation images).\n    if bg_observtn:\n        for exposure in bg_obs_id_table:\n            bg_products = Observations.get_product_list(exposure)\n\n            avg_bg_size = np.nanmean(bg_products['size'])\n            bg_products = bg_products[bg_products['size'] > avg_bg_size]\n            bg_downloads.extend(pfilter(bg_products, **file_criteria)['dataURI'])\n\n    # Filter out other observations and remove duplicates.\n    sci_downloads = {f for f in sci_downloads if f\"jw{program}{sci_observtn}\" in f}\n\n    if bg_observtn:\n        bg_downloads = {f for f in bg_downloads if f\"jw{program}{bg_observtn}\" in f}\n        print(f\"Background files selected for downloading: {len(bg_downloads)}\")\n    else:\n        print(\"Background files selected for downloading: 0\")\n\n    print(f\"Science files selected for downloading: {len(sci_downloads)}\")\n\n\n\nDownload the data.\n\nWarning: If this notebook is halted during this step, the downloaded file may be incomplete, and cause crashes later on!\n\n# Download data and place them into the appropriate directories.\n\nif demo_mode:\n    for file in sci_downloads:\n        sci_manifest = Observations.download_file(file, local_path=uncal_dir)\n    for file in bg_downloads:\n        bg_manifest = Observations.download_file(file, local_path=uncal_bgdir)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":17},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-4-directory-setup","position":18},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"Set up detailed paths to input/output stages here.\n\n# Define/create output subdirectories to keep data products organized.\n\n# -----------------------------Science Directories------------------------------\nuncal_dir = os.path.join(sci_dir, 'uncal/')  # Uncalibrated pipeline inputs.\nasn_dir = os.path.join(sci_dir, 'asn/')  # Association files.\ndet1_dir = os.path.join(sci_dir, 'stage1/')  # calwebb_detector1 pipeline outputs.\nspec2_dir = os.path.join(sci_dir, 'stage2/')  # calwebb_spec2 pipeline outputs.\nspec3_dir = os.path.join(sci_dir, 'stage3/')  # calwebb_spec3 pipeline outputs.\n\nos.makedirs(asn_dir, exist_ok=True)\nos.makedirs(det1_dir, exist_ok=True)\nos.makedirs(spec2_dir, exist_ok=True)\nos.makedirs(spec3_dir, exist_ok=True)\n\n# ---------------------------Background Directories-----------------------------\nuncal_bgdir = os.path.join(bg_dir, 'uncal/')  # Uncalibrated pipeline inputs.\nasn_bgdir = os.path.join(bg_dir, 'asn/')  # Association files.\ndet1_bgdir = os.path.join(bg_dir, 'stage1/')  # calwebb_detector1 pipeline outputs.\nspec2_bgdir = os.path.join(bg_dir, 'stage2/')  # calwebb_spec2 pipeline outputs.\n\nif bg_dir:\n    os.makedirs(asn_bgdir, exist_ok=True)\n    os.makedirs(det1_bgdir, exist_ok=True)\n    os.makedirs(spec2_bgdir, exist_ok=True)\n\n\n\n# Print out the time benchmark.\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {round((time1-time0)/60.0, 1):0.4f} min\")\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-4-directory-setup","position":19},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-stage-1-detector1pipeline-calwebb-detector1","position":20},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"In this section, we process the data through the calwebb_detector1 pipeline to create Stage 1 \n\ndata products.\n\nInput: Raw exposure (_uncal.fits) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n\nOutput: Uncalibrated countrate (slope) image in units of DN/s:\n\n_rate.fits: A single countrate image averaged over multiple integrations (if available).\n\n_rateints.fits: Countrate images for each integration, saved in multiple extensions.\n\nThe Detector1Pipeline applies basic detector-level corrections on a group-by-group basis, followed by ramp fitting for all exposure types, commonly referred to as “ramps-to-slopes” processing.\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-stage-1-detector1pipeline-calwebb-detector1","position":21},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-1-configure-detector1pipeline","position":22},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"The Detector1Pipeline has the following steps available for NIRSpec IFU:\n\ngroup_scale : Rescales pixel values to correct for improper onboard frame averaging.\n\ndq_init : Initializes the data quality (DQ) flags for the input data.\n\nsaturation : Flags pixels at or below the A/D floor or above the saturation threshold.\n\nsuperbias : Subtracts the superbias reference file from the input data.\n\nrefpix : Use reference pixels to correct bias drifts.\n\nlinearity : Applies a correction for non-linear detector response.\n\ndark_current : Subtracts the dark current reference file from the input data.\n\njump : Performs CR/jump detection on each ramp integration within an exposure.\n\nclean_flicker_noise: Removes flicker (1/f) noise from calibrated ramp images (similar to nsclean in spec2).\n\nramp_fit : Determines the mean count rate (counts per second) for each pixel by performing a linear fit to the input data.\n\ngain_scale : Corrects pixel values for non-standard gain settings, primarily in NIRSpec subarray data.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox •\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Detector1Pipeline should be configured for IFU data.\n\nTo override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\ndet1dict['superbias'], det1dict['refpix'] = {}, {}\ndet1dict['linearity'], det1dict['dark_current'], det1dict['jump'] = {}, {}, {}\ndet1dict['clean_flicker_noise'], det1dict['ramp_fit'] = {}, {}\ndet1dict['gain_scale'] = {}\n\n# ---------------------------Override reference files---------------------------\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n#det1dict['superbias']['override_superbias'] = 'myfile.fits' # Bias subtraction\n#det1dict['dark_current']['override_dark'] = 'myfile.fits' # Dark current subtraction\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\ndet1dict['linearity']['skip'] = False  # This is the default.\n\n# Turn on multi-core processing for jump step (off by default).\n# Choose what fraction of cores to use (quarter, half, or all).\ndet1dict['jump']['maximum_cores'] = 'half'\n\n\n\n# Turn on detection of cosmic ray snowballs (on by default).\ndet1dict['jump']['expand_large_events'] = True\ndet1dict['jump']['expand_factor'] = 3  # (default 2).\n\n\n\nMany exposures are affected by artifacts known as \n\nsnowballs caused by large cosmic ray events. These artifacts are particularly significant in deep exposures with long integration times, with an estimated rate of one snowball per detector (FULL FRAME) per 20 seconds. To expand the number of pixels flagged as jumps around large cosmic ray events, set expand_large_events to True. An expand_factor of 3 works well for NIRSpec observations to cover most snowballs.\n\n# Turn on 1/f noise correction in Stage 1? (off by default).\n#det1dict['clean_flicker_noise']['skip'] = False\n\n\n\nJWST detector readout electronics (a.k.a. SIDECAR ASICs) generate significant 1/f noise during detector operations and signal digitization. This noise manifests as faint banding along the detector’s slow axis and varies from column to column. For NIRSpec data, the primary pipeline algorithm to address 1/f noise is nsclean in the Spec2Pipeline (Rauscher 2023) but is off by default.\n\nAn additional 1/f noise-cleaning algorithm, clean_flicker_noise, has been implemented at the group stage in the Detector1Pipeline. This step is also off by default.\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-1-configure-detector1pipeline","position":23},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-2-run-detector1pipeline","position":24},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Run the science files and, if available, any background files through the calwebb_detector1 pipeline using the .call() method.\n\nWe use .call() instead of .run() to ensure that the latest default parameters from CRDS are applied (\n\nReadtheDocs).\n\nThis stage takes approximately 14 minutes to process sixteen _uncal.fits files (~1 minutes per file) and generate _rate.fits files.\n\n# Final list of UNCAL files ready for Stage 1 processing.\nuncal_sci = sorted(glob.glob(uncal_dir + '*uncal.fits'))\nprint(f\"Science UNCAL Files:\\n{'-'*20}\\n\" + \"\\n\".join(uncal_sci))\n\nif bg_dir:\n    uncal_bg = sorted(glob.glob(uncal_bgdir + '*uncal.fits'))\n    print(f\"Background UNCAL Files:\\n{'-'*20}\\n\" + \"\\n\".join(uncal_bg))\n\n\n\ntime_det1 = time.perf_counter()  # Tracks runtime for Stage 1.\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-2-run-detector1pipeline","position":25},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"5.2.1 Calibrating Science Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl4","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-2-1-calibrating-science-files","position":26},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"5.2.1 Calibrating Science Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Identify the input science files and execute the calwebb_detector1 pipeline using the call method.\n\n# Run Stage 1 pipeline on the science using the custom det1dict dictionary.\nif dodet1:\n    # --------------------------Science UNCAL files--------------------------\n    for uncal_file in sorted(glob.glob(uncal_dir + '*uncal.fits')):\n        print(f\"Applying Stage 1 Corrections & Calibrations to: \"\n              f\"{os.path.basename(uncal_file)}\")\n\n        det1_result = Detector1Pipeline.call(uncal_file,\n                                             save_results=True,\n                                             steps=det1dict,\n                                             output_dir=det1_dir)\n    print(\"Stage 1 has been completed for SCI data! \\n\")\nelse:\n    print('Skipping Detector1 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-2-1-calibrating-science-files","position":27},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"5.2.2 Calibrating Background Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl4","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-2-2-calibrating-background-files","position":28},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"5.2.2 Calibrating Background Files","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Identify the input background files and execute the calwebb_detector1 pipeline using the call method.\n\n# Run Stage 1 pipeline on any background using the custom det1dict dictionary.\n\nif dodet1bg:\n    # ------------------------Background UNCAL files-------------------------\n    for uncal_file in sorted(glob.glob(uncal_bgdir + '*uncal.fits')):\n\n        print(f\"Applying Stage 1 Corrections & Calibrations to: \"\n              f\"{os.path.basename(uncal_file)}\")\n\n        det1bg_result = Detector1Pipeline.call(uncal_file,\n                                               save_results=True,\n                                               steps=det1dict,\n                                               output_dir=det1_bgdir)\n    print(\"Stage 1 has been completed for BKG data! \\n\")\nelse:\n    print('Skipping Detector1 processing for BKG data.')\n\n\n\n\n\n# Print out the time benchmark.\ntime2 = time.perf_counter()\nprint(f\"Runtime so far: {round((time2-time0)/60.0, 1):0.4f} min\")\nprint(f\"Runtime for Stage 1: {round((time2-time_det1)/60.0, 1):0.4f} min\")\n\n\n\n# Final list of RATE[INTS] files ready for Stage 2 processing.\nrate_sci = sorted(glob.glob(det1_dir + '*_rate.fits'))\nrateints_sci = sorted(glob.glob(det1_dir + '*_rateints.fits'))\nprint(f\"SCIENCE | RATE[INTS] Files:\\n{'-'*20}\\n\" + \"\\n\".join(rate_sci + rateints_sci))\n\nrate_bg = sorted(glob.glob(det1_bgdir + '*_rate.fits'))\nrateints_bg = sorted(glob.glob(det1_bgdir + '*_rateints.fits'))\nprint(f\"BACKGROUND | RATE[INTS] Files:\\n{'-' * 20}\\n\" + \"\\n\".join(rate_bg + rateints_bg))\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-5-2-2-calibrating-background-files","position":29},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-stage-2-spec2pipeline-calwebb-spec2","position":30},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"In this section, we process our countrate (slope) image products from Stage 1 (calwebb_detector1) through the Spec2 (calwebb_spec2) pipeline to create Stage 2 \n\ndata products.\n\nInput: A single countrate (slope) image (_rate[ints].fits) or an association file listing multiple inputs.\n\nOutput: Calibrated products (rectified and unrectified) and 1D spectra.\n\n_cal[ints].fits: Calibrated 2D (unrectified) spectra (ncols x nrows).\n\n_s3d.fits: Resampled 3D IFU cube (ncols x nrows x nwaves).\n\n_x1d[ints].fits: Extracted 1D spectroscopic data (wavelength vs. flux).\n\nIn Stage 2, each exposure (or association) and detector produces a single file, with multiple extensions corresponding to each source.\n\nThe Spec2Pipeline applies additional instrumental corrections and calibrations (e.g., slit loss, path loss, etc.,) to countrate products that result in a fully calibrated individual exposure (per nod/dither position). The Spec2Pipeline also converts countrate products from units of DN/s to flux (Jy) for point sources and surface brightness (MJy/sr) for extended sources.\n\nNote there has been a bug in the `cube_build` step that caused the point source flux to not be conserved when using different spatial sampling. A fix has been implemented as of release DMS build 9.3/CAL_VER 1.10.2. In order to enable the correct functionality, the units of the `_cal.fits` files and cubes will now be in surface brightness, and only the 1D extracted spectra will be in units of Jy.\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-stage-2-spec2pipeline-calwebb-spec2","position":31},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-1-configure-spec2pipeline","position":32},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"The Spec2Pipeline has the following steps available for NIRSpec IFU:\n\nassign_wcs: Assigns wavelength solution for spectra.\n\nbadpix_selfcal: Flags bad pixels in the input data using a self-calibration technique based on median filtering along the spectral axis.\n\nmsaflagopen: Flags pixels in NIRSpec exposures affected by MSA shutters stuck in the open position.\n\nnsclean: Cleans 1/f noise.\n\nimprint: Removes patterns caused by the MSA structure in NIRSpec MOS and IFU exposures.\n\nbkg_subtract: Performs image subtraction for background removal.\n\nsrctype: Determines whether a spectroscopic source should be classified as a point or extended object.\n\nflat_field: Applies flat-field corrections to the input science dataset.\n\npathloss: Calculates and applies corrections for signal loss in spectroscopic data.\n\nphotom: Applies photometric calibrations to convert data from countrate to surface brightness or flux density.\n\npixel_replace: Interpolates and estimates flux values for pixels flagged as DO_NOT_USE in 2D extracted spectra.\n\ncube_build: Produces 3D spectral cubes.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox •\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Spec2Pipeline should be configured for IFU data.\n\nIf pixel-to-pixel background subtraction was chosen above, it will be applied during this stage. To override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Spec2 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\nspec2dict = {}\nspec2dict['assign_wcs'], spec2dict['badpix_selfcal'] = {}, {}\nspec2dict['msa_flagging'], spec2dict['nsclean'] = {}, {}\nspec2dict['imprint_subtract'], spec2dict['bkg_subtract'] = {}, {}\nspec2dict['srctype'], spec2dict['wavecorr'] = {}, {}\nspec2dict['flat_field'], spec2dict['pathloss'] = {}, {}\nspec2dict['photom'], spec2dict['pixel_replace'] = {}, {}\nspec2dict['cube_build'], spec2dict['extract_1d'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n#spec2dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\nspec2dict['bkg_subtract']['skip'] = not pixel_bg\n#spec2dict['imprint_subtract']['skip'] = True  # Skip imprint subtraction?\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\n#spec2dict['pixel_replace']['skip'] = False\n#spec2dict['pixel_replace']['n_adjacent_cols'] = 5\n#spec2dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n# Run nsclean for 1/f noise.\n#spec2dict['nsclean']['skip'] = False\n#spec2dict['nsclean']['n_sigma'] = 2\n\n# Turn on bad pixel self-calibration, where all exposures on a given detector \n# are used to find and flag bad pixels that may have been missed by the bad pixel mask.\n# This step is experimental, and works best when dedicated background observations are included.\n#spec2dict['badpix_selfcal']['skip'] = False\n#spec2dict['badpix_selfcal']['flagfrac_upper'] = 0.005  # Fraction of pixels to flag.\n\n\n\nTo correct for 1/f noise with nsclean in Stage 2, see the IFU_NSClean_example demo notebook for IFU data \n\nhere.\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-1-configure-spec2pipeline","position":33},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline Association Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-2-create-spec2pipeline-association-files","position":34},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline Association Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Association (ASN) files define the relationships between multiple exposures, allowing them to get processed as a set rather than individually. Processing an ASN file enables the exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than as individual objects.\n\nStage 2 ASN files for IFU data can include science, background, imprint, and selfcal exposure types. A Stage 2 ASN file requires at least one science file but can contain multiple background, imprint (leakcals), and selfcal files that enable pixel-to-pixel background subtraction, imprint subtraction, and bad pixel self-calibration in calwebb_spec2.\n\nHere we construct the necessary association files based on the observing sequence.\n\nBackground subtraction may not be correctly applied if more than one science file is included in the association. Additionally, pixel-to-pixel background subtraction will only be performed if the grating wheel has not moved between the target and off-scene associated background exposures. If the grating wheel moved between the target and background exposures (as would be the case if they were in different visits), pipeline processing will follow a more involved “master background” subtraction done in Stage 3.\n\nDefine a function that associates background, imprint, and selfcal exposures for nodded observations.\n\ndef asn_nod(asn, onescifile, sci, sci_imprint, pattnum):\n    \"\"\"\n    Associate background, imprint, and selfcal exposures for nodded observations.\n\n    Parameters\n    ----------\n    asn : dict\n        The association dictionary to update.\n    onescifile : str \n        Path to the primary science file.\n    sci : list of str\n        List of science exposure file paths.\n    sci_imprint : list of str\n        List of science imprint exposure file paths.\n    pattnum : int\n        Dither position.\n\n    Returns\n    -------\n    asn : dict \n        Updated association dictionary with members for applicable background, imprint, and selfcal.\n    \"\"\"\n    members = asn['products'][0]['members']\n\n    # Assign background exposures.\n    for file in sci:\n        # If dither position is different from the input position, use it as a background.\n        if fits.getval(file, 'PATT_NUM') != pattnum:\n            members.append({'expname': file, 'exptype': 'background'})\n    \n    # Assign imprint exposures (pipeline handles figuring out which one is best).\n    for file in sci_imprint:\n        # Only IFU and MOS observations have imprint exposures.\n        if fits.getval(file, 'EXP_TYPE') == 'NRS_IFU' or 'NRS_MSASPEC':\n            if match_gwa(onescifile, file):\n                members.append({'expname': file, 'exptype': 'imprint'})\n\n    # Assign selfcal exposures (only applicable to IFU exposures).\n    for file in sci + sci_imprint:\n        members.append({'expname': file, 'exptype': 'selfcal'})\n\n    return asn\n\n\n\nDefine a function that associates background, imprint, and selfcal exposures for dithered observations.\n\ndef asn_dither(asn, onescifile, sci, sci_imprint, bg, bg_imprint):\n    \"\"\"\n    Associate background, imprint, and selfcal exposures for dithered observations.\n\n    Parameters\n    ----------\n    asn : dict\n        The association dictionary to update.\n    onescifile : str \n        Path to the primary science file.\n    sci : list of str\n        List of science exposure file paths.\n    sci_imprint : list of str\n        List of science imprint exposure file paths.\n    bg : list of str\n        List of background exposure file paths.\n    bg_imprint : list of str\n        List of background imprint exposure file paths.\n\n    Returns\n    -------\n    asn : dict \n        Updated association dictionary with members for applicable background, imprint, and selfcal.\n    \"\"\"\n    members = asn['products'][0]['members']\n\n    # Assign background exposures.\n    for file in bg:\n        members.append({'expname': file, 'exptype': 'background'})\n\n    # Assign imprint exposures (pipeline handles figuring out which one is best).\n    for file in sci_imprint:\n        # Only IFU and MOS observations have imprint exposures.\n        if fits.getval(file, 'EXP_TYPE') == 'NRS_IFU' or 'NRS_MSASPEC':\n            if match_gwa(onescifile, file):\n                members.append({'expname': file, 'exptype': 'imprint'})\n    for file in bg_imprint:\n        # Only IFU and MOS observations have imprint exposures.\n        if fits.getval(file, 'EXP_TYPE') == 'NRS_IFU' or 'NRS_MSASPEC':\n            if match_gwa(bg[0], file):\n                members.append({'expname': file, 'exptype': 'imprint'})\n\n    # Assign selfcal exposures.\n    for file in sci + sci_imprint + bg + bg_imprint:\n        members.append({'expname': file, 'exptype': 'selfcal'})\n\n    return asn\n\n\n\nDefine a function that creates a Level 2 ASN file.\n\ndef writel2asn(onescifile, allscifiles, bgfiles, asnfile, product_name, exp_type):\n    \"\"\"\n    Create a Level 2 association file for each science exposure.\n\n    Parameters\n    ----------\n    onescifile : str\n        Path to the primary science exposure file.\n    allscifiles : list of str\n        List of all science exposure files.\n    bgfiles : list of str\n        List of background exposure files.\n    asnfile : str\n        Path to write the output association file.\n    product_name : str\n        Name of the product for the association.\n    exp_type : str, optional\n        Exposure type to match against.\n\n    Returns\n    -------\n    True if the association was written successfully, and False otherwise \n    \"\"\"\n    # Define a basic association with the science file.\n    # Wrap in array since input was single exposure.\n    asn = afl.asn_from_list([onescifile], rule=DMSLevel2bBase, product_name=product_name)\n    asn.data['program'] = program if 'program' in globals() else \"9999\"\n\n    # Grab header information from the science file.\n    exp_type = fits.getval(onescifile, 'EXP_TYPE')\n    if (exp_type == exp_type):\n        detector = fits.getval(onescifile, 'DETECTOR')\n        grating = fits.getval(onescifile, 'GRATING')\n        filt = fits.getval(onescifile, 'FILTER')\n        patttype = fits.getval(onescifile, 'PATTTYPE')  # Dither pattern type.\n        pattnum = fits.getval(onescifile, 'PATT_NUM')  # Dither pattern number.\n        imprint = fits.getval(onescifile, 'IS_IMPRT')  # Imprint exposure?\n\n        # If this is an imprint exposure, fail out since those shouldn't be processed alone.\n        if imprint:\n            return False\n\n    # If the exposure type does not match, fail out \n    # to ensure TA images don't get processed by accident.\n    else:\n        return False\n\n    # Find all files matching the input configuration and split into regular/imprint.\n    use_sci, use_sci_imprint = get_matching(allscifiles, detector, filt, grating, exp_type)\n    use_bg, use_bg_imprint = get_matching(bgfiles, detector, filt, grating, exp_type) if bgfiles else ([], [])\n\n    # If this uses nodded exposures set up pixel-based background subtraction accordingly.\n    is_nod = 'NOD' in patttype.split('-')\n    if is_nod:\n        asn = asn_nod(asn, onescifile, use_sci, use_sci_imprint, pattnum)\n    else:  # Otherwise handle as dithered exposures\n        asn = asn_dither(asn, onescifile, use_sci, use_sci_imprint, use_bg, use_bg_imprint)\n\n    # Write the association to a json file.\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n \n    return True\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-2-create-spec2pipeline-association-files","position":35},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-3-run-spec2pipeline","position":36},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Run the science files and, if available, any background files through the calwebb_spec2 pipeline using the .call() method.\n\nPerform pixel-to-pixel background subtraction (if desired) here in Stage 2. Otherwise, reduce the backgrounds individually for master background subtraction in Stage 3 (if desired).\n\ntime_spec2 = time.perf_counter()  # Tracks runtime for Stage 2.\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-3-run-spec2pipeline","position":37},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"6.3.1 Calibrating Science Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl4","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-3-1-calibrating-science-files","position":38},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"6.3.1 Calibrating Science Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Identify the Stage 2 science files and execute the calwebb_spec2 pipeline using the call method.\n\n# To save on runtime, make a new version of our spec2 parameter dictionary\n# that turns off creation of quicklook 3d cubes/1d spectra for science data.\n# Any master background subtraction in spec3 will require the 1d spectra from spec2.\nspec2dict_sci = copy.deepcopy(spec2dict)\nspec2dict_sci['cube_build']['skip'] = True  # S2D products.\nspec2dict_sci['extract_1d']['skip'] = True  # X1D products.\n\n\n\n# Run Stage 2 pipeline using the custom spec2dict_sci dictionary.\n\nif dospec2:\n    # --------------------------Science files--------------------------\n    for file in rate_sci:\n        try:  # Create ASN files.\n            asnfile = os.path.join(asn_dir, os.path.basename(file).replace('rate.fits', 'l2asn.json'))\n            if writel2asn(file, rate_sci, rate_bg, asnfile, 'Level2', 'NRS_IFU'):\n                print(f\"Applying Stage 2 Corrections & Calibrations to: {file}\")\n                spec2sci_result = Spec2Pipeline.call(asnfile,\n                                                     save_results=True,\n                                                     steps=spec2dict_sci,\n                                                     output_dir=spec2_dir)\n        except Exception as e:\n            # A handle for when no slices fall on NRS2.\n            print(f\"Skipped processing {os.path.basename(asnfile)}: {e}\")\n    print(\"Stage 2 has been completed for SCI data! \\n\")\nelse:\n    print('Skipping Spec2 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-3-1-calibrating-science-files","position":39},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"6.3.2 Calibrating Background Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl4","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-3-2-calibrating-background-files","position":40},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl4":"6.3.2 Calibrating Background Files","lvl3":"6.3 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Prepare background files for master background subtraction in Stage 3. Will skip if no background files.\n\n# Run Stage 2 pipeline using the custom spec2dict dictionary.\n\nif dospec2bg and master_bg:\n    # ---------------------Background ASN or RATE files---------------------\n    for file in rate_bg:\n        try:\n            asnfile = os.path.join(asn_bgdir, os.path.basename(file).replace('rate.fits', 'l2asn.json'))\n            if writel2asn(file, rate_bg, '', asnfile, 'Level2', 'NRS_IFU'):\n                print(f\"Applying Stage 2 Corrections & Calibrations to: {os.path.basename(file)}\")\n                spec2bg_result = Spec2Pipeline.call(asnfile,\n                                                    save_results=True,\n                                                    steps=spec2dict,\n                                                    output_dir=spec2_bgdir)\n        except Exception as e:\n            # A handle for when no slices fall on NRS2.\n            print(f\"Skipped processing {os.path.basename(file)}: {e}\")\n    print(\"Stage 2 has been completed for BKG data! \\n\")\nelse:\n    print(\"Skipping Stage 2 for BKG data. \\n\")\n\n\n\n\n\n# Print out the time benchmarks.\ntime3 = time.perf_counter()\nprint(f\"Runtime so far: {round((time3-time0)/60.0, 1):0.4f} min\")\nprint(f\"Runtime for Spec2: {round((time3-time_spec2)/60.0, 1):0.4f} min\")\n\n\n\n# List the Stage 2 products.\n\n# -----------------------------Science files-----------------------------\nsci_cal = sorted(glob.glob(spec2_dir + '*_cal.fits'))\nsci_s3d = sorted(glob.glob(spec2_dir + '*_s3d.fits'))\nsci_x1d = sorted(glob.glob(spec2_dir + '*_x1d.fits'))\n\nprint(f\"SCIENCE | Stage 2 CAL Products:\\n{'-'*20}\\n\" + \"\\n\".join(sci_cal))\nprint(f\"SCIENCE | Stage 2 S3D Products:\\n{'-'*20}\\n\" + \"\\n\".join(sci_s3d))\nprint(f\"SCIENCE | Stage 2 X1D Products:\\n{'-'*20}\\n\" + \"\\n\".join(sci_x1d))\n\n# ----------------------------Background files---------------------------\nbg_cal = sorted(glob.glob(spec2_bgdir + '*_cal.fits'))\nbg_s3d = sorted(glob.glob(spec2_bgdir + '*_s3d.fits'))\nbg_x1d = sorted(glob.glob(spec2_bgdir + '*_x1d.fits'))\n\nprint(f\"BACKGROUND | Stage 2 CAL Products:\\n{'-'*20}\\n\" + \"\\n\".join(bg_cal))\nprint(f\"BACKGROUND | Stage 2 S3D Products:\\n{'-'*20}\\n\" + \"\\n\".join(bg_s3d))\nprint(f\"BACKGROUND | Stage 2 X1D Products:\\n{'-'*20}\\n\" + \"\\n\".join(bg_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-6-3-2-calibrating-background-files","position":41},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-stage-3-spec3pipeline-calwebb-spec3","position":42},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"In this section, we process our calibrated spectra from Stage 2 (calwebb_spec2) through the Spec3 (calwebb_spec3) pipeline to create Stage 3 \n\ndata products.\n\nInput: An ASN file that lists multiple calibrated exposures (_cal.fits) in addition to any background exposures (_x1d.fits).\n\nOutput: A single calibrated product (rectified and unrectified) and 1D spectrum. These data products have units of MJy/sr (or Jy for extracted point-source spectra).\n\n_cal.fits: Calibrated 2D (unrectified) spectra (ncols x nrows).\n\n_crf.fits: Calibrated 2D (unrectified) spectra whose DQ array has been updated to flag pixels detected as outliers (ncols x nrows).\n\n_s3d.fits: Resampled 3D IFU cube (ncols x nrows x nwaves).\n\n_x1d.fits: Extracted 1D spectroscopic data.\n\nIn Stage 3, single files are created for each source, one extension in the file.\n\nThe Spec3Pipeline performs additional corrections (e.g., outlier detection, background subtraction) and combines calibrated data from multiple exposures (e.g. a dither/nod pattern) into a single 3D spectral product, as well as a combined 1D spectrum.\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-stage-3-spec3pipeline-calwebb-spec3","position":43},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"7.1 Configure Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-1-configure-spec3pipeline","position":44},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"7.1 Configure Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"The Spec3Pipeline has the following steps available for NIRSpec IFU:\n\nassign_mtwcs: Modifies the WCS output frame in each exposure of a Moving Target (MT) observation association.\n\nmaster_background: Master background subtraction.\n\noutlier_detection : Identification of bad pixels or cosmic-rays that remain in each of the input images.\n\npixel_replace: Interpolates and estimates flux values for pixels flagged as DO_NOT_USE in 2D extracted spectra.\n\ncube_build: Produces 3D spectral cubes from 2D images.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox •\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Spec3Pipeline should be configured for IFU data.\n\nIf master background subtraction was chosen above, it will be applied during this stage. To override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Spec3 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\nspec3dict = {}\nspec3dict['assign_mtwcs'], spec3dict['master_background'] = {}, {}\nspec3dict['outlier_detection'], spec3dict['pixel_replace'] = {}, {}\nspec3dict['cube_build'], spec3dict['extract_1d'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n\n# Overrides for various reference files.\n# Files should be in the base local directory or provide full path.\n#spec3dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\n#spec3dict['outlier_detection']['skip'] = True\n\n# Master background usage was set up above, propagate that here.\nspec3dict['master_background']['skip'] = not master_bg\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels.\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\n#spec3dict['pixel_replace']['skip'] = False\n#spec3dict['pixel_replace']['n_adjacent_cols'] = 5\n#spec3dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n# Testing found this to be a better kernel size.\n# The kernel size must only contain odd values.\nspec3dict['outlier_detection']['kernel_size'] = '3 3'\n\n\n\nAs of DMS build B9.3rc1/CAL_VER 1.11.0, a new outlier detection algorithm for IFU data has been implemented. If using a pipeline version before this build, we recommend that outlier detection be skipped/turned off. To learn more about how the algorithm operates, refer to the documentation \n\nhere.\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-1-configure-spec3pipeline","position":45},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"7.2 Create Spec3Pipeline Association Files","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-2-create-spec3pipeline-association-files","position":46},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"7.2 Create Spec3Pipeline Association Files","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"Stage 3 ASN files for IFU data can include science and background exposure types. A Stage 3 ASN file requires at least one science file (there is usually more than one) but can contain multiple background files that enable master background subtraction in calwebb_spec3. Note that the science exposures should be in the _cal.fits format, while the background exposures must be in the _x1d.fits format.\n\nIn practice, Stage 3 ASN files can be downloaded directly from MAST, however, here we provide an example of manually creating Stage 3 ASN files. Below we create an ASN files for each GRATING/FILTER combination.\n\ndef writel3asn(scifiles, bgfiles):\n    \"\"\"\n    Create a Level 3 association file.\n\n    Parameters\n    ----------\n    scifiles : list of str\n        List of all science exposure files.\n    bgfiles : list of str\n        List of background exposure files.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n    # Filter based on GRATING/FILTER.\n    from collections import defaultdict\n    grouped = defaultdict(lambda: {'sci': [], 'bg': []})\n\n    for f in scifiles:\n        k = (fits.getval(f, 'FILTER'), fits.getval(f, 'GRATING'))\n        grouped[k]['sci'].append(f)\n    for f in bgfiles:\n        k = (fits.getval(f, 'FILTER'), fits.getval(f, 'GRATING'))\n        grouped[k]['bg'].append(f)\n\n    # Make ASN for each FILTER/GRATING.\n    for (filt, grat), files in grouped.items():\n        name = f\"{filt}_{grat}\".lower()\n        asnfile = os.path.join(asn_dir, f\"{name}_l3asn.json\")\n        asn = afl.asn_from_list(files['sci'], rule=DMS_Level3_Base, product_name=name)\n        for bg in files['bg']:\n            asn['products'][0]['members'].append({'expname': bg, 'exptype': 'background'})\n        with open(asnfile, 'w') as f:\n            f.write(asn.dump()[1])\n    print(\"Level 3 ASN creation complete!\")\n\n\n\nif dospec3:\n    writel3asn(sci_cal, bg_x1d)\n\n\n\n# Open an ASN file as an example.\n# Check that file paths have been correctly updated.\nif dospec3:\n    spec3_asn = glob.glob(asn_dir + '*l3asn.json')[0]\n    with open(spec3_asn, 'r') as f_obj:\n        asnfile_data = json.load(f_obj)\n    display(JSON(asnfile_data, expanded=True))\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-2-create-spec3pipeline-association-files","position":47},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"7.3 Run Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-3-run-spec3pipeline","position":48},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"7.3 Run Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"Run the science files and, if available, any background files through the calwebb_spec3 pipeline using the .call() method.\n\ntime_spec3 = time.perf_counter()\n\n\n\n# Run Stage 3 pipeline using the custom spec3dict dictionary.\n\nif dospec3:\n    print(f\"Applying Stage 3 Corrections & Calibrations to: \"f\"{os.path.basename(spec3_asn)}\")\n    spec3_result = Spec3Pipeline.call(spec3_asn,\n                                      save_results=True,\n                                      steps=spec3dict,\n                                      output_dir=spec3_dir)\n    print(\"Stage 3 has been completed! \\n\")\nelse:\n    print(\"Skipping Stage 3. \\n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmarks.\ntime4 = time.perf_counter()\nprint(f\"Runtime so far: {round((time4-time0)/60.0, 1):0.4f} min\")\nprint(f\"Runtime for Spec3: {round((time4-time_spec3)/60.0, 1):0.4f} min\")\n\n\n\n# List the Stage 3 products.\n\nstage3_cal = sorted(glob.glob(spec3_dir + '*_crf.fits'))\nstage3_s3d = sorted(glob.glob(spec3_dir + '*_s3d.fits'))\nstage3_x1d = sorted(glob.glob(spec3_dir + '*_x1d.fits'))\n\nprint(f\"Stage 3 CAL Products:\\n{'-'*20}\\n\" + \"\\n\".join(stage3_cal))\nprint(f\"Stage 3 S3D Products:\\n{'-'*20}\\n\" + \"\\n\".join(stage3_s3d))\nprint(f\"Stage 3 X1D Products:\\n{'-'*20}\\n\" + \"\\n\".join(stage3_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-7-3-run-spec3pipeline","position":49},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"8. Visualize the Data"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-8-visualize-the-data","position":50},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"8. Visualize the Data"},"content":"Define convenience funcitons for visualization. For some plots we utilize \n\njdaviz, a package of astronomical data analysis visualization tools designed to work in Jupyter notebooks.\n\nDefine a function to display Stage 1 products.\n\ndef display_rate(rates,\n                 slits_models=[],\n                 integration=0,\n                 extname='data',\n                 cmap='viridis',\n                 bad_color=(1, 0.7, 0.7),\n                 vmin=None,\n                 vmax=None,\n                 scale='asinh',\n                 aspect='auto',\n                 title_prefix=None,\n                 title_path=False,\n                 save_plot=False):\n    \"\"\"\n    Display countrate images.\n\n    Parameters\n    ----------\n    rates : list of str\n        A list of RATE[INTS] files to be displayed.\n    slits_models : list of str, optional\n        A list of CAL[INTS] or S2D files containing the slit models.\n        If provided, slit cutouts will be overlaid on the countrate images.\n    integration : {None, 'min', int}, optional\n        Specifies the integration to use for multi-integration data.\n        If 'min', the minimum value across all integrations is used.\n        If an integer, the specific integration index is used (default 0).\n    extname : str, optional\n        The name of the data extension to extract from ('data', 'dq', etc.).\n    cmap : str, optional\n        Colormap to use for displaying the image. Default is 'viridis'.\n    bad_color : tuple of float, optional\n        Color to use for NaN pixels. Default is light red (1, 0.7, 0.7).\n    vmin : float, optional\n        Minimum value for color scaling. If None, determined from the data.\n    vmax : float, optional\n        Maximum value for color scaling. If None, determined from the data.\n    scale : {'linear', 'log', 'asinh'}, optional\n        Scale to use for the image normalization. Default is 'asinh'.\n    aspect : str, optional\n        Aspect ratio of the plot. Default is 'auto'.\n    title_prefix : str, optional\n        Optional prefix for the plot title.\n    title_path : bool, optional\n        If True, uses the full file path for the title;\n        otherwise, uses the basename. Default is False.\n    save_plot : bool, optional\n        If True, saves the plot as a PNG file. Default is False.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n\n    # -------------------------------Check Inputs-------------------------------\n    rates = [rates] if isinstance(rates, str) else rates\n    slits_models = [slits_models] if isinstance(slits_models, str) else slits_models\n    nrates = len(rates)\n\n    # ------------------------------Set up figures------------------------------\n    fig, axes = plt.subplots(nrates, 1, figsize=(12, 12 * nrates),\n                             sharex=True, height_ratios=[1] * nrates)\n    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n    axes = [axes] if nrates == 1 else axes\n\n    cmap = plt.get_cmap(cmap)  # Set up colormap and bad pixel color.\n    cmap.set_bad(bad_color, 1.0)\n\n    # ---------------------------Plot countrate image---------------------------\n    for i, (rate, cal) in enumerate(itertools.zip_longest(rates,\n                                                          slits_models,\n                                                          fillvalue=None)):\n\n        # -------------------Open files as JWST datamodels-------------------\n        model = datamodels.open(rate)\n        slits_model = datamodels.open(cal) if cal else None\n\n        # -----------------------Extract the 2D/3D data----------------------\n        data_2d = getattr(model, extname)\n        if data_2d.ndim == 3:  # Handle multi-integration data.\n            if integration == 'min':\n                data_2d = np.nanmin(data_2d, axis=0)\n            elif isinstance(integration, int) and 0 <= integration < data_2d.shape[0]:\n                data_2d = data_2d[integration]\n            else:\n                raise ValueError(f\"Invalid integration '{integration}' for 3D data.\")\n\n        # ---------------------------Scale the data-------------------------\n        sigma_clipped_data = sigma_clip(data_2d, sigma=5, maxiters=3)\n        vmin = np.nanmin(sigma_clipped_data) if vmin is None else vmin\n        vmax = np.nanmax(sigma_clipped_data) if vmax is None else vmax\n        stretch_map = {'log': LogStretch(), 'linear': LinearStretch(),\n                       'asinh': AsinhStretch()}\n        if scale in stretch_map:\n            norm = ImageNormalize(sigma_clipped_data,\n                                  interval=ManualInterval(vmin=vmin, vmax=vmax),\n                                  stretch=stretch_map[scale])\n        else:\n            norm = simple_norm(sigma_clipped_data, vmin=vmin, vmax=vmax)\n\n        # ----------------Plot the countrate image & colorbar---------------\n        plt.subplots_adjust(left=0.05, right=0.85)\n        im = axes[i].imshow(data_2d, origin='lower', cmap=cmap,\n                            norm=norm, aspect=aspect, interpolation='nearest')\n        units = model.meta.bunit_data\n        cbar_ax = fig.add_axes([axes[i].get_position().x1 + 0.02,\n                                axes[i].get_position().y0, 0.02,\n                                axes[i].get_position().height])\n        cbar = fig.colorbar(im, cax=cbar_ax)\n        cbar.set_label(units, fontsize=12)\n\n        # -----------------Draw slits and label source ids------------------\n        # slits_model can be s2d/cal from spec2 - contains slit models for all sources.\n        if slits_model:\n            slit_patches = []\n            for slit in slits_model.slits:\n                slit_patch = Rectangle((slit.xstart, slit.ystart),\n                                       slit.xsize, slit.ysize)\n                slit_patches.append(slit_patch)\n                y = slit.ystart + slit.ysize / 2\n                x = slit.xstart if 'nrs1' in rate else slit.xstart + slit.xsize\n                ha = 'right' if 'nrs1' in rate else 'left'\n                plt.text(x, y, slit.source_id, color='w', ha=ha, va='center',\n                         fontsize=7, path_effects=[], weight='bold')\n            axes[i].add_collection(PatchCollection(slit_patches, ec='r', fc='None'))\n\n        # -----------------Construct title and axis labels------------------\n        filename = model.meta.filename\n        title = (f\"{title_prefix + ' ' if title_prefix else ''}\"\n                 f\"{filename if title_path else os.path.basename(filename)}\")\n        if integration is not None:\n            title = title.replace('rateints', f'rateints[{integration}]')\n        axes[i].set_title(title, fontsize=14)\n        axes[i].set_xlabel(\"Pixel Column\", fontsize=12)\n        axes[i].set_ylabel(\"Pixel Row\", fontsize=12)\n\n        # -------------------------Save the figure?-------------------------\n        if save_plot:\n            save_plot = rate.replace('fits', 'png')\n            if integration:\n                save_plot = save_plot.replace('.png', '%s.png' % integration)\n            fig.savefig(save_plot, dpi=200)\n\n        fig.show()\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-8-visualize-the-data","position":51},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-8-1-display-detector1pipeline-products","position":52},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Inspect the Stage 1 slope products.\n\nJdaviz Rampviz is a visualization and analysis toolbox for ramp cubes from infrared detectors and is currently under active development. Until it’s fully available, we can plot Stage 1 products using display_rate.\n\nif doviz:\n    rate_file = rate_sci[-1]  # Show the last rate file, as an example.\n    display_rate(rate_file, vmin=0, vmax=2, scale='asinh',\n                 aspect=1, title_prefix='REPROCESSED')  # , extname='dq')\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-8-1-display-detector1pipeline-products","position":53},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"8.2 Display Spec3Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-8-2-display-spec3pipeline-products","position":54},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl3":"8.2 Display Spec3Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Use Jdaviz \n\nCubeviz and \n\nSpecviz to visualize and analyze the Stage 3 combined calibrated spectra. For more information on these visualization tools and plotting capabilities, refer to the official documentation linked.\n\n# Plot the Stage 3 IFU cube with Cubeviz.\nif doviz:\n    cubeviz = Cubeviz()\n    cube = stage3_s3d[0]\n    cubeviz.load_data(cube, data_label='Level 3 IFU Product: 3D Cube')\n    cubeviz.show()\n\n\n\n# Plot the Stage 3 1D spectrum with Specviz.\nif doviz:\n    spec1d = Spectrum1D.read(stage3_x1d[0])\n    specviz = Specviz()\n    specviz.load_data(spec1d, data_label=\"Level 3 IFU Product: Extracted 1D Spectrum\")\n    specviz.show()\n\n\n\ntime5 = time.perf_counter()\nprint(f\"Runtime so far: {round((time5-time0)/60.0, 1):0.4f} min\")\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-8-2-display-spec3pipeline-products","position":55},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-9-modifying-the-extract1d-reference-file-as-needed","position":56},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"content":"The extract_1d step is controlled by a different set of parameters in the EXTRACT1D reference file for extended vs. point source IFU data.\n\nExtraction for 3D IFU Data:\n\nFor extended sources, rectangular aperture photometry is used, with the entire image extracted and no background subtraction, regardless of what is specified in the reference file or step arguments.\n\nFor point source data, the extraction aperture is centered at the RA/DEC target location indicated by the header. If the target location is undefined in the header, then the extraction region is the center of the IFU cube.\n\nFor point sources, a circular extraction aperture is used, along with an optional circular annulus for background extraction and subtraction. The size of the extraction region and the background annulus size varies with wavelength. The extraction-related vectors are found in the ASDF EXTRACT1D reference file. For each element in the wavelength vector, there are three size components: radius, inner_bkg, and outer_bkg. The radius vector sets the extraction size while inner_bkg and outer_bkg specify the limits of an annular background aperture.\n\nBelow is an example of how to modify the EXTRACT1D reference file for point sources. More information about this file and how to modify it in \n\nextract_1d and\n\n\nEditing JSON reference file.\n\nThe ifu_autocen parameter provides a new method to center on the point sources even if the header information is imperfect due to inaccuracies caused by, e.g., FGS.\n\nWarning: Currently, there is no aperture correction in place for NIRSpec, so the radius parameter MUST remain unchanged for point source to ensure proper flux calibration!\n\n# If you don't know the reference file name this should work.\n#extract_1d_ref = Spec3Pipeline().get_reference_file(stage3_s3d, 'extract1d')\n\nrefs = api.dump_references(crds_client.get_context_used('jwst'),\n                           ['jwst_nirspec_extract1d_0002.asdf'])\nextract_1d_ref = refs['jwst_nirspec_extract1d_0002.asdf']\n\n# Construct the modified file name\nbasename = os.path.basename(extract_1d_ref)[:-5]  # Remove \".asdf\"\nextract_1d_ref_mod = os.path.join(spec3_dir, f\"{basename}_demo.asdf\")\n\nprint('Original x1d reference file', extract_1d_ref)\nprint('Modified x1d reference file', extract_1d_ref_mod)\n\n# Open the original ASDF file, modify it, and save the modified version\n# in your current directory.\nwith asdf.open(extract_1d_ref, mode='r') as ref_file:\n    # Create a copy of the original tree\n    tree = ref_file.tree.copy()\n\n    # Modify the tree.\n    tree['data']['radius'] = np.full((2048,), 0.45, dtype='float32')\n    tree['data']['inner_bkg'] = np.full((2048,), 1.0, dtype='float32')\n    tree['data']['outer_bkg'] = np.full((2048,), 1.2, dtype='float32')\n\n    # Save the modified tree to a new file.\n    with asdf.AsdfFile(tree) as new_file:\n        new_file.write_to(extract_1d_ref_mod, all_array_storage='inline')\n\n\n\n# Check modified file contents.\nwith asdf.open(extract_1d_ref_mod) as ref_file:\n    # Pretty-print the ASDF tree structure.\n    pprint(ref_file.tree, depth=4)\n\n\n\nNow, we re-extract the 1D spectrum by running the Extract1dStep and overriding the reference file.\n\nfor s3d in stage3_s3d:\n    Extract1dStep.call(s3d,\n                       save_results=True,\n                       output_dir=spec3_dir,\n                       output_use_model=True,\n                       suffix='x1d_mod',  # Default suffix is `_extract1dstep.fits`\n                       use_source_posn=False,\n                       ifu_autocen=False,  # Set this to True for isolated point sources\n                       override_extract1d=extract_1d_ref_mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe now plot again the 3D/1D final cube/spectra and showing the original extraction box in red and the new extraction box in black.\n\nif doviz:\n    # Load necessary files\n    x1d_file = datamodels.open(stage3_x1d[0])\n    x1d_wave = x1d_file.spec[0].spec_table.WAVELENGTH\n    x1d_flux = x1d_file.spec[0].spec_table.FLUX\n\n    stage3_x1d_mod = sorted(glob.glob(spec3_dir + '*_x1d_mod.fits'))\n    x1d_mod = datamodels.open(stage3_x1d_mod[0])\n    x1d_wave_mod = x1d_mod.spec[0].spec_table.WAVELENGTH\n    x1d_flux_mod = x1d_mod.spec[0].spec_table.FLUX\n\n    cube_data = datamodels.open(cube).data\n\n    # Setup the figure\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(25, 9),\n                                   gridspec_kw={'width_ratios': [5, 3],\n                                                'wspace': 0.1})\n\n    # Plot the original and modified spectra\n    ax1.plot(x1d_wave, x1d_flux, linewidth=2, label=\"Original Extraction\")\n    ax1.plot(x1d_wave_mod, x1d_flux_mod, linewidth=2, label=\"Modified Extraction\")\n    ax1.set_xlabel('Wavelength (μm)', fontsize=15)\n    ax1.set_ylabel('Flux (Jy)', fontsize=15)\n    ax1.set_title(\"Level 3 IFU Product: Extracted 1D Spectrum\", fontsize=20)\n    ax1.set_ylim(np.nanpercentile(x1d_flux, 2), np.nanpercentile(x1d_flux, 98))\n    ax1.ticklabel_format(axis='y', style='sci', scilimits=(0, -2))\n    ax1.legend(fontsize=15)\n\n    # Plot the IFU cube slice\n    slice_mean = np.nanmean(cube_data[400:500, :, :], axis=0)\n    vmin = np.nanpercentile(slice_mean, 2)\n    vmax = np.nanpercentile(slice_mean, 98)\n    if vmin < -vmax:\n        vmin = -vmax\n    slice_full = ax2.imshow(slice_mean,\n                            norm=ImageNormalize(vmin=vmin, vmax=vmax, stretch=LinearStretch()),\n                            origin='lower', cmap='viridis')\n    plt.colorbar(slice_full, ax=ax2,\n                 fraction=0.046, pad=0.04).set_label('MJy/sr', fontsize=15)\n\n    # Annotate the extraction regions\n    with asdf.open(extract_1d_ref_mod, mode='r') as ref_file:\n        radii_data = ref_file.tree['data']\n        print(\"Radius [arcsec]:\", radii_data['radius'][0])\n        print(\"Inner background [arcsec]:\", radii_data['inner_bkg'][0])\n        print(\"Outer background [arcsec]:\", radii_data['outer_bkg'][0])\n\n        if x1d_mod.spec[0].source_type == 'POINT':\n            x_cen, y_cen = x1d_mod.spec[0].extraction_x, x1d_mod.spec[0].extraction_y\n            for label, radius, color in zip(['Radius', 'Inner Background Radius',\n                                            'Outer Background Radius'],\n                                            ['radius', 'inner_bkg', 'outer_bkg'],\n                                            ['black', 'blue', 'red']):\n                ax2.add_patch(Circle((x_cen, y_cen), radii_data[radius][0] * 10,\n                                     fill=False, color=color, label=label))\n\n        ax2.set_xlabel('X (pixels)', fontsize=15)\n        ax2.set_ylabel('Y (pixels)', fontsize=15)\n        ax2.set_title(\"Full IFU Cube: \\n Extraction Region Preview\", fontsize=20)\n        ax2.legend(fontsize=15)\n\n    plt.show()\n\n\n\n\n\nThe spectra will look identical if the source is extended.\n\ntime5 = time.perf_counter()\nprint(f\"Runtime so far: {round((time5-time0)/60.0, 1):0.4f} min\")\n\n\n\n","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#id-9-modifying-the-extract1d-reference-file-as-needed","position":57},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"Related Notebooks"},"type":"lvl2","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#related-notebooks","position":58},{"hierarchy":{"lvl1":"NIRSpec IFU Pipeline Notebook","lvl2":"Related Notebooks"},"content":"NIRSpec Workaround Notebooks\n\nJDAT: JWST Data Analysis Example Notebooks\n\n\n\nTop of Page","type":"content","url":"/notebooks/nirspec/ifu/jwpipenb-nirspec-ifu#related-notebooks","position":59},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos","position":0},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook"},"content":"\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos","position":1},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook"},"type":"lvl1","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#nirspec-mos-pipeline-notebook","position":2},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook"},"content":"\n\nAuthors: Dan Coe (\n\ndcoe@stsci.edu), Kayli Glidic (\n\nkglidic@stsci.edu), NIRSpec branch, with contributions from the NIRSpec team, including Elena Manjavacas, Peter Zeidler, Melanie Clarke, James Muzerolle, Nikolay Nikolov, Chris Hayes, and Alaina Henry, who designed the ERO NIRSpec observations.\nLast Updated: July 16, 2025 \nPipeline Version: 1.19.1 (Build 12.0, Context jwst_1413.pmap)\n\nPurpose:\nEnd-to-end calibration with the James Webb Space Telescope (JWST) pipeline is divided into three main processing stages. This notebook provides a framework for processing generic Near-Infrared Spectrograph (NIRSpec) multi-object spectroscopy (MOS) data through \n\nstages 1-3 of the JWST pipeline, including how to use associations for multi-exposure observations and how to interact and work with JWST datamodels. In most cases, editing cells outside the \n\nConfiguration section is unnecessary unless the standard pipeline processing options or plot parameters need to be modified.\n\nData:\nThis notebook is set up to use observations of galaxy cluster SMACS0723 with the G395M grism obtained by Proposal ID (PID) 2736, Observation 7. The demo data will automatically download unless disabled (i.e., to use local files instead).\n\nJWST pipeline version and CRDS context:\nThis notebook was written for the above-specified pipeline version and associated build context for this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS \n\nserver). If you use different pipeline versions, please refer to the table \n\nhere to determine what context to use. To learn more about the differences for the pipeline, read the relevant \n\ndocumentation.\n\nPlease note that pipeline software development is a continuous process, so results in some cases may be slightly different if a subsequent version is used. For optimal results, users are strongly encouraged to reprocess their data using the most recent pipeline version and \n\nassociated CRDS context, taking advantage of bug fixes and algorithm improvements.\nAny \n\nknown issues for this build are noted in the notebook.\n\nUpdates:\nThis notebook is regularly updated to incorporate the latest pipeline improvements. Find the most up-to-date version of this notebook \n\nhere.\n\nRecent Changes:\n\nOctober 15, 2024: Converted notebook to follow standard template (\n\noriginal). \n\nNovember 4, 2024: Notebook updated to JWST pipeline version 1.16.0 (Build 11.1).\n\nJanuary 12, 2024: Added an example for association file creation.\n\nFebruary 19, 2025: Updated JWST pipeline version 1.17.1 (Build 11.2). Changed code to create all associations instead of using the MAST downloads.\n\nApril 16, 2025: Updated JWST pipeline version 1.18.0 (Build 11.3) and added Jdaviz plotting options.\n\nJuly 16, 2025: Updated to JWST pipeline version 1.19.1 (no significant changes)\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#nirspec-mos-pipeline-notebook","position":3},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"Table of Contents"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#table-of-contents","position":4},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"Table of Contents"},"content":"1. Configuration\n\n2. Package Imports\n\n3. Demo Mode Setup\n\n4. Directory Setup\n\n5. Stage 1: Detector1Pipeline (calwebb_detector1)\n\n5.1 Configure Detector1Pipeline\n\n5.2 Run Detector1Pipeline\n\n6. Stage 2: Spec2Pipeline (calwebb_spec2)\n\n6.1 Configure Spec2Pipeline\n\n6.2 Create Spec2Pipeline Association Files\n\n6.3 MSA Metadata File\n\n6.4 Run Spec2Pipeline\n\n7. Stage 3: Spec3Pipeline (calwebb_spec3)\n\n7.1 Configure Spec3Pipeline\n\n7.2 Create Spec3Pipeline Association Files\n\n7.3 Run Spec3Pipeline\n\n8. Visualize the Data\n\n8.1 Display Detector1Pipeline Products\n\n8.2 Display Spec2Pipeline Products\n\n8.3 Display Spec3Pipeline Products\n\n9. Modifying the EXTRACT1D Reference File (as needed)\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#table-of-contents","position":5},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"1. Configuration"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-1-configuration","position":6},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"1. Configuration"},"content":"","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-1-configuration","position":7},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"type":"lvl4","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#install-dependencies-and-parameters","position":8},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl4":"Install dependencies and parameters","lvl2":"1. Configuration"},"content":"To make sure that the pipeline version is compatible with the steps discussed below and that the required dependencies and packages get installed, you can create a fresh conda environment and install the provided requirements.txt file before starting this notebook:conda create -n nirspec_mos_pipeline python=3.12\nconda activate nirspec_mos_pipeline\npip install -r requirements.txt","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#install-dependencies-and-parameters","position":9},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl4":"Set the basic parameters to configure the notebook","lvl2":"1. Configuration"},"type":"lvl4","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#set-the-basic-parameters-to-configure-the-notebook","position":10},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl4":"Set the basic parameters to configure the notebook","lvl2":"1. Configuration"},"content":"These parameters determine what data gets used, where data is located (if already on disk), and the type of background subtraction (if any). The list of parameters includes:\n\ndemo_mode:\n\nTrue: Downloads example data from the \n\nBarbara A. Mikulski Archive for Space Telescopes (MAST) and processes it through the pipeline. All processing will occur in a local directory unless modified in \n\nSection 3 below.\n\nFalse: Process your own downloaded data; provide its location.\n\nDirectories with data:\n\nsci_dir: Directory where science observation data is stored.\n\nBackgroud subtraction methods (True = run, False = skip):\n\nmaster_bg: Apply master-background subtraction in calwebb_spec2? Uses “blank sky” shutters defined in the observation.\n\npixel_bg : Apply pixel-to-pixel background subtraction in calwebb_spec2.  This is the default pipeline setting. Uses nodded observations.\n\n# Basic import necessary for configuration.\n# Uncomment logging to hide log information.\n\nimport os\nimport warnings\n#import logging\n\n# Control logging level: INFO, WARNING, ERROR\n# Run command logging.disable if want to hide logging\n# ERROR messages.\n#logging.disable(logging.ERROR)\nwarnings.simplefilter(\"ignore\", RuntimeWarning)\n\n\n\nNote that demo_mode must be set appropriately below.\n\n# Set parameters for demo_mode, data mode directories, and processing steps.\n\n# -------------------------------DEMO MODE-----------------------------------\ndemo_mode = True\n\nif demo_mode:\n    print('Running in demonstration mode using online example data!')\n\n# --------------------------User Mode Directories----------------------------\nelse:  # If demo_mode = False, look for user data in these paths.\n\n    # Set directory paths for processing specific data; adjust to your local\n    # directory setup (examples provided below).\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n\n    # Directory to science observation data; expects uncalibrated data in\n    # sci_dir/uncal/ and results in stage1, stage2, and stage3 directories.\n    sci_dir = os.path.join(basedir, 'mos_data_02736/Obs007', '')\n\n# --------------------------Set Processing Steps-----------------------------\n# Individual pipeline stages can be turned on/off here. Note that a later\n# stage won't be able to run unless data products have already been\n# produced from the prior stage.\n\n# Science processing.\ndodet1 = True  # calwebb_detector1\ndospec2 = True  # calwebb_spec2\ndospec3 = True  # calwebb_spec3\ndoviz = True  # Visualize calwebb outputs\n\n# ---------------------------Set Processing Steps----------------------------\n# How should background subtraction be done?\n# If none are selected, data will not be background subtracted.\n# pixel_bg - True for nodded observations.\n# master_bg - True if using \"blank sky\" sutters in the science observation.\nmaster_bg = False  # Master-background subtraction in spec2.\npixel_bg = True  # Pixel-based background subtraction in spec2.\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#set-the-basic-parameters-to-configure-the-notebook","position":11},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#set-crds-context-and-server","position":12},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"Set CRDS Context and Server","lvl2":"1. Configuration"},"content":"Before importing CRDS and JWST modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline. If the local CRDS cache directory has not been set, it will automatically be created in the home directory.\n\n\nBuild Context Table\n\n# ------------------------Set CRDS context and paths------------------------\n\n# Each version of the calibration pipeline is associated with a specific CRDS\n# context file. The pipeline will select the appropriate context file behind\n# the scenes while running. However, if you wish to override the default context\n# file and run the pipeline with a different context, you can set that using\n# the CRDS_CONTEXT environment variable. Here we show how this is done,\n# although we leave the line commented out in order to use the default context.\n# If you wish to specify a different context, uncomment the line below.\n#os.environ['CRDS_CONTEXT'] = 'jwst_1364.pmap'  # CRDS context for 1.18.0\n\n# Set CRDS cache directory to user home if not already set.\nif os.getenv('CRDS_PATH') is None:\n    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds_cache')\n\n# Check whether the CRDS server URL has been set. If not, set it.\nif os.getenv('CRDS_SERVER_URL') is None:\n    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n\n# Output the current CRDS path and server URL in use.\nprint('CRDS local filepath:', os.environ['CRDS_PATH'])\nprint('CRDS file server:', os.environ['CRDS_SERVER_URL'])\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#set-crds-context-and-server","position":13},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"2. Package Imports"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-2-package-imports","position":14},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"2. Package Imports"},"content":"\n\n# Use the entire available screen width for this notebook.\nfrom IPython.display import display, HTML, JSON\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))\n\n\n\n# ----------------------General Imports----------------------\nimport time\nimport glob\nimport json\nimport itertools\nimport numpy as np\n\n# ----------------------Astropy Imports----------------------\n# Astropy utilities for opening FITS files, downloading demo files, etc.\nfrom astropy.io import fits\nfrom astropy.stats import sigma_clip\nfrom astropy.visualization import ImageNormalize, ManualInterval, LogStretch\nfrom astropy.visualization import LinearStretch, AsinhStretch, simple_norm\n\n# -------------------- Astroquery Imports ----------------------\nfrom astroquery.mast import Observations\n\n# ----------------------Plotting Imports---------------------\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.collections import PatchCollection\nfrom jdaviz import Mosviz\n\n\n\nInstallation instructions for the JWST pipeline found here: \n\nJDox • \n\nReadtheDocs • \n\nGithub\n\n# ----------------------JWST Calibration Pipeline Imports----------------------\nimport jwst  # Import the base JWST and CRDS packages.\nimport crds\nfrom crds.client import api\nfrom stpipe import crds_client\n\n# JWST pipelines (each encompassing many steps).\nfrom jwst.pipeline import Detector1Pipeline  # calwebb_detector1\nfrom jwst.pipeline import Spec2Pipeline  # calwebb_spec2\nfrom jwst.pipeline import Spec3Pipeline  # calwebb_spec3\nfrom jwst.extract_1d import Extract1dStep  # Extract1D Step\n\n# JWST pipeline utilities\nfrom jwst import datamodels  # JWST pipeline utilities: datamodels.\nfrom jwst.associations import asn_from_list as afl  # Tools for creating association files.\nfrom jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Define Lvl2 ASN.\nfrom jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Define Lvl3 ASN.\n\ndefault_context = crds.get_default_context('jwst', state='build')\nprint(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\nprint(f\"Default CRDS Context for JWST Version {jwst.__version__}: {default_context}\")\nprint(f\"Using CRDS Context: {os.environ.get('CRDS_CONTEXT', default_context)}\")\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-2-package-imports","position":15},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"Define Convience Functions","lvl2":"2. Package Imports"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#define-convience-functions","position":16},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"Define Convience Functions","lvl2":"2. Package Imports"},"content":"Define a function that identifies unique MSA files.\n\n# Find unique files to download.\ndef unique_files_to_array(files):\n    \"\"\"\n    Checks for unique files and adds them to an array.\n\n    Parameters\n    ----------\n    files : list of lists\n        The input files.\n\n    Returns\n    -------\n    list : An array of unique files.\n    \"\"\"\n\n    unique_files = set()\n    for row in files:\n        for element in row:\n            if isinstance(element, str):\n                unique_files.add(element)\n\n    return list(unique_files)\n\n\n\nDefine a function that filters files based on detector, filter, and grating.\n\ndef get_matching(files, detector, filt, grating, exp_type):\n    \"\"\"\n    Filters a list of FITS files to find those with matching \n    detector, filter, and grating for a specified exposure type.\n\n    Parameters\n    ----------\n    files : list of str\n        Paths to FITS files to check.\n    detector : str\n        Expected value of the DETECTOR keyword.\n    filt : str\n        Expected value of the FILTER keyword.\n    grating : str\n        Expected value of the GRATING keyword.\n    exp_type : str, optional\n        The exposure type to match.\n\n    Returns\n    -------\n    files_regular : list of str\n        Files with matching configuration and IS_IMPRT == False or missing.\n    files_imprint : list of str)\n        Files with matching configuration and IS_IMPRT == True.\n    \"\"\"\n    files_regular, files_imprint = [], []\n    for file in files:\n        # Skip if EXP_TYPE doesn't match the provided one.\n        if fits.getval(file, 'EXP_TYPE') != exp_type:\n            files_regular.append(file)\n            continue\n        # Check if DETECTOR, FILTER, and GRATING match\n        if (fits.getval(file, 'DETECTOR') == detector and fits.getval(file, 'FILTER') == filt and fits.getval(file, 'GRATING') == grating):\n            try:\n                is_imprt = fits.getval(file, 'IS_IMPRT') # Only IFU and MOS observations have imprint exposures.\n            except KeyError:\n                is_imprt = None\n            (files_imprint if is_imprt else files_regular).append(file)\n    return files_regular, files_imprint\n\n\n\n# Start a timer to keep track of runtime.\ntime0 = time.perf_counter()\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#define-convience-functions","position":17},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":18},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"The data in this notebook is public and does not require a token. For other data sets, you may need to provide a token. For more infomation visit the \n\nastroquery documentation.\n\nIf running in demonstration mode, set up the program information to retrieve the uncalibrated data (_uncal.fits) automatically from MAST using astroquery. MAST provides flexibility by allowing searches based on proposal ID and observation ID, rather than relying solely on filenames. More information about the JWST file naming conventions can be found \n\nhere.\n\nThe MOS demo data in this notebook is from \n\n“JWST’s First Deep Field”, \n\nJWST Early Release Observation (ERO) program 2736 and features observations of galaxy cluster SMACS0723 with NIRCam, NIRSpec, and MIRI. This program includes two identical MOS observations (7 and 8) with confirmation images taken after target acquisition (20 groups | NRSIRS2RAPID | 306 [s]). More of the program setup is briefly summarized in the table below.\n\nDemo Target: SMACS0723\n\n\n\n\n\nPROGRAM\n\n02736\n\nProgram number\n\nOBSERVTN\n\n007\n\nObservation number\n\nGRATING/FILTER\n\nG395M/F290LP\n\nλ: 2.87–5.10 μm (a medium resolution, R ~ 1000)\n\n\n\nG235M/F170LP\n\nλ: 1.66–3.07 μm (a medium resolution, R ~ 1000)\n\nSUBARRAY\n\nFULL\n\nSubarray used (2048 x 2048)\n\nNINTS\n\n2\n\nNumber of integrations in exposure\n\nNGROUPS\n\n20\n\nNumber of groups in integration\n\nREADPATT\n\nNRSIRS2\n\nReadout pattern\n\nNOD_TYPE\n\n3-SHUTTER-SLITLET\n\nNod pattern type\n\nNUMDTHPT\n\n3\n\nTotal number of points in pattern\n\nSRCTYAPT\n\nUNKNOWN\n\nSource type selected in APT\n\nTOTAL DURATION\n\nNOD_TYPE x NINTS x NGROUPS = 8841 [s] (~2.5 hrs)\n\nTotal duration (per grating and observation)\n\nNote: The presence of a physical gap between detectors affects all MOS observations (any resolution) because the spectra can be long enough to span both NIRSpec detectors. \n\nMore Info ...\n\n# Set up the program information and directories to collect\n# the data in demo_mode.\n\nif demo_mode:\n\n    print('Running in demonstration mode. '\n          'Example data will be downloaded from MAST!')\n\n    # NOTE:\n    # For non public data sets, you may need to provide a token.\n    # However, for security it is not recommended to enter tokens into\n    # a terminal or Jupyter notebook.\n    #Observations.login(token=\"your-token\")\n\n    # --------------Program and observation information--------------\n    program = \"02736\"\n    sci_observtn = \"007\"\n    filters = [\"F290LP;G395M\"]\n\n    # ----------Define the base and observation directories----------\n    basedir = os.path.abspath(os.path.join(os.getcwd(), ''))\n    sci_dir = os.path.join(basedir, f'mos_data_{program}')\n    sci_dir = os.path.join(sci_dir, f'Obs{sci_observtn}')\n    uncal_dir = os.path.join(sci_dir, 'uncal/')\n    asn_dir = os.path.join(sci_dir, 'asn/') # Keep MSA files in the association directory.\n\n    # ----Ensure directories for downloading MAST data exists--------\n    os.makedirs(uncal_dir, exist_ok=True)\n    os.makedirs(asn_dir, exist_ok=True)\n\n\n\nClick on the following links to learn more about querying and downloading data:\n• \n\nDownloading data\n• \n\nObservations Class\n• \n\nProducts Field Descriptions\n\nCompile a table of files from MAST associated with the science (SCI) observation.\n\n# Obtain a list of observation IDs for the specified demo program.\n\nif demo_mode:\n    # --------------------SCIENCE Observation--------------------\n    sci_obs_id_table = Observations.query_criteria(instrument_name=['NIRSPEC/MSA'],\n                                                   provenance_name=[\"CALJWST\"],\n                                                   obs_id=[f'*{program}*{sci_observtn}*'])\n\n\n\nFilter these tables to identify uncalibrated and metadata files to download from MAST.\n\nThe demo dataset consists of six _uncal.fits files, each approximately 500 MB in size.\n\n# Convert visits into a list of uncalibrated data and ASN files.\n\nif demo_mode:\n\n    file_criteria = {'filters': filters, 'calib_level': [1],\n                     'productSubGroupDescription': 'UNCAL'}\n\n    # Initialize lists for science and metadata files.\n    sci_downloads, msa_downloads = [], []\n\n    pfilter = Observations.filter_products  # Alias for filter_products method.\n\n    # ----Identify uncalibrated SCIENCE files associated with each visit-----\n    for exposure in sci_obs_id_table:\n        sci_products = Observations.get_product_list(exposure)\n\n        # Filter for full-size science files (exclude smaller confirmation images).\n        avg_sci_size = np.nanmean(sci_products['size'])\n        sci_products_avg = sci_products[sci_products['size'] > avg_sci_size]\n        sci_downloads.extend(pfilter(sci_products_avg, **file_criteria)['dataURI'])\n\n        # Identifies association metadata files.\n        msa_files = {\n            f['productFilename'] for f in sci_products\n            if 'AUXILIARY' in f['productType'] and 'metadata' in f['description']}\n        msa_downloads.append(msa_files)\n\n    # Filter out other observations and remove duplicates.\n    msa_downloads = unique_files_to_array(msa_downloads)\n    sci_downloads = {f for f in sci_downloads if f\"jw{program}{sci_observtn}\" in f}\n\n    msa_mast_downloads = [\n        f\"mast:JWST/product/{f}\" for f in msa_downloads\n        if f\"jw{program}{sci_observtn}\" in f\n    ]\n\n    print(f\"Science files selected for downloading: {len(sci_downloads)}\")\n    print(f\"MSA files selected for downloading: {len(msa_mast_downloads)}\")\n\n\n\nDownload the data.\n\nWarning: If this notebook is halted during this step, the downloaded file may be incomplete, and cause crashes later on!\n\n# Download data and place them into the appropriate directories.\n\nif demo_mode:\n    for file in sci_downloads:\n        sci_manifest = Observations.download_file(file, local_path=uncal_dir)\n    for file in msa_mast_downloads:\n        msa_manifest = Observations.download_file(file, local_path=asn_dir)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-3-demo-mode-setup-ignore-if-not-using-demo-data","position":19},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"Galaxies of Interest","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#galaxies-of-interest","position":20},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"Galaxies of Interest","lvl2":"3. Demo Mode Setup (ignore if not using demo data)"},"content":"There are several galaxies of interest in the demo data. Here we will look at some of them (source_ids provided below).\n\n6355: z = 7.665 (13.0 Gyr ago)\n\nWe’ll look at this galaxy in this notebook.\n\nExcellent spectrum with bright lines.\n\n5-shutter slitlet (rather than standard 3-shutter slitlet), so 1D extraction can be improved significantly.\n\nNot a multiple image of 10612 (described below), which has a similar redshift.\n\n5144: z = 6.383 (12.8 Gyr ago)\n\nThe following galaxies have been featured in the \n\npress release:\n\n4590: z = 8.498 (13.1 Gyr ago)\n\n10612: z = 7.663 (13.0 Gyr ago)\n\n8140: z = 5.275 (12.6 Gyr ago)\n\n9922: z = 2.743 (11.3 Gyr ago)\n\nand presented and studied in papers including\n\n\nKatz et al. 2023,\n\n\nCurti et al. 2023,\n\n\nCarnall et al. 2023.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#galaxies-of-interest","position":21},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"4. Directory Setup"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-4-directory-setup","position":22},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"4. Directory Setup"},"content":"Set up detailed paths to input/output stages here.\n\n# Define/create output subdirectories to keep data products organized.\n\n# -----------------------------Science Directories------------------------------\nuncal_dir = os.path.join(sci_dir, 'uncal/')  # Uncalibrated pipeline inputs.\ndet1_dir = os.path.join(sci_dir, 'stage1/')  # calwebb_detector1 pipeline outputs.\nspec2_dir = os.path.join(sci_dir, 'stage2/')  # calwebb_spec2 pipeline outputs.\nspec3_dir = os.path.join(sci_dir, 'stage3/')  # calwebb_spec3 pipeline outputs.\nasn_dir = os.path.join(sci_dir, 'asn/')  # Associations directory.\n\n# Creates the directories if target directory does not exist.\nos.makedirs(det1_dir, exist_ok=True)\nos.makedirs(spec2_dir, exist_ok=True)\nos.makedirs(spec3_dir, exist_ok=True)\nos.makedirs(asn_dir, exist_ok=True)\n\n\n\n# Print out the time benchmark.\ntime1 = time.perf_counter()\nprint(f\"Runtime so far: {round((time1 - time0) / 60.0, 1):0.4f} min\")\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-4-directory-setup","position":23},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-5-stage-1-detector1pipeline-calwebb-detector1","position":24},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"In this section, we process the data through the calwebb_detector1 pipeline to create Stage 1 \n\ndata products.\n\nInput: Raw exposure (_uncal.fits) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n\nOutput: Uncalibrated countrate (slope) image in units of DN/s:\n\n_rate.fits: A single countrate image averaged over multiple integrations (if available).\n\n_rateints.fits: Countrate images for each integration, saved in multiple extensions.\n\nThe Detector1Pipeline applies basic detector-level corrections on a group-by-group basis, followed by ramp fitting for all exposure types, commonly referred to as “ramps-to-slopes” processing.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-5-stage-1-detector1pipeline-calwebb-detector1","position":25},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-5-1-configure-detector1pipeline","position":26},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"5.1 Configure Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"The Detector1Pipeline has the following steps available for NIRSpec MOS:\n\ngroup_scale : Rescales pixel values to correct for improper onboard frame averaging.\n\ndq_init : Initializes the data quality (DQ) flags for the input data.\n\nsaturation : Flags pixels at or below the A/D floor or above the saturation threshold.\n\nsuperbias : Subtracts the superbias reference file from the input data.\n\nrefpix : Use reference pixels to correct bias drifts.\n\nlinearity : Applies a correction for non-linear detector response.\n\ndark_current : Subtracts the dark current reference file from the input data.\n\njump : Performs CR/jump detection on each ramp integration within an exposure.\n\nclean_flicker_noise: Removes flicker (1/f) noise from calibrated ramp images (similar to nsclean in spec2).\n\nramp_fit : Determines the mean count rate (counts per second) for each pixel by performing a linear fit to the input data.\n\ngain_scale : Corrects pixel values for non-standard gain settings, primarily in NIRSpec subarray data.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox and\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Detector1Pipeline should be configured for MOS data. We follow the \n\nCEERS NIRSpec reduction parameters to improve the rejection of cosmic rays and snowballs during the jump step.\n\nTo override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Detector1 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\ndet1dict = {}\ndet1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\ndet1dict['superbias'], det1dict['refpix'] = {}, {}\ndet1dict['linearity'], det1dict['dark_current'], det1dict['jump'] = {}, {}, {}\ndet1dict['clean_flicker_noise'], det1dict['ramp_fit'] = {}, {}\ndet1dict['gain_scale'] = {}\n\n# ---------------------------Override reference files---------------------------\n\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n#det1dict['dq_init']['override_mask'] = 'myfile.fits'  # Bad pixel mask\n#det1dict['superbias']['override_superbias'] = 'myfile.fits'  # Bias subtraction\n#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\ndet1dict['linearity']['skip'] = False  # This is the default.\n\n# Turn on multi-core processing (off by default).\n# Choose what fraction of cores to use (quarter, half, or all).\ndet1dict['jump']['maximum_cores'] = 'half'\n#det1dict['ramp_fit']['maximum_cores'] = 'half'\n\n\n\n# Turn on detection of cosmic ray snowballs (on by default)\n# and change some parameters.\ndet1dict['jump']['expand_large_events'] = True\ndet1dict['jump']['expand_factor'] = 3  # (default 2)\ndet1dict['jump']['min_sat_area'] = 15  # (default 1)\ndet1dict['jump']['min_jump_area'] = 15  # (default 5)\n\n\n\nMany exposures are affected by artifacts known as \n\nsnowballs caused by large cosmic ray events. These artifacts are particularly significant in deep exposures with long integration times, with an estimated rate of one snowball per detector (FULL FRAME) per 20 seconds. To expand the number of pixels flagged as jumps around large cosmic ray events, set expand_large_events to True. An expand_factor of 3 works well for NIRSpec observations to cover most snowballs.\n\n# Turn on 1/f noise correction in Stage 1? (off by default).\n#det1dict['clean_flicker_noise']['skip'] = False\n\n\n\nJWST detector readout electronics (a.k.a. SIDECAR ASICs) generate significant 1/f noise during detector operations and signal digitization. This noise manifests as faint banding along the detector’s slow axis and varies from column to column. For NIRSpec data, the primary pipeline algorithm to address 1/f noise is nsclean in the Spec2Pipeline (Rauscher 2023) but is off by default.\n\nAn additional 1/f noise-cleaning algorithm, clean_flicker_noise, has been implemented at the group stage in the Detector1Pipeline. This step is also off by default.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-5-1-configure-detector1pipeline","position":27},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-5-2-run-detector1pipeline","position":28},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"5.2 Run Detector1Pipeline","lvl2":"5. Stage 1: Detector1Pipeline (calwebb_detector1)"},"content":"Run the science files through the calwebb_detector1 pipeline using the .call() method.\n\nWe use .call() instead of .run() to ensure that the latest default parameters set via reference files in CRDS are applied (\n\nReadtheDocs).\n\nThis stage takes approximately 25 minutes to process six _uncal.fits files (~4 minutes per file) and generate _rate.fits files.\n\n# Final list of UNCAL files ready for Stage 1 processing.\nuncal_sci = sorted(glob.glob(uncal_dir + '*uncal.fits'))\nprint(f\"Science UNCAL Files:\\n{'-' * 20}\\n\" + \"\\n\".join(uncal_sci))\n\n\n\ntime_det1 = time.perf_counter()  # Tracks runtime for Stage 1.\n\n\n\n# Run Stage 1 pipeline using the custom det1dict dictionary.\n\nif dodet1:\n    # --------------------------Science UNCAL files--------------------------\n    for uncal_file in uncal_sci:\n        print(f\"Applying Stage 1 Corrections & Calibrations to: \"\n              f\"{os.path.basename(uncal_file)}\")\n\n        det1_result = Detector1Pipeline.call(uncal_file,\n                                             save_results=True,\n                                             steps=det1dict,\n                                             output_dir=det1_dir)\n    print(\"Stage 1 has been completed! \\n\")\nelse:\n    print('Skipping Detector1 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print output result details:\n#det1_result.__dict__  # View entire contents.\n#det1_result.meta.filename\n#det1_result.data.shape\n\n\n\n# Print out the time benchmark.\ntime2 = time.perf_counter()\nprint(f\"Runtime so far: {round((time2 - time0) / 60.0, 1):0.4f} min\")\nprint(f\"Runtime for Stage 1: {round((time2 - time_det1) / 60.0, 1):0.4f} min\")\n\n\n\n# Final list of RATE[INTS] files ready for Stage 2 processing.\nrate_sci = sorted(glob.glob(det1_dir + '*_rate.fits'))\nrateints_sci = sorted(glob.glob(det1_dir + '*_rateints.fits'))\nprint(f\"SCIENCE | RATE[INTS] Files:\\n{'-'*20}\\n\" + \"\\n\".join(rate_sci + rateints_sci))\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-5-2-run-detector1pipeline","position":29},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-stage-2-spec2pipeline-calwebb-spec2","position":30},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"In this section, we process our countrate (slope) image products from Stage 1 (calwebb_detector1) through the Spec2 (calwebb_spec2) pipeline to create Stage 2 \n\ndata products.\n\nInput: A single countrate (slope) image (_rate[ints].fits) or an association file listing multiple inputs.\n\nOutput: Calibrated products (rectified and unrectified) and 1D spectra.\n\n_cal[ints].fits: Calibrated 2D (unrectified) spectra (ncols x nrows).\n\n_s2d.fits: Resampled (rectified) 2D spectra (ncols x nrows).\n\n_x1d[ints].fits: Extracted 1D spectroscopic data (wavelength vs. flux).\n\nIn Stage 2, each exposure (or association) and detector produces a single file, with multiple extensions corresponding to each source.\n\nThe Spec2Pipeline applies additional instrumental corrections and calibrations (e.g., slit loss, path loss, etc.,) to countrate products that result in a fully calibrated individual exposure (per nod/dither position). The Spec2Pipeline also converts countrate products from units of DN/s to flux (Jy) for point sources and surface brightness (MJy/sr) for extended sources.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-stage-2-spec2pipeline-calwebb-spec2","position":31},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-1-configure-spec2pipeline","position":32},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.1 Configure Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"The Spec2Pipeline has the following steps available for NIRSpec MOS:\n\nassign_wcs: Associates a WCS object with each exposure.\n\nbadpix_selfcal: Flags bad pixels in the input data using a self-calibration technique based on median filtering along the spectral axis.\n\nmsaflagopen: Flags pixels in NIRSpec exposures affected by MSA shutters stuck in the open position.\n\nnsclean: Cleans 1/f noise.\n\nimprint: Removes patterns caused by the MSA structure in NIRSpec MOS and IFU exposures.\n\nbkg_subtract: Performs image subtraction for background removal.\n\nextract_2d : Extracts 2D arrays from spectral images.\n\nsrctype: Determines whether a spectroscopic source should be classified as a point or extended object.\n\nmaster_background : Subtracts background signal from 2D spectroscopic data using a 1D master background spectrum.\n\nwavecorr : Updates wavelength assignments for FS and MOS point sources that are offset in the dispersion direction within their slit.\n\nflat_field: Applies flat-field corrections to the input science dataset.\n\npathloss: Calculates and applies corrections for signal loss in spectroscopic data.\n\nbarshadow : Calculates the correction to NIRSpec MOS data for extended sources affected by the bar that separates adjacent microshutters.\n\nphotom: Applies photometric calibrations to convert data from countrate to surface brightness or flux density.\n\npixel_replace: Interpolates and estimates flux values for pixels flagged as DO_NOT_USE in 2D extracted spectra.\n\nresample_spec: Resamples each input 2D spectral image using WCS and distortion information.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox and\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Spec2Pipeline should be configured for MOS data.\n\nIf pixel-to-pixel or master background subtraction was chosen above, it will be applied during this stage. To override specific steps and reference files, use the examples below.\n\n# Select source to inspect.\n# Set None to proccess all sources.\nsource_ids, slit_names = None, None\n\nif demo_mode:\n    # The pipeline will accept a list of source IDs or slit names.\n    # Galaxies of interest:\n    source_ids = [\n        6355,\n        # 5144, 4590, 10612, 8140, 9922\n        ]\n    \n    slit_names = [\n        '72',\n        # '51', '55', '69', '16', '64'\n        ]\n\n# If running master background subtraction,\n# make sure we don't restrict to one slit.\nelif not master_bg:\n    source_ids, slit_names = None, None\n\n\n\n# Set up a dictionary to define how the Spec2 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\nspec2dict = {}\nspec2dict['assign_wcs'], spec2dict['badpix_selfcal'] = {}, {}\nspec2dict['nsclean'], spec2dict['master_background_mos'] = {}, {}\nspec2dict['barshadow'], spec2dict['extract_2d'] = {}, {}\nspec2dict['bkg_subtract'], spec2dict['srctype'], spec2dict['wavecorr'] = {}, {}, {}\nspec2dict['flat_field'], spec2dict['pathloss'] = {}, {}\nspec2dict['photom'], spec2dict['pixel_replace'] = {}, {}\nspec2dict['resample_spec'], spec2dict['extract_1d'] = {}, {}\n\n# ---------------------------Override reference files---------------------------\n\n# Overrides for various reference files (example).\n# Files should be in the base local directory or provide full path.\n#spec2dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\nspec2dict['bkg_subtract']['skip'] = not pixel_bg  # Runs if pixel-to-pixel bkg selected.\nspec2dict['master_background_mos']['skip'] = not master_bg  # Runs if masterbg selected.\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\n#spec2dict['pixel_replace']['skip'] = False\n#spec2dict['pixel_replace']['n_adjacent_cols'] = 5\n#spec2dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n# Extract specific sources; saves on processing time.\nif slit_names or source_ids is not None:\n    spec2dict['extract_2d']['slit_names'] = slit_names or source_ids\n\n# Turn on bad pixel self-calibration, where all exposures on a given detector \n# are used to find and flag bad pixels that may have been missed by the bad pixel mask.\n# This step is experimental, and works best when dedicated background observations are included.\n#spec2dict['badpix_selfcal']['skip'] = False\n#spec2dict['badpix_selfcal']['flagfrac_upper'] = 0.005  # Fraction of pixels to flag.\n\n# Resample weight_type.\nspec2dict['resample_spec']['weight_type'] = 'ivm'\n\n\n\nResampling 2D spectra (resample_spec step)can sometimes introduce artificial noise and reduce the signal-to-noise ratio (SNR) in the resulting 1D spectra when using weight_type='ivm' (\n\nknown issue). The default is now set to ‘exptime’. Consider the following when selecting a weight_type:\n\n‘ivm’: Inverse variant scaling based on read noise (VAR_RNOISE), ideal for rejecting outliers and better suited for faint sources.\n\n‘exptime’: Uses exposure time for scaling, improving SNR for bright sources.\n\n# Run nsclean for 1/f noise.\n#spec2dict['nsclean']['skip'] = False\n#spec2dict['nsclean']['n_sigma'] = 2\n\n\n\nTo correct for 1/f noise with nsclean in Stage 2, see the MOS_NSClean_example demo notebook for MOS data \n\nhere.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-1-configure-spec2pipeline","position":33},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline Association Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-2-create-spec2pipeline-association-files","position":34},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.2 Create Spec2Pipeline Association Files","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Association (ASN) files define the relationships between multiple exposures, allowing them to get processed as a set rather than individually. Processing an ASN file enables the exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than as individual objects.\n\nStage 2 ASN files for MOS data can include science, background, and selfcal exposure types. A Stage 2 ASN file requires at least one science file but can contain multiple background and selfcal files that enable pixel-to-pixel background subtraction and bad pixel self-calibration in calwebb_spec2.\n\nBelow we create these Stage 2 ASN files.\n\nBackground subtraction may not be correctly applied if more than one science file is included in the association.\n\nDefine a function that associates background, imprint, and selfcal exposures for nodded observations.\n\ndef asn_nod(asn, onescifile, sci, sci_imprint, pattnum):\n    \"\"\"\n    Associate background, imprint, and selfcal exposures for nodded observations.\n\n    Parameters\n    ----------\n    asn : dict\n        The association dictionary to update.\n    onescifile : str \n        Path to the primary science file.\n    sci : list of str\n        List of science exposure file paths.\n    sci_imprint : list of str\n        List of science imprint exposure file paths.\n    pattnum : int\n        Dither position.\n\n    Returns\n    -------\n    asn : dict \n        Updated association dictionary with members for applicable background, imprint, and selfcal.\n    \"\"\"\n    members = asn['products'][0]['members']\n\n    # Assign background exposures.\n    for file in sci:\n        # If dither position is different from the input position, use it as a background.\n        if fits.getval(file, 'PATT_NUM') != pattnum:\n            members.append({'expname': file, 'exptype': 'background'})\n    \n    # Assign imprint exposures (pipeline handles figuring out which one is best).\n    for file in sci_imprint:\n        # Only IFU and MOS observations have imprint exposures.\n        if fits.getval(file, 'EXP_TYPE') == 'NRS_IFU' or 'NRS_MSASPEC':\n            if match_gwa(onescifile, file):\n                members.append({'expname': file, 'exptype': 'imprint'})\n\n    # Assign selfcal exposures.\n    for file in sci + sci_imprint:\n        members.append({'expname': file, 'exptype': 'selfcal'})\n\n    return asn\n\n\n\nDefine a function that creates a Level 2 ASN file.\n\ndef writel2asn(onescifile, allscifiles, asnfile, product_name, exp_type):\n    \"\"\"\n    Create a Level 2 association file for each science exposure.\n\n    Parameters\n    ----------\n    onescifile : str\n        Path to the primary science exposure file.\n    allscifiles : list of str\n        List of all science exposure files.\n    asnfile : str\n        Path to write the output association file.\n    product_name : str\n        Name of the product for the association.\n    exp_type : str, optional\n        Exposure type to match against.\n\n    Returns\n    -------\n    True if the association was written successfully, and False otherwise \n    \"\"\"\n    # Define a basic association with the science file.\n    # Wrap in array since input was single exposure.\n    asn = afl.asn_from_list([onescifile], rule=DMSLevel2bBase, product_name=product_name)\n    asn.data['program'] = program if 'program' in globals() else \"9999\"\n\n    # Grab header information from the science file.\n    exp_type = fits.getval(onescifile, 'EXP_TYPE')\n    if (exp_type == exp_type):\n        detector = fits.getval(onescifile, 'DETECTOR')\n        grating = fits.getval(onescifile, 'GRATING')\n        filt = fits.getval(onescifile, 'FILTER')\n        patttype = fits.getval(onescifile, 'PATTTYPE')  # Dither pattern type.\n        pattnum = fits.getval(onescifile, 'PATT_NUM')  # Dither pattern number.\n        imprint = fits.getval(onescifile, 'IS_IMPRT')  # Imprint exposure?\n        \n        # If this is an imprint exposure, fail out since those shouldn't be processed alone.\n        if imprint:\n            return False\n\n    # If the exposure type does not match, fail out \n    # to ensure TA images don't get processed by accident.\n    else:\n        return False\n\n    # Find all files matching the input configuration and split into regular/imprint.\n    use_sci, use_sci_imprint = get_matching(allscifiles, detector, filt, grating, exp_type)\n    \n    # If this uses nodded exposures set up pixel-based background subtraction accordingly.\n    is_nod = 'NOD' in patttype.split('-') or fits.getval(onescifile, 'NOD_TYPE') \n    if is_nod:\n        asn = asn_nod(asn, onescifile, use_sci, use_sci_imprint, pattnum)\n    \n    # Write the association to a json file.\n    _, serialized = asn.dump()\n    with open(asnfile, 'w') as outfile:\n        outfile.write(serialized)\n        \n    return True\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-2-create-spec2pipeline-association-files","position":35},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.3 MSA Metadata File","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-3-msa-metadata-file","position":36},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.3 MSA Metadata File","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"While it doesn’t contain actual science data, the NIRSpec \n\nMSA metadata file is a crucial component of calibration processing for NIRSpec MOS exposures through the calwebb_spec2 pipeline. The MSA metadata contains:\n\nInformation on which MSA shutters (slitlets) are open, which sources they observe (if any), and whether they should be used for science or background in each dithered exposure.\n\nSource details, including RA, Dec, and whether they should be treated as point sources (stellarity > 0.75) or extended (uniform illumination) for path loss corrections.\n\nAll MSA configurations for an observing program may be stored in a single MSA metadata file.\n\nThe MSA metadata file is stored in the ASN directory.\n\nIf you wish to edit the MSA metafile, a detailed example notebook is forthcoming (\n\ndraft) ...\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-3-msa-metadata-file","position":37},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.4 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-4-run-spec2pipeline","position":38},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"6.4 Run Spec2Pipeline","lvl2":"6. Stage 2: Spec2Pipeline (calwebb_spec2)"},"content":"Run the science files and, if available, any background files through the calwebb_spec2 pipeline using the .call() method.\n\nPerform pixel-to-pixel or master background subtraction (if desired) here in Stage 2.\n\ntime_spec2 = time.perf_counter()  # Tracks runtime for Stage 2.\n\n\n\n# To save on runtime turns off creation of quicklook 2d/1d spectra for science data.\n#spec2dict['resample_spec']['skip'] = True  # S2D products.\n#spec2dict['extract_1d']['skip'] = True  # X1D products.\n\n\n\n# Run Stage 2 pipeline using the custom spec2dict dictionary.\n\nif dospec2:\n    # ------------------Execute using Science ASN files-------------------\n    for file in rate_sci:\n        try:  # Create ASN files.\n            asnfile = os.path.join(asn_dir, os.path.basename(file).replace('rate.fits', 'l2asn.json'))\n            if writel2asn(file, rate_sci, asnfile, 'Level2', 'NRS_MSASPEC'):\n                print(f\"Applying Stage 2 Corrections & Calibrations to: {file}\")\n                spec2sci_result = Spec2Pipeline.call(asnfile,\n                                                     save_results=True,\n                                                     steps=spec2dict,\n                                                     output_dir=spec2_dir)\n        except Exception as e:\n            # A handle for when no slits fall on NRS1/2.\n            print(f\"Skipped processing {os.path.basename(asnfile)}: {e}\")\n\n    print(\"Stage 2 has been completed! \\n\")\nelse:\n    print('Skipping Spec2 processing for SCI data.')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# List the Stage 2 products.\n\n# -----------------------------Science files-----------------------------\nsci_cal = sorted(glob.glob(spec2_dir + '*_cal.fits'))\nsci_s2d = sorted(glob.glob(spec2_dir + '*_s2d.fits'))\nsci_x1d = sorted(glob.glob(spec2_dir + '*_x1d.fits'))\n\nprint(f\"SCIENCE | Stage 2 CAL Products:\\n{'-' * 20}\\n\" + \"\\n\".join(sci_cal))\nprint(f\"SCIENCE | Stage 2 S2D Products:\\n{'-' * 20}\\n\" + \"\\n\".join(sci_s2d))\nprint(f\"SCIENCE | Stage 2 X1D Products:\\n{'-' * 20}\\n\" + \"\\n\".join(sci_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-6-4-run-spec2pipeline","position":39},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-stage-3-spec3pipeline-calwebb-spec3","position":40},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"In this section, we process our calibrated spectra from Stage 2 (calwebb_spec2) through the Spec3 (calwebb_spec3) pipeline to create Stage 3 \n\ndata products.\n\nInput: An ASN file that lists multiple calibrated exposures (_cal.fits) in addition to any background exposures (_x1d.fits).\n\nOutput: A single calibrated product (rectified and unrectified) and 1D spectrum. These data products have units of MJy/sr (or Jy for extracted point-source spectra).\n\n_cal.fits: Calibrated 2D (unrectified) spectra (ncols x nrows).\n\n_crf.fits: Calibrated 2D (unrectified) spectra whose DQ array has been updated to flag pixels detected as outliers (ncols x nrows).\n\n_s2d.fits: Resampled (rectified) 2D spectra (ncols x nrows).\n\n_x1d.fits: Extracted 1D spectroscopic data.\n\nIn Stage 3, single files are created for each source, one extension in the file.\n\nThe Spec3Pipeline performs additional corrections (e.g., outlier detection) and combines calibrated data from multiple exposures (e.g. a dither/nod pattern) into a single 2D spectral product, as well as a combined 1D spectrum.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-stage-3-spec3pipeline-calwebb-spec3","position":41},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"7.1 Configure Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-1-configure-spec3pipeline","position":42},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"7.1 Configure Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"The Spec3Pipeline has the following steps available for NIRSpec MOS:\n\nassign_mtwcs: Modifies the WCS output frame in each exposure of a Moving Target (MT) observation association.\n\noutlier_detection : Identification of bad pixels or cosmic-rays that remain in each of the input images.\n\npixel_replace: Interpolates and estimates flux values for pixels flagged as DO_NOT_USE in 2D extracted spectra.\n\nresample_spec: Resamples each input 2D spectral image using WCS and distortion information.\n\nextract_1d: Extracts a 1D signal from 2D or 3D datasets.\n\nFor more information about each step and a full list of step arguments, please refer to the official documentation: \n\nJDox and\n\n\nReadtheDocs\n\nBelow, we set up a dictionary that defines how the Spec3Pipeline should be configured for MOS data.\n\nTo override specific steps and reference files, use the examples below.\n\n# Set up a dictionary to define how the Spec3 pipeline should be configured.\n\n# -------------------------Boilerplate dictionary setup-------------------------\nspec3dict = {}\nspec3dict['assign_mtwcs'], spec3dict['outlier_detection'] = {}, {}\nspec3dict['pixel_replace'], spec3dict['resample_spec'] = {}, {}\nspec3dict['extract_1d'] = {}\n\n# ---------------------------Override reference files---------------------------\n\n# Overrides for various reference files.\n# Files should be in the base local directory or provide full path.\n#spec3dict['extract_1d']['override_extract1d'] = 'myfile.json'\n\n# -----------------------------Set step parameters------------------------------\n\n# Overrides for whether or not certain steps should be skipped (example).\nspec3dict['outlier_detection']['skip'] = False\n\n# Run pixel replacement code to extrapolate values for otherwise bad pixels.\n# This can help mitigate 5-10% negative dips in spectra of bright sources.\n# Use the 'fit_profile' algorithm.\n#spec3dict['pixel_replace']['skip'] = False\n#spec3dict['pixel_replace']['n_adjacent_cols'] = 5\n#spec3dict['pixel_replace']['algorithm'] = 'fit_profile'\n\n# Resample weight_type.\nspec3dict['resample_spec']['weight_type'] = 'ivm'\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-1-configure-spec3pipeline","position":43},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"7.2 Create Spec3Pipeline Association Files","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-2-create-spec3pipeline-association-files","position":44},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"7.2 Create Spec3Pipeline Association Files","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"Stage 3 ASN files for MOS data includes science exposure types. A Stage 3 ASN file requires at least one science file, although there is usually more than one. Note that the science exposures should be in the _cal.fits format.\n\nIn practice, Stage 3 ASN files can be downloaded directly from MAST, however, here we provide an example of manually creating Stage 3 ASN files. Below we create an ASN files for each GRATING/FILTER combination.\n\ndef writel3asn(scifiles):\n    \"\"\"\n    Create a Level 3 association file.\n\n    Parameters\n    ----------\n    scifiles : list of str\n        List of all science exposure files.\n    \n    Returns\n    -------\n    None.\n    \"\"\"\n    # Filter based on GRATING/FILTER.\n    from collections import defaultdict\n    grouped = defaultdict(lambda: {'sci': [], 'bg': []})\n\n    for f in scifiles:\n        k = (fits.getval(f, 'FILTER'), fits.getval(f, 'GRATING'))\n        grouped[k]['sci'].append(f)\n\n    # Make ASN for each FILTER/GRATING.\n    for (filt, grat), files in grouped.items():\n        name = f\"{filt}_{grat}\".lower()\n        asnfile = os.path.join(asn_dir, f\"{name}_l3asn.json\")\n        asn = afl.asn_from_list(files['sci'], rule=DMS_Level3_Base, product_name=name)\n\n        with open(asnfile, 'w') as f:\n            f.write(asn.dump()[1])\n    print(\"Level 3 ASN creation complete!\")\n\n\n\nif dospec3:\n    writel3asn(sci_cal)\n\n\n\nCheck that the association files for Stage 3\n\n# Open an ASN file as an example.\n# Check that file paths have been correctly updated.\nif dospec3:\n    spec3_asn = glob.glob(asn_dir+'*l3asn.json')[0]\n    with open(spec3_asn, 'r') as f_obj:\n        asnfile_data = json.load(f_obj)\n    display(JSON(asnfile_data, expanded=True))\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-2-create-spec3pipeline-association-files","position":45},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"7.3 Run Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-3-run-spec3pipeline","position":46},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"7.3 Run Spec3Pipeline","lvl2":"7. Stage 3: Spec3Pipeline (calwebb_spec3)"},"content":"Run the science files through the calwebb_spec3 pipeline using the .call() method.\n\ntime_spec3 = time.perf_counter()\n\n\n\n# Run Stage 3 pipeline using the custom spec3dict dictionary.\n\nif dospec3:\n    for spec3_asn in glob.glob(asn_dir+'*l3asn.json'):\n        print(f\"Applying Stage 3 Corrections & Calibrations to: \"f\"{os.path.basename(spec3_asn)}\")\n        spec3_result = Spec3Pipeline.call(spec3_asn,\n                                          save_results=True,\n                                          steps=spec3dict,\n                                          output_dir=spec3_dir)\n    print(\"Stage 3 has been completed! \\n\")\nelse:\n    print(\"Skipping Stage 3. \\n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Print out the time benchmarks.\ntime4 = time.perf_counter()\nprint(f\"Runtime so far: {round((time4 - time0) / 60.0, 1):0.4f} min\")\nprint(f\"Runtime for Spec3: {round((time4 - time_spec3) / 60.0, 1):0.4f} min\")\n\n\n\n# List the Stage 3 products.\n\nstage3_cal = sorted(glob.glob(spec3_dir + '*_cal.fits'))\nstage3_s2d = sorted(glob.glob(spec3_dir + '*_s2d.fits'))\nstage3_x1d = sorted(glob.glob(spec3_dir + '*_x1d.fits'))\n\nprint(f\"Stage 3 CAL Products:\\n{'-' * 20}\\n\" + \"\\n\".join(stage3_cal))\nprint(f\"Stage 3 S3D Products:\\n{'-' * 20}\\n\" + \"\\n\".join(stage3_s2d))\nprint(f\"Stage 3 X1D Products:\\n{'-' * 20}\\n\" + \"\\n\".join(stage3_x1d))\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-7-3-run-spec3pipeline","position":47},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"8. Visualize the Data"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-visualize-the-data","position":48},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"8. Visualize the Data"},"content":"Define convenience funcitons for visualization. For some plots we utilize \n\njdaviz, a package of astronomical data analysis visualization tools designed to work in Jupyter notebooks.\n\nDefine a function to display Stage 1 products.\n\ndef display_rate(rates,\n                 slits_models=[],\n                 integration=0,\n                 extname='data',\n                 cmap='viridis',\n                 bad_color=(1, 0.7, 0.7),\n                 vmin=None,\n                 vmax=None,\n                 scale='asinh',\n                 aspect='auto',\n                 title_prefix=None,\n                 title_path=False,\n                 save_plot=False):\n    \"\"\"\n    Display countrate images.\n\n    Parameters\n    ----------\n    rates : list of str\n        A list of RATE[INTS] files to be displayed.\n    slits_models : list of str, optional\n        A list of CAL[INTS] or S2D files containing the slit models.\n        If provided, slit cutouts will be overlaid on the countrate images.\n    integration : {None, 'min', int}, optional\n        Specifies the integration to use for multi-integration data.\n        If 'min', the minimum value across all integrations is used.\n        If an integer, the specific integration index is used (default 0).\n    extname : str, optional\n        The name of the data extension to extract from ('data', 'dq', etc.).\n    cmap : str, optional\n        Colormap to use for displaying the image. Default is 'viridis'.\n    bad_color : tuple of float, optional\n        Color to use for NaN pixels. Default is light red (1, 0.7, 0.7).\n    vmin : float, optional\n        Minimum value for color scaling. If None, determined from the data.\n    vmax : float, optional\n        Maximum value for color scaling. If None, determined from the data.\n    scale : {'linear', 'log', 'asinh'}, optional\n        Scale to use for the image normalization. Default is 'asinh'.\n    aspect : str, optional\n        Aspect ratio of the plot. Default is 'auto'.\n    title_prefix : str, optional\n        Optional prefix for the plot title.\n    title_path : bool, optional\n        If True, uses the full file path for the title;\n        otherwise, uses the basename. Default is False.\n    save_plot : bool, optional\n        If True, saves the plot as a PNG file. Default is False.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n\n    # -------------------------------Check Inputs-------------------------------\n    rates = [rates] if isinstance(rates, str) else rates\n    slits_models = [slits_models] if isinstance(slits_models, str) else slits_models\n    nrates = len(rates)\n\n    # ------------------------------Set up figures------------------------------\n    fig, axes = plt.subplots(nrates, 1, figsize=(12, 12 * nrates),\n                             sharex=True, height_ratios=[1] * nrates)\n    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n    axes = [axes] if nrates == 1 else axes\n\n    cmap = plt.get_cmap(cmap)  # Set up colormap and bad pixel color.\n    cmap.set_bad(bad_color, 1.0)\n\n    # ---------------------------Plot countrate image---------------------------\n    for i, (rate, cal) in enumerate(itertools.zip_longest(rates,\n                                                          slits_models,\n                                                          fillvalue=None)):\n\n        # -------------------Open files as JWST datamodels-------------------\n        model = datamodels.open(rate)\n        slits_model = datamodels.open(cal) if cal else None\n\n        # -----------------------Extract the 2D/3D data----------------------\n        data_2d = getattr(model, extname)\n        if data_2d.ndim == 3:  # Handle multi-integration data.\n            if integration == 'min':\n                data_2d = np.nanmin(data_2d, axis=0)\n            elif isinstance(integration, int) and 0 <= integration < data_2d.shape[0]:\n                data_2d = data_2d[integration]\n            else:\n                raise ValueError(f\"Invalid integration '{integration}' for 3D data.\")\n\n        # ---------------------------Scale the data-------------------------\n        sigma_clipped_data = sigma_clip(data_2d, sigma=5, maxiters=3)\n        vmin = np.nanmin(sigma_clipped_data) if vmin is None else vmin\n        vmax = np.nanmax(sigma_clipped_data) if vmax is None else vmax\n        stretch_map = {'log': LogStretch(), 'linear': LinearStretch(),\n                       'asinh': AsinhStretch()}\n        if scale in stretch_map:\n            norm = ImageNormalize(sigma_clipped_data,\n                                  interval=ManualInterval(vmin=vmin, vmax=vmax),\n                                  stretch=stretch_map[scale])\n        else:\n            norm = simple_norm(sigma_clipped_data, vmin=vmin, vmax=vmax)\n\n        # -----------------Draw slits and label source ids------------------\n        # slits_model can be s2d/cal from spec2 - contains slit models for all sources.\n        if slits_model:\n            slit_patches = []\n            for slit in slits_model.slits:\n                slit_patch = Rectangle((slit.xstart, slit.ystart),\n                                       slit.xsize, slit.ysize)\n                slit_patches.append(slit_patch)\n                y = slit.ystart + slit.ysize / 2\n                ha = 'right' if 'nrs1' in rate else 'left'\n                plt.text(slit.xstart, y, slit.source_id, color='w', ha=ha, va='center',\n                         fontsize=7, path_effects=[], weight='bold')\n            axes[i].add_collection(PatchCollection(slit_patches, ec='r', fc='None'))\n\n        # ----------------Plot the countrate image & colorbar---------------\n        plt.subplots_adjust(left=0.05, right=0.85)\n        im = axes[i].imshow(data_2d, origin='lower', cmap=cmap,\n                            norm=norm, aspect=aspect, interpolation='nearest')\n        units = model.meta.bunit_data\n        cbar_ax = fig.add_axes([axes[i].get_position().x1 + 0.02,\n                                axes[i].get_position().y0, 0.02,\n                                axes[i].get_position().height])\n        cbar = fig.colorbar(im, cax=cbar_ax)\n        cbar.set_label(units, fontsize=12)\n\n        # -----------------Construct title and axis labels------------------\n        filename = model.meta.filename\n        title = (f\"{title_prefix + ' ' if title_prefix else ''}\"\n                 f\"{filename if title_path else os.path.basename(filename)}\")\n        if integration is not None:\n            title = title.replace('rateints', f'rateints[{integration}]')\n        axes[i].set_title(title, fontsize=14)\n        axes[i].set_xlabel(\"Pixel Column\", fontsize=12)\n        axes[i].set_ylabel(\"Pixel Row\", fontsize=12)\n\n        # -------------------------Save the figure?-------------------------\n        if save_plot:\n            save_plot = rate.replace('fits', 'png')\n            if integration:\n                save_plot = save_plot.replace('.png', '%s.png' % integration)\n            fig.savefig(save_plot, dpi=200)\n\n        fig.show()\n\n\n\nFunction to create plots of the Stage 2/3 spectra.\n\ndef display_spectra(spectra,\n                    compare_x1d=None,\n                    compare_mast=None,\n                    integration=None,\n                    extname='data',\n                    source_id=None,\n                    source_type=None,\n                    expand_wavelength_gap=True,\n                    plot_resample=True,\n                    plot_errors=False,\n                    cmap='viridis',\n                    bad_color=(1, 0.7, 0.7),\n                    aspect='auto',\n                    vmin=None,\n                    vmax=None,\n                    scale='asinh',\n                    title_prefix=None,\n                    title_path=False,\n                    y_limits=None,\n                    is_stage3=False):\n\n    \"\"\"\n    Display 2D and 1D spectra (Stage 2/3).\n\n    Parameters\n    ----------\n    spectra : list of str\n        A list of data products (e.g., CAL, S2D, X1D files).\n    compare_x1d : list of str, optional\n        A list of 1D spectra for comparison (X1D files).\n    compare_mast : list of str, optional\n        A list of 1D spectra from MAST for comparison (X1D files).\n    integration : {None, 'min', int}, optional\n        Specifies the integration to use for multi-integration data.\n        If 'min', the minimum value across all integrations is used.\n        If an integer, the specific integration index is used (default 0).\n     extname : str, optional\n        The name of the data extension to extract ('data', 'dq', etc.).\n    source_id : int or none, optional\n        Identifier for the source/slit to be displayed. Default is None.\n    source_type : str, optional\n        Override data source type ('POINT' or 'EXTENDED').\n    expand_wavelength_gap : bool, optional\n        If True, expands gaps in the wavelength data for better visualization.\n    plot_resample : bool, optional\n        If True, plots resampled (S2D) data products;\n        otherwise, plots calibrated (CAL) data. Default is True.\n    plot_errors : bool, optional\n        If True, plots the error bands for the 1D spectra. Default is False.\n    cmap : str, optional\n        Colormap to use for displaying the images. Default is 'viridis'.\n    bad_color : tuple of float, optional\n        Color to use for bad pixels. Default is light red (1, 0.7, 0.7).\n    aspect : str, optional\n        Aspect ratio of the plot. Default is 'auto'.\n    vmin : float, optional\n        Minimum value for color scaling. If None, determined from the data.\n    vmax : float, optional\n        Maximum value for color scaling. If None, determined from the data.\n    scale : {'linear', 'log', 'asinh'}, optional\n        Scale to use for the image normalization. Default is 'asinh'.\n    title_prefix : str, optional\n        Optional prefix for the plot title.\n    title_path : bool, optional\n        If True, uses the full file path for the title;\n        otherwise, uses the basename. Default is False.\n    y_limits : tuple of float, optional\n        Limits for the y-axis of the 1D spectrum plot.\n        If None, limits are determined from the data.\n    is_stage3 : bool, optional\n        Plot stage 3 products? Default is False.\n\n    Returns\n    -------\n    None.\n    \"\"\"\n\n    # ---------------------------------Check Inputs---------------------------------\n    spectra = [spectra] if isinstance(spectra, str) else spectra\n    compare_x1d = [compare_x1d] if isinstance(compare_x1d, str) else compare_x1d\n    compare_mast = [compare_mast] if isinstance(compare_mast, str) else compare_mast\n\n    # Assign a default source_id if one was not supplied.\n    if source_id is None:\n        ftype = \"cal\"\n        if plot_resample:\n            ftype = \"s2d\"\n        for file in spectra:\n            if ftype in file:\n                source_id = datamodels.open(file)[0].slits[0].source_id\n                break\n\n    src_str = str(source_id)\n\n    # Plot stage 3 products?\n    if is_stage3:\n\n        # Stage 3 products should include the source_id in the filename.\n        # Sort based on filename rather than open all.\n        def filter_prod(products, source_id):\n            \"\"\"Filter products based on the source_id.\"\"\"\n\n            return [\n                f for f in products\n                if src_str.lower() in f and ('FXD_SLIT' not in fits.getheader(f, ext=0) or fits.getheader(f, ext=0)['FXD_SLIT'].lower() == src_str.lower())]\n\n        spectra = filter_prod(spectra, source_id)\n        compare_x1d = filter_prod(compare_x1d, source_id) if compare_x1d else None\n        compare_mast = filter_prod(compare_mast, source_id) if compare_mast else None\n\n    ftypes = {ftype: [f for f in spectra\n                      if ftype in f] for ftype in [\"cal\", \"s2d\", \"x1d\"]}\n    products = sorted(ftypes['s2d']) if plot_resample else sorted(ftypes['cal'])\n    if not products:\n        raise ValueError(\"No valid data products found for plotting.\")\n\n    # --------------------------------Set up figures-------------------------------\n    total_plots = len(products) + bool(ftypes['x1d'])\n    height_ratios = [1] * len(products) + ([3] if bool(ftypes['x1d']) else [])\n    fig, axes = plt.subplots(total_plots, 1, figsize=(15, 5 * total_plots),\n                             sharex=False, height_ratios=height_ratios)\n    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n    ax2d, ax1d = (axes[:-1], axes[-1]) if bool(ftypes['x1d']) else (axes, None)\n\n    cmap = plt.get_cmap(cmap)  # Set up colormap and bad pixel color.\n    cmap.set_bad(bad_color, 1.0)\n    colors = plt.get_cmap('tab10').colors\n    color_cycle = itertools.cycle(colors)\n\n    # ---------------------------------Plot spectra--------------------------------\n    for i, product in enumerate(products):\n        model = datamodels.open(product)  # Open files as JWST datamodels.\n\n        # Extract the correct 2D source spectrum if there are multiple.\n        slit_m = model\n        if 'slits' in model:\n            slits = model.slits\n            slit_m = next((s for s in slits\n                           if getattr(s, 'name', None) == source_id), None)\n            slit_m = slit_m or next((s for s in model.slits\n                                     if s.source_id == source_id), None)\n            if not slit_m:\n                print(f\"'{source_id}' not found/invalid.\")\n                print(f\"Available source_ids: {[s.source_id for s in slits][:5]}\")\n                break\n\n        # Check if 'fixed_slit' exists, otherwise fall back to 'slitlet_id'\n        slit_name = (f\"SLIT: {getattr(slit_m, 'name', None) or slit_m.slitlet_id}, \"\n                     f\"SOURCE: {getattr(slit_m, 'source_id', '')}\")\n\n        # -----------------------Extract the 2D/3D data----------------------\n        data_2d = getattr(slit_m, extname)\n        if data_2d.ndim == 3:  # Handle multi-integration data.\n            if integration == 'min':\n                data_2d = np.nanmin(data_2d, axis=0)\n            elif isinstance(integration, int) and 0 <= integration < data_2d.shape[0]:\n                data_2d = data_2d[integration]\n            else:\n                raise ValueError(f\"Invalid integration '{integration}' for 3D data.\")\n\n        # -----------Convert from pixels to wavelength (x-axis)--------------\n        wcsobj = slit_m.meta.wcs  # Obtaining the WCS object from the meta data.\n        y, x = np.mgrid[:slit_m.data.shape[0], :slit_m.data.shape[1]]\n        # Coordinate transform from detector space (pixels) to sky (RA, DEC).\n        det2sky = wcsobj.get_transform('detector', 'world')\n        ra, dec, s2dwave = det2sky(x, y)  # RA/Dec, wavelength (microns) for each pixel.\n        s2dwaves = s2dwave[0, :]  # Single row since this is the rectified spectrum.\n        x_arr = np.arange(0, slit_m.data.shape[1], int(len(slit_m.data[1]) / 4))\n        wav = np.round(s2dwaves[x_arr], 2)  # Populating the wavelength array.\n        ax2d[i].set_xticks(x_arr, wav)\n\n        # xticks = np.arange(np.ceil(wave_1d[0]), wave_1d[-1], 0.2)\n        # xtick_pos = np.interp(xticks, wave_1d, np.arange(num_waves))\n        # ax1d.set_xticks(xtick_pos)\n        # ax1d.set_xticklabels([f'{xtick:.1f}' for xtick in xticks])\n\n        # ---------------------------Scale the data-------------------------\n        sigma_clipped_data = sigma_clip(data_2d, sigma=5, maxiters=3)\n        vmin = np.nanmin(sigma_clipped_data) if vmin is None else vmin\n        vmax = np.nanmax(sigma_clipped_data) if vmax is None else vmax\n        stretch_map = {'log': LogStretch(), 'linear': LinearStretch(),\n                       'asinh': AsinhStretch()}\n        if scale in stretch_map:\n            norm = ImageNormalize(sigma_clipped_data,\n                                  interval=ManualInterval(vmin=vmin, vmax=vmax),\n                                  stretch=stretch_map[scale])\n        else:\n            norm = simple_norm(sigma_clipped_data, vmin=vmin, vmax=vmax)\n\n        # -------------------------Plot 1D Spectra-------------------------\n        for k, (prods_1d, prefix) in enumerate([(sorted(ftypes['x1d']),\n                                                 f'{title_prefix} '),\n                                                (compare_x1d, 'RE-EXTRACTION '),\n                                                (compare_mast, 'MAST ')]):\n            if prods_1d:\n                model_1d = datamodels.open(prods_1d[i])\n                specs = model_1d.spec\n                spec = next((s for s in specs if\n                             getattr(s, 'name', None) == source_id), None)\n                spec = spec or next((s for s in specs\n                                     if s.source_id == source_id), None)\n\n                if spec:\n                    tab = spec.spec_table\n                    source_type = source_type if source_type else slit_m.source_type\n                    wave = tab.WAVELENGTH\n                    flux = tab.FLUX if source_type == 'POINT' else tab.SURF_BRIGHT\n                    errs = tab.FLUX_ERROR if source_type == 'POINT' else tab.SB_ERROR\n\n                    # Expand the array to visualize the wavelength gap.\n                    if expand_wavelength_gap:\n                        dx1d_wave = wave[1:] - wave[:-1]\n                        igap = np.argmax(dx1d_wave)\n                        dx_replace = (dx1d_wave[igap - 1] + dx1d_wave[igap + 1]) / 2.\n                        nfill = int(np.round(np.nanmax(dx1d_wave) / dx_replace))\n\n                        if nfill > 1:\n                            print(nfill)\n                            print(f\"Expanding wavelength gap {wave[igap]:.2f} \"\n                                  f\"-- {wave[igap + 1]:.2f} μm\")\n\n                            wave_fill = np.mgrid[wave[igap]:wave[igap + 1]:(nfill + 1) * 1j]\n                            wave = np.concatenate([wave[:igap + 1],\n                                                   wave_fill[1:-1],\n                                                   wave[igap + 1:]])\n\n                            if prefix != 'RE-EXTRACTION ':\n                                num_rows, num_waves = data_2d.shape\n                                fill_2d = np.zeros(shape=(num_rows, nfill - 1)) * np.nan\n                                data_2d = np.concatenate([data_2d[:, :igap + 1],\n                                                          fill_2d, data_2d[:, igap + 1:]],\n                                                         axis=1)\n\n                            fill = np.zeros(shape=(nfill - 1)) * np.nan\n                            flux = np.concatenate([flux[:igap + 1], fill, flux[igap + 1:]])\n                            errs = np.concatenate([errs[:igap + 1], fill, errs[igap + 1:]])\n                    else:\n                        nfill = 0\n\n                    # ----------------Construct legends and annotations-----------------\n                    detector = slit_m.meta.instrument.detector\n                    ffilter = slit_m.meta.instrument.filter\n                    grating = slit_m.meta.instrument.grating\n                    dither = model.meta.dither.position_number\n                    label_2d = f'{grating}/{ffilter}'\n                    label_1d = f'{detector} ({grating}/{ffilter})'\n                    if not is_stage3:\n                        label_2d = f'Dither/Nod {dither} ({label_2d})'\n                        label_1d = (f'{prefix} Dither/Nod {dither} {label_1d}')\n                    else:\n                        label_1d = f'{prefix}{label_1d}'\n                    ax2d[i].annotate(label_2d, xy=(1, 1), xycoords='axes fraction',\n                                     xytext=(-10, -10), textcoords='offset points',\n                                     bbox=dict(boxstyle=\"round,pad=0.3\",\n                                               edgecolor='white',\n                                               facecolor='white', alpha=0.8),\n                                     fontsize=12, ha='right', va='top')\n\n                    title_2d = (f\"{title_prefix + ' ' if title_prefix else ''}\"\n                                f\"{model.meta.filename} | {slit_name}\")\n                    if integration:\n                        title_2d = title_2d.replace('.fits', f'[{integration}].fits')\n                    ax2d[i].set_title(title_2d, fontsize=14)\n                    if not bool(ftypes['x1d']):\n                        ax2d[i].set_xlabel(\"Wavelength (μm)\", fontsize=12)\n                    ax2d[i].set_ylabel(\"Pixel Row\", fontsize=12)\n                    ax2d[i].legend(fontsize=12)\n\n                    # ------------------------------------------------------------------\n\n                    num_waves = len(wave)\n                    color = next(color_cycle)\n                    ax1d.step(wave, flux, lw=1, label=label_1d, color=color)\n                    if plot_errors:\n                        ax1d.fill_between(np.arange(num_waves), flux - errs,\n                                          flux + errs, color='grey', alpha=0.3)\n                    ax1d.legend(fontsize=12)\n                    ax1d.set_title(f\"{title_prefix + ' ' if title_prefix else ''}\"\n                                   f\"Extracted 1D Spectra | {slit_name}\", fontsize=14)\n                    ax1d.set_ylabel(\"Flux (Jy)\" if source_type == 'POINT'\n                                    else \"Surface Brightness (MJy/sr)\", fontsize=12)\n                    ax1d.set_xlabel(\"Wavelength (μm)\", fontsize=12)\n\n                    ax1d.set_ylim(y_limits or (np.nanpercentile(flux, 1),\n                                               np.nanpercentile(flux, 99.5)))\n\n                    # --------------------Plot the 2D spectra & colorbar---------------\n                    plt.subplots_adjust(left=0.05, right=0.85)\n                    if k == 0:\n                        im = ax2d[i].imshow(data_2d, origin='lower',\n                                            cmap=cmap, norm=norm,\n                                            aspect=aspect, interpolation='nearest')\n                        units = slit_m.meta.bunit_data\n                        cbar_ax = fig.add_axes([ax2d[i].get_position().x1 + 0.02,\n                                                ax2d[i].get_position().y0, 0.02,\n                                                ax2d[i].get_position().height])\n                        cbar = fig.colorbar(im, cax=cbar_ax)\n                        cbar.set_label(units, fontsize=12)\n\n                    # ----------------------Add extraction region---------------------\n                    ystart, ystop, xstart, xstop = (spec.extraction_ystart - 1,\n                                                    spec.extraction_ystop - 1,\n                                                    spec.extraction_xstart - 1,\n                                                    spec.extraction_xstop - 1)\n                    extract_width = ystop - ystart + 1\n                    box = Rectangle((xstart, ystart), xstop - xstart + nfill,\n                                    extract_width, fc='None', ec=color,\n                                    lw=2, label=prefix)\n                    ax2d[i].add_patch(box)\n                    ax2d[i].legend()\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-visualize-the-data","position":49},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-1-display-detector1pipeline-products","position":50},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"8.1 Display Detector1Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Inspect the Stage 1 slope products.\n\nif doviz:\n    rate_file = rate_sci[-1]  # Show the last rate file, as an example.\n    display_rate(rate_file, vmin=-0.003, vmax=0.022, scale='linear',\n                 title_prefix='REPROCESSED')  # , extname='dq')\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-1-display-detector1pipeline-products","position":51},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"8.2 Display Spec2Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-2-display-spec2pipeline-products","position":52},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"8.2 Display Spec2Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Use Jdaviz \n\nMosviz to visualize and analyze the Stage 2 2D and 1D calibrated spectra. For more information on these visualization tools and plotting capabilities, refer to the official documentation linked.\n\n# Plot the Stage 3 MOS spectra with Mosviz.\nif doviz:\n    mosviz = Mosviz()\n    spectra_1d = glob.glob(spec2_dir+'*x1d.fits')\n    spectra_2d = glob.glob(spec2_dir+'*s2d.fits')\n    image = None  # If you have 'mymosaic.fits'\n    mosviz.load_data(spectra_1d=spectra_1d, spectra_2d=spectra_2d, images=image)\n    mosviz.show()\n\n\n\nDraw boxes around the extraction regions for each source in a _rate.fits file using the slit information from the corresponding Stage 2 calibrated products (_cal.fits or _s2d.fits). These boxes should be large enough to accommodate the curved spectral traces. While neighboring boxes may overlap, the spectra themselves do not.\n\nif doviz:\n    rate_file = rate_sci[-1]  # Show the last rate file, as an example.\n    display_rate(rate_file, slits_models=sci_cal[0], vmin=-0.003, vmax=0.022, scale='linear',\n                 title_prefix='REPROCESSED')  # , extname='dq')\n\n\n\nPlease note that the demo source data is technically defined and processed as an extended source, even though the plots above are presented in units of Jy (for point sources). For extended sources, the extraction box for the 1D spectra defaults to the center of the slitlet. In these cases, you may need to manually adjust the position of the extraction box.\n\nAdditionally, with point source data, you may sometimes observe that the extraction region is not always perfectly centered on the source. Recent improvements in resampling might exacerbate some off-centered cases, and in certain situations, the source may be completely missed. The workaround for this issue is found in \n\nSection 9.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-2-display-spec2pipeline-products","position":53},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"8.3 Display Spec3Pipeline Products","lvl2":"8. Visualize the Data"},"type":"lvl3","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-3-display-spec3pipeline-products","position":54},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl3":"8.3 Display Spec3Pipeline Products","lvl2":"8. Visualize the Data"},"content":"Inspect the Stage 3 combined calibrated spectra with Mosviz.\n\nif doviz:\n    mosviz = Mosviz()\n    spectra_1d = glob.glob(spec3_dir+'*x1d.fits')\n    spectra_2d = glob.glob(spec3_dir+'*s2d.fits')\n    image = None  # If you have 'mymosaic.fits'\n    mosviz.load_data(spectra_1d=spectra_1d, spectra_2d=spectra_2d, images=image)\n    mosviz.show()\n\n\n\nNote in the demo data, the default extraction region misses the positive signal for this 5-shutter slitlet target and instead extracts negative signal from one of the nod subtractions. A workaround in \n\nSection 9 is provided.\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-8-3-display-spec3pipeline-products","position":55},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-9-modifying-the-extract1d-reference-file-as-needed","position":56},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"9. Modifying the EXTRACT1D Reference File (as needed)"},"content":"extract_1d •\n\n\nEditing JSON reference file\n\nThe extract_1d step’s use_source_pos parameter in Stage 2 generally centers the 1D extraction box on the actual source location effectively and thus doesn’t usually require manual adjustment. However, in some cases, adjusting the position of the extraction box by modifying the EXTRACT1D reference file may be useful. The following section demonstrates how to modify which rows in the 2D spectrum (S2D) are used for extracting the 1D spectrum (X1D).\n\nThe EXTRACT1D reference file, along with several other parameter files, can be found in the CRDS_PATH directory. While some files, like .json files, can be manually edited, we modify them using Python.\n\nWarning: Currently, there is no aperture correction in place for NIRSpec, so the extract_width parameter MUST remain unchanged (6 pixels wide) to ensure proper flux calibration! The extraction box limits (ystart and ystop) can be modified; however, if ystart and ystop do not match the extract_width, the extract_width takes precedence and is applied symmetrically around the midpoint between ystart and ystop.\n\n# Modify the EXTRACT1D reference file.\n\n# If you don't know the reference file name this should work.\n# extract_1d_ref = Spec3Pipeline().get_reference_file(stage3_s2d, 'extract1d')\n\nrefs = api.dump_references(crds_client.get_context_used('jwst'),\n                           ['jwst_nirspec_extract1d_0009.json'])\nextract_1d_ref = refs['jwst_nirspec_extract1d_0009.json']\n\n# Open EXTRACT1D reference file in read-mode.\nwith open(extract_1d_ref, \"r\") as ref_file:\n    params = json.load(ref_file)\n\n    # All of these values are zero-indexed integers.\n    # The start and stop limits are inclusive.\n\n    # ANY MOS SLITLET\n    params[\"apertures\"][0][\"extract_width\"] = 6\n    params[\"apertures\"][0][\"ystart\"] = 22\n    params[\"apertures\"][0][\"ystop\"] = 27\n\n# Write changes to a new file.\nnewData = json.dumps(params, indent=4)\n# Add the suffix '_fs' to distinguish the file from the default version.\nbasename = os.path.basename(extract_1d_ref)[:-5]\nextract_1d_ref_mod = os.path.join(spec3_dir, basename + \"_mos.json\")\nwith open(extract_1d_ref_mod, \"w\") as file:\n    file.write(newData)\n\n\n\n# Inspect the EXTRACT1D reference file.\nwith open(extract_1d_ref_mod, 'r') as f_obj:\n    extract_1d_ref_mod_data = json.load(f_obj)\n\nJSON(extract_1d_ref_mod_data, expanded=True)\n\n\n\nRerun Extract1d step using the new EXTRACT1D reference file.\n\nfor s2d in stage3_s2d:\n    Extract1dStep.call(s2d,\n                       save_results=True,\n                       output_dir=spec3_dir,\n                       output_use_model=True,\n                       suffix='x1d_mod',  # Default suffix is `_extract1dstep.fits`\n                       use_source_posn=False,\n                       override_extract1d=extract_1d_ref_mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmosviz = Mosviz()\nspectra_1d = glob.glob(spec3_dir+'*x1d_mod.fits')\nspectra_2d = glob.glob(spec3_dir+'*s2d.fits')\nimage = None  # If you have 'mymosaic.fits'\nmosviz.load_data(spectra_1d=spectra_1d, spectra_2d=spectra_2d, images=image)\nmosviz.show()\n\n\n\nTo overlay the spectra for comparison run the cell below.\n\nif doviz:\n    stage3_x1ds_mod = sorted(glob.glob(spec3_dir + '*_x1d_mod.fits'))\n    display_spectra(stage3_s2d + stage3_x1d, compare_x1d=stage3_x1ds_mod,\n                    source_id=source_ids[0] or None, source_type='POINT', scale='log',\n                    vmin=0, vmax=3, y_limits=(-1e-6, 0.3e-5),\n                    title_prefix='REPROCESSED', is_stage3=True)\n\n\n\n\n\n","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#id-9-modifying-the-extract1d-reference-file-as-needed","position":57},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"Related Notebooks"},"type":"lvl2","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#related-notebooks","position":58},{"hierarchy":{"lvl1":"NIRSpec MOS Pipeline Notebook","lvl2":"Related Notebooks"},"content":"NIRSpec Workaround Notebooks\n\nJDAT: JWST Data Analysis Example Notebooks\n\nNotebooks running pipeline on simulated NIRSpec MOS data:\n\n\nJWebbinar7 (Oct 2021) •\n\n\nJDAT (2021) •\n\n\nJADES (June 2022)\n\nNotebook processing ERO SMACS0723 NIRSpec MOS data\nusing the JWST pipeline and\n\n\nmsaexp\n\nMOSViz notebook analyzing NIRSpec MOS spectra\n\nOptimal extraction\n\n\n\n\n\nTop of Page","type":"content","url":"/notebooks/nirspec/mos/jwpipenb-nirspec-mos#related-notebooks","position":59}]}